[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "Contrastive State Augmentations for Reinforcement Learning-Based\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2305.11081v1",
        "pub_date": "2023-05-18",
        "summary": "Learning reinforcement learning (RL)-based recommenders from historical\nuser-item interaction sequences is vital to generate high-reward\nrecommendations and improve long-term cumulative benefits. However, existing RL\nrecommendation methods encounter difficulties (i) to estimate the value\nfunctions for states which are not contained in the offline training data, and\n(ii) to learn effective state representations from user implicit feedback due\nto the lack of contrastive signals. In this work, we propose contrastive state\naugmentations (CSA) for the training of RL-based recommender systems. To tackle\nthe first issue, we propose four state augmentation strategies to enlarge the\nstate space of the offline data. The proposed method improves the\ngeneralization capability of the recommender by making the RL agent visit the\nlocal state regions and ensuring the learned value functions are similar\nbetween the original and augmented states. For the second issue, we propose\nintroducing contrastive signals between augmented states and the state randomly\nsampled from other sessions to improve the state representation learning\nfurther. To verify the effectiveness of the proposed CSA, we conduct extensive\nexperiments on two publicly accessible datasets and one dataset collected from\na real-life e-commerce platform. We also conduct experiments on a simulated\nenvironment as the online evaluation setting. Experimental results demonstrate\nthat CSA can effectively improve recommendation performance.",
        "translated": "从历史用户项目交互序列中学习基于强化学习的推荐对于产生高回报的推荐和提高长期累积效益至关重要。然而，现有的 RL 推荐方法遇到了困难(i)估计不包含在离线训练数据中的状态的值函数，以及(ii)由于缺乏对比信号而从用户隐式反馈中学习有效的状态表示。在这项工作中，我们提出了对比状态增强(CSA)的训练基于 RL 的推荐系统。针对第一个问题，我们提出了四种状态增强策略来扩大离线数据的状态空间。该方法通过使 RL 代理访问局部状态区域，保证学习值函数在原状态和增广状态之间相似，提高了推荐器的泛化能力。对于第二个问题，我们提出在增广状态和从其他会话中随机采样的状态之间引入对比信号，以进一步改善状态表示学习。为了验证所提出的 CSA 的有效性，我们对从现实生活中的电子商务平台收集的两个可公开访问的数据集和一个数据集进行了广泛的实验。我们还进行了模拟环境的实验，作为在线评价设置。实验结果表明，CSA 能有效提高推荐性能。"
    },
    {
        "title": "BERM: Training the Balanced and Extractable Representation for Matching\n  to Improve Generalization Ability of Dense Retrieval",
        "url": "http://arxiv.org/abs/2305.11052v1",
        "pub_date": "2023-05-18",
        "summary": "Dense retrieval has shown promise in the first-stage retrieval process when\ntrained on in-domain labeled datasets. However, previous studies have found\nthat dense retrieval is hard to generalize to unseen domains due to its weak\nmodeling of domain-invariant and interpretable feature (i.e., matching signal\nbetween two texts, which is the essence of information retrieval). In this\npaper, we propose a novel method to improve the generalization of dense\nretrieval via capturing matching signal called BERM. Fully fine-grained\nexpression and query-oriented saliency are two properties of the matching\nsignal. Thus, in BERM, a single passage is segmented into multiple units and\ntwo unit-level requirements are proposed for representation as the constraint\nin training to obtain the effective matching signal. One is semantic unit\nbalance and the other is essential matching unit extractability. Unit-level\nview and balanced semantics make representation express the text in a\nfine-grained manner. Essential matching unit extractability makes passage\nrepresentation sensitive to the given query to extract the pure matching\ninformation from the passage containing complex context. Experiments on BEIR\nshow that our method can be effectively combined with different dense retrieval\ntraining methods (vanilla, hard negatives mining and knowledge distillation) to\nimprove its generalization ability without any additional inference overhead\nand target domain data.",
        "translated": "密集检索在域内标记数据集训练的第一阶段检索过程中显示出希望。然而，先前的研究发现，由于密集检索对领域不变性和可解释特征(即两个文本之间的匹配信号，这是信息检索的本质)的建模较弱，因此很难将其推广到不可见的领域。在本文中，我们提出了一种新的方法来提高通过捕获匹配信号密集检索的泛化称为 BERM。完全细粒度表达式和面向查询的显著性是匹配信号的两个属性。因此，在误码率模型中，将一个通道分割成多个单元，并提出了两个单元级的要求作为训练中获得有效匹配信号的约束条件。一个是语义单元平衡，另一个是必要的匹配单元可提取性。单元级视图和平衡语义使表示以细粒度的方式表示文本。基本匹配单元可提取性使得文本表示对给定的查询敏感，从包含复杂上下文的文本中提取纯匹配信息。在 BEIR 上的实验表明，该方法可以有效地结合不同的密集检索训练方法(普通方法、硬负数挖掘和知识提取) ，在不增加任何推理开销和目标域数据的情况下提高其泛化能力。"
    },
    {
        "title": "Improving Recommendation System Serendipity Through Lexicase Selection",
        "url": "http://arxiv.org/abs/2305.11044v1",
        "pub_date": "2023-05-18",
        "summary": "Recommender systems influence almost every aspect of our digital lives.\nUnfortunately, in striving to give us what we want, they end up restricting our\nopen-mindedness. Current recommender systems promote echo chambers, where\npeople only see the information they want to see, and homophily, where users of\nsimilar background see similar content. We propose a new serendipity metric to\nmeasure the presence of echo chambers and homophily in recommendation systems\nusing cluster analysis. We then attempt to improve the diversity-preservation\nqualities of well known recommendation techniques by adopting a parent\nselection algorithm from the evolutionary computation literature known as\nlexicase selection. Our results show that lexicase selection, or a mixture of\nlexicase selection and ranking, outperforms its purely ranked counterparts in\nterms of personalization, coverage and our specifically designed serendipity\nbenchmark, while only slightly under-performing in terms of accuracy (hit\nrate). We verify these results across a variety of recommendation list sizes.\nIn this work we show that lexicase selection is able to maintain multiple\ndiverse clusters of item recommendations that are each relevant for the\nspecific user, while still maintaining a high hit-rate accuracy, a trade off\nthat is not achieved by other methods.",
        "translated": "推荐系统几乎影响了我们数字生活的方方面面。不幸的是，在努力给予我们想要的东西的过程中，他们最终限制了我们思想的开放性。目前的推荐系统推广回声室，人们只看到他们想看到的信息，同质性，相似背景的用户看到相似的内容。我们提出了一种新的意外发现度量方法，用来衡量使用数据聚类的推荐系统中是否存在回声室和同质性。然后，我们试图通过采用来自进化计算文献的父选择算法(称为 lexicase 选择)来改进众所周知的推荐技术的多样性保持质量。我们的研究结果表明，词汇表选择，或词汇表选择和排名的混合，在个性化，覆盖率和我们专门设计的意外发现基准方面表现优于纯粹的排名对应方，而在准确性(命中率)方面表现稍差。我们通过各种推荐列表大小来验证这些结果。在这项工作中，我们表明，词汇表选择能够维护多个不同的项目推荐集群，每个相关的特定用户，同时仍然保持高命中率的准确性，这是一个权衡，没有实现的其他方法。"
    },
    {
        "title": "Query Performance Prediction: From Ad-hoc to Conversational Search",
        "url": "http://arxiv.org/abs/2305.10923v1",
        "pub_date": "2023-05-18",
        "summary": "Query performance prediction (QPP) is a core task in information retrieval.\nThe QPP task is to predict the retrieval quality of a search system for a query\nwithout relevance judgments. Research has shown the effectiveness and\nusefulness of QPP for ad-hoc search. Recent years have witnessed considerable\nprogress in conversational search (CS). Effective QPP could help a CS system to\ndecide an appropriate action to be taken at the next turn. Despite its\npotential, QPP for CS has been little studied. We address this research gap by\nreproducing and studying the effectiveness of existing QPP methods in the\ncontext of CS. While the task of passage retrieval remains the same in the two\nsettings, a user query in CS depends on the conversational history, introducing\nnovel QPP challenges. In particular, we seek to explore to what extent findings\nfrom QPP methods for ad-hoc search generalize to three CS settings: (i)\nestimating the retrieval quality of different query rewriting-based retrieval\nmethods, (ii) estimating the retrieval quality of a conversational dense\nretrieval method, and (iii) estimating the retrieval quality for top ranks vs.\ndeeper-ranked lists. Our findings can be summarized as follows: (i) supervised\nQPP methods distinctly outperform unsupervised counterparts only when a\nlarge-scale training set is available; (ii) point-wise supervised QPP methods\noutperform their list-wise counterparts in most cases; and (iii) retrieval\nscore-based unsupervised QPP methods show high effectiveness in assessing the\nconversational dense retrieval method, ConvDR.",
        "translated": "查询性能预测是信息检索的核心任务。QPP 任务是在没有相关性判断的情况下预测查询检索系统的检索质量。研究表明 QPP 在自组织搜索中的有效性和实用性。近年来，会话搜索取得了长足的进步。有效的质量保证计划可以帮助 CS 系统决定下一轮要采取的适当行动。尽管 QPP 具有很大的潜力，但是对它的研究还很少。我们通过再现和研究现有的 QPP 方法在 CS 背景下的有效性来弥补这一研究差距。虽然在这两种情况下，文章检索的任务是相同的，但用户在 CS 中的查询依赖于会话历史，引入了新的 QPP 挑战。特别是，我们试图探索用于特别搜索的 QPP 方法的结果在多大程度上概括为三种 CS 设置: (i)估计不同基于查询重写的检索方法的检索质量，(ii)估计会话密集检索方法的检索质量，以及(iii)估计顶级与更深级列表的检索质量。我们的研究结果可以总结如下: (i)监督 QPP 方法只有在大规模训练集可用时才明显优于无监督的对应方法; (ii)点式监督 QPP 方法在大多数情况下优于其列表式对应方法; 和(iii)基于检索评分的无监督 QPP 方法在评估会话密集检索方法，ConvDR 方面显示出高效性。"
    },
    {
        "title": "Adaptive Graph Contrastive Learning for Recommendation",
        "url": "http://arxiv.org/abs/2305.10837v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, graph neural networks (GNNs) have been successfully applied to\nrecommender systems as an effective collaborative filtering (CF) approach. The\nkey idea of GNN-based recommender system is to recursively perform the message\npassing along the user-item interaction edge for refining the encoded\nembeddings, relying on sufficient and high-quality training data. Since user\nbehavior data in practical recommendation scenarios is often noisy and exhibits\nskewed distribution, some recommendation approaches, e.g., SGL and SimGCL,\nleverage self-supervised learning to improve user representations against the\nabove issues. Despite their effectiveness, however, they conduct\nself-supervised learning through creating contrastvie views, depending on the\nexploration of data augmentations with the problem of tedious trial-and-error\nselection of augmentation methods. In this paper, we propose a novel Adaptive\nGraph Contrastive Learning (AdaptiveGCL) framework which conducts graph\ncontrastive learning with two adaptive contrastive view generators to better\nempower CF paradigm. Specifically, we use two trainable view generators, which\nare a graph generative model and a graph denoising model respectively, to\ncreate contrastive views. Two generators are able to create adaptive\ncontrastive views, addressing the problem of model collapse and achieving\nadaptive contrastive learning. With two adaptive contrasive views, more\nadditionally high-quality training signals will be introduced into the CF\nparadigm and help to alleviate the data sparsity and noise issues. Extensive\nexperiments on three benchmark datasets demonstrate the superiority of our\nmodel over various state-of-the-art recommendation methods. Further visual\nanalysis intuitively explains why our AdaptiveGCL outperforms existing\ncontrastive learning approaches based on selected data augmentation methods.",
        "translated": "最近，图形神经网络(GNN)已成功应用于推荐系统，作为一种有效的协同过滤(CF)方法。基于 GNN 的推荐系统的关键思想是依靠充分和高质量的训练数据，递归地执行沿用户项目交互边缘传递的消息，以完善编码的嵌入。由于实际推荐场景中的用户行为数据通常是有噪音的，并且呈现出倾斜的分布，因此一些推荐方法，如 SGL 和 SimGCL，利用自监督学习来改善用户对上述问题的表示。然而，尽管他们的有效性，他们进行自我监督学习通过创建对比观点，依赖于探索数据增强与繁琐的试错选择增强方法的问题。本文提出了一种新的自适应图形对比学习(AdaptiveGCL)框架，该框架使用两个自适应对比视图生成器进行图形对比学习，以更好地支持 CF 范式。具体来说，我们使用两个可训练的视图生成器，分别是一个图形生成模型和一个图形去噪模型，来创建对比视图。两个生成器能够创建自适应对比视图，解决模型崩溃问题，实现自适应对比学习。通过两个自适应对立视图，在 CF 范式中引入更多高质量的训练信号，有助于缓解数据稀疏和噪声问题。在三个基准数据集上的大量实验证明了我们的模型优于各种最先进的推荐方法。进一步的可视化分析直观地解释了为什么我们的 AdaptiveGCL 优于基于所选数据增强方法的现有对比学习方法。"
    },
    {
        "title": "Integrating Item Relevance in Training Loss for Sequential Recommender\n  Systems",
        "url": "http://arxiv.org/abs/2305.10824v1",
        "pub_date": "2023-05-18",
        "summary": "Sequential Recommender Systems (SRSs) are a popular type of recommender\nsystem that learns from a user's history to predict the next item they are\nlikely to interact with. However, user interactions can be affected by noise\nstemming from account sharing, inconsistent preferences, or accidental clicks.\nTo address this issue, we (i) propose a new evaluation protocol that takes\nmultiple future items into account and (ii) introduce a novel relevance-aware\nloss function to train a SRS with multiple future items to make it more robust\nto noise. Our relevance-aware models obtain an improvement of ~1.2% of NDCG@10\nand 0.88% in the traditional evaluation protocol, while in the new evaluation\nprotocol, the improvement is ~1.63% of NDCG@10 and ~1.5% of HR w.r.t the best\nperforming models.",
        "translated": "顺序推荐系统(SRSs)是一种流行的推荐系统，它可以从用户的历史中学习，预测他们可能接触到的下一个项目。然而，用户交互可能受到来自帐户共享、不一致的首选项或偶然点击的噪音的影响。为了解决这个问题，我们(i)提出了一个新的评估协议，考虑到多个未来项目，并且(ii)引入一个新的相关性感知损失函数来训练具有多个未来项目的 SRS，以使其对噪声更加鲁棒。我们的相关意识模型在传统的评估方案中获得了? 1.2% 的 NDCG@10和0.88% 的改善，而在新的评估方案中，改善是? 1.63% 的 NDCG@10和? 1.5% 的最佳表现模型。"
    },
    {
        "title": "When Search Meets Recommendation: Learning Disentangled Search\n  Representation for Recommendation",
        "url": "http://arxiv.org/abs/2305.10822v1",
        "pub_date": "2023-05-18",
        "summary": "Modern online service providers such as online shopping platforms often\nprovide both search and recommendation (S&amp;R) services to meet different user\nneeds. Rarely has there been any effective means of incorporating user behavior\ndata from both S&amp;R services. Most existing approaches either simply treat S&amp;R\nbehaviors separately, or jointly optimize them by aggregating data from both\nservices, ignoring the fact that user intents in S&amp;R can be distinctively\ndifferent. In our paper, we propose a Search-Enhanced framework for the\nSequential Recommendation (SESRec) that leverages users' search interests for\nrecommendation, by disentangling similar and dissimilar representations within\nS&amp;R behaviors. Specifically, SESRec first aligns query and item embeddings\nbased on users' query-item interactions for the computations of their\nsimilarities. Two transformer encoders are used to learn the contextual\nrepresentations of S&amp;R behaviors independently. Then a contrastive learning\ntask is designed to supervise the disentanglement of similar and dissimilar\nrepresentations from behavior sequences of S&amp;R. Finally, we extract user\ninterests by the attention mechanism from three perspectives, i.e., the\ncontextual representations, the two separated behaviors containing similar and\ndissimilar interests. Extensive experiments on both industrial and public\ndatasets demonstrate that SESRec consistently outperforms state-of-the-art\nmodels. Empirical studies further validate that SESRec successfully disentangle\nsimilar and dissimilar user interests from their S&amp;R behaviors.",
        "translated": "现代在线服务提供商，如在线购物平台，经常同时提供搜索和推荐(S & R)服务，以满足不同的用户需求。很少有任何有效的方法来整合来自 S & R 服务的用户行为数据。大多数现有的方法要么单独处理 S & R 行为，要么通过聚合来自两个服务的数据来共同优化它们，忽略了 S & R 中的用户意图可能截然不同的事实。在我们的论文中，我们提出了一个搜索增强的序列推荐框架(SESRec) ，它利用用户的搜索兴趣进行推荐，通过在 S & R 行为中分离相似和不相似的表示。具体来说，SESRec 首先根据用户的查询-项交互对查询和项嵌入进行对齐，以计算它们的相似性。使用两个变压器编码器分别学习 S & R 行为的上下文表示。然后设计了一个对比学习任务来监督 S & R 行为序列中相似和不相似表征的分离。最后，通过注意机制从三个方面提取用户的兴趣，即语境表征，两个分离的具有相似兴趣和不同兴趣的行为。在工业和公共数据集上的大量实验表明，SESRec 始终优于最先进的模型。实证研究进一步验证了 SESRec 成功地将相似和不同的用户兴趣从他们的 S & R 行为中分离出来。"
    },
    {
        "title": "How Does Generative Retrieval Scale to Millions of Passages?",
        "url": "http://arxiv.org/abs/2305.11841v1",
        "pub_date": "2023-05-19",
        "summary": "Popularized by the Differentiable Search Index, the emerging paradigm of\ngenerative retrieval re-frames the classic information retrieval problem into a\nsequence-to-sequence modeling task, forgoing external indices and encoding an\nentire document corpus within a single Transformer. Although many different\napproaches have been proposed to improve the effectiveness of generative\nretrieval, they have only been evaluated on document corpora on the order of\n100k in size. We conduct the first empirical study of generative retrieval\ntechniques across various corpus scales, ultimately scaling up to the entire MS\nMARCO passage ranking task with a corpus of 8.8M passages and evaluating model\nsizes up to 11B parameters. We uncover several findings about scaling\ngenerative retrieval to millions of passages; notably, the central importance\nof using synthetic queries as document representations during indexing, the\nineffectiveness of existing proposed architecture modifications when accounting\nfor compute cost, and the limits of naively scaling model parameters with\nrespect to retrieval performance. While we find that generative retrieval is\ncompetitive with state-of-the-art dual encoders on small corpora, scaling to\nmillions of passages remains an important and unsolved challenge. We believe\nthese findings will be valuable for the community to clarify the current state\nof generative retrieval, highlight the unique challenges, and inspire new\nresearch directions.",
        "translated": "由于可分辨搜索索引的普及，新兴的生成检索范式将经典的信息检索问题重新定义为一个序列到序列的建模任务，放弃外部索引，并在一个 former 中编码整个文档语料库。为了提高生成检索的有效性，人们提出了许多不同的方法，但这些方法在文献语料库中的检索效果只有10万次左右。我们进行了第一次实证研究的生成检索技术在不同的语料库尺度，最终扩大到整个 MS MARCO 段落排序任务与8.8 M 段落的语料库和评估模型大小高达11B 参数。我们发现了关于将生成性检索扩展到数百万段的一些发现; 值得注意的是，在索引过程中使用合成查询作为文档表示的核心重要性，在计算计算成本时现有提议的架构修改的无效性，以及天真地扩展模型参数对检索性能的限制。虽然我们发现生成检索与小型语料库上最先进的双编码器相比具有竞争力，但是扩展到数百万段仍然是一个重要的未解决的挑战。我们相信这些研究结果将有助于社区阐明生成性检索的现状，突出独特的挑战，并启发新的研究方向。"
    },
    {
        "title": "Visualization for Recommendation Explainability: A Survey and New\n  Perspectives",
        "url": "http://arxiv.org/abs/2305.11755v1",
        "pub_date": "2023-05-19",
        "summary": "Providing system-generated explanations for recommendations represents an\nimportant step towards transparent and trustworthy recommender systems.\nExplainable recommender systems provide a human-understandable rationale for\ntheir outputs. Over the last two decades, explainable recommendation has\nattracted much attention in the recommender systems research community. This\npaper aims to provide a comprehensive review of research efforts on visual\nexplanation in recommender systems. More concretely, we systematically review\nthe literature on explanations in recommender systems based on four dimensions,\nnamely explanation goal, explanation scope, explanation style, and explanation\nformat. Recognizing the importance of visualization, we approach the\nrecommender system literature from the angle of explanatory visualizations,\nthat is using visualizations as a display style of explanation. As a result, we\nderive a set of guidelines that might be constructive for designing explanatory\nvisualizations in recommender systems and identify perspectives for future work\nin this field. The aim of this review is to help recommendation researchers and\npractitioners better understand the potential of visually explainable\nrecommendation research and to support them in the systematic design of visual\nexplanations in current and future recommender systems.",
        "translated": "对建议提供系统生成的解释是朝向透明和可靠的推荐系统迈出的重要一步。可解释的推荐系统为其输出提供了一个人类可理解的理由。在过去的二十年中，可解释的推荐引起了推荐系统研究界的广泛关注。本文旨在对推荐系统中视觉解释的研究工作进行综述。更具体地，我们从解释目的、解释范围、解释风格和解释格式四个维度系统地回顾了关于推荐系统中解释的文献。认识到可视化的重要性，我们从解释性可视化的角度来看待推荐系统文献，即使用可视化作为一种解释的显示方式。因此，我们得出了一套指导方针，可能是建设性的设计解释性可视化在推荐系统，并确定未来的工作在这一领域的前景。本综述的目的是帮助推荐研究人员和从业人员更好地理解可视化解释推荐研究的潜力，并支持他们在目前和未来的推荐系统中系统地设计可视化解释。"
    },
    {
        "title": "Inference-time Re-ranker Relevance Feedback for Neural Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2305.11744v1",
        "pub_date": "2023-05-19",
        "summary": "Neural information retrieval often adopts a retrieve-and-rerank framework: a\nbi-encoder network first retrieves K (e.g., 100) candidates that are then\nre-ranked using a more powerful cross-encoder model to rank the better\ncandidates higher. The re-ranker generally produces better candidate scores\nthan the retriever, but is limited to seeing only the top K retrieved\ncandidates, thus providing no improvements in retrieval performance as measured\nby Recall@K. In this work, we leverage the re-ranker to also improve retrieval\nby providing inference-time relevance feedback to the retriever. Concretely, we\nupdate the retriever's query representation for a test instance using a\nlightweight inference-time distillation of the re-ranker's prediction for that\ninstance. The distillation loss is designed to bring the retriever's candidate\nscores closer to those of the re-ranker. A second retrieval step is then\nperformed with the updated query vector. We empirically show that our approach,\nwhich can serve arbitrary retrieve-and-rerank pipelines, significantly improves\nretrieval recall in multiple domains, languages, and modalities.",
        "translated": "神经信息检索通常采用一个检索-重新排序框架: 一个双编码器网络首先检索 K (例如，100)候选人，然后使用一个更强大的交叉编码器模型重新排序，以排序更好的候选人更高。重新排名通常比检索器产生更好的候选人分数，但是仅限于看到被检索的最高 K 的候选人，因此没有提供根据 Recall@K 测量的检索性能的改善。在这项工作中，我们利用重新排名也提高检索提供推理时间关联反馈的检索。具体来说，我们使用重新排序器对测试实例的预测的轻量级推理时间精馏来更新检索器对该实例的查询表示。蒸馏损失的目的是使猎犬的候选分数更接近那些重新排名。然后使用更新的查询向量执行第二个检索步骤。我们的实验表明，我们的方法，可以服务任意的检索和重新排序管道，显着提高检索召回在多个领域，语言和模式。"
    },
    {
        "title": "Exploring the Upper Limits of Text-Based Collaborative Filtering Using\n  Large Language Models: Discoveries and Insights",
        "url": "http://arxiv.org/abs/2305.11700v1",
        "pub_date": "2023-05-19",
        "summary": "Text-based collaborative filtering (TCF) has become the mainstream approach\nfor text and news recommendation, utilizing text encoders, also known as\nlanguage models (LMs), to represent items. However, existing TCF models\nprimarily focus on using small or medium-sized LMs. It remains uncertain what\nimpact replacing the item encoder with one of the largest and most powerful\nLMs, such as the 175-billion parameter GPT-3 model, would have on\nrecommendation performance. Can we expect unprecedented results? To this end,\nwe conduct an extensive series of experiments aimed at exploring the\nperformance limits of the TCF paradigm. Specifically, we increase the size of\nitem encoders from one hundred million to one hundred billion to reveal the\nscaling limits of the TCF paradigm. We then examine whether these extremely\nlarge LMs could enable a universal item representation for the recommendation\ntask. Furthermore, we compare the performance of the TCF paradigm utilizing the\nmost powerful LMs to the currently dominant ID embedding-based paradigm and\ninvestigate the transferability of this TCF paradigm. Finally, we compare TCF\nwith the recently popularized prompt-based recommendation using ChatGPT. Our\nresearch findings have not only yielded positive results but also uncovered\nsome surprising and previously unknown negative outcomes, which can inspire\ndeeper reflection and innovative thinking regarding text-based recommender\nsystems. Codes and datasets will be released for further research.",
        "translated": "基于文本的协同过滤(TCF)已经成为文本和新闻推荐的主流方法，利用文本编码器(也称为语言模型(LMs))来表示项目。然而，现有的 TCF 模型主要侧重于使用中小型 LM。用最大最强的 LM (比如1750亿参数的 GPT-3模型)替换项目编码器会对推荐性能产生什么影响还不确定。我们能期待前所未有的结果吗？为此，我们进行了一系列广泛的实验，旨在探索 TCF 范式的性能极限。具体来说，我们将条目编码器的大小从1亿增加到1亿，以揭示 TCF 范例的伸缩限制。然后，我们检查这些极大的 LM 是否能够为推荐任务启用通用项表示。此外，我们比较了使用最强大的 LM 的 TCF 范式和目前占主导地位的基于 ID 嵌入的 TCF 范式的性能，并研究了这种 TCF 范式的可转移性。最后，我们使用 ChatGPT 比较 TCF 和最近推广的基于提示的推荐。我们的研究结果不仅产生了积极的结果，而且还揭示了一些令人惊讶的和以前未知的负面结果，这可以激发关于基于文本的推荐系统的更深层次的反思和创新思维。代码和数据集将被发布用于进一步的研究。"
    },
    {
        "title": "The Barriers to Online Clothing Websites for Visually Impaired People:\n  An Interview and Observation Approach to Understanding Needs",
        "url": "http://arxiv.org/abs/2305.11559v1",
        "pub_date": "2023-05-19",
        "summary": "Visually impaired (VI) people often face challenges when performing everyday\ntasks and identify shopping for clothes as one of the most challenging. Many\nengage in online shopping, which eliminates some challenges of physical\nshopping. However, clothes shopping online suffers from many other limitations\nand barriers. More research is needed to address these challenges, and extant\nworks often base their findings on interviews alone, providing only subjective,\nrecall-biased information. We conducted two complementary studies using both\nobservational and interview approaches to fill a gap in understanding about VI\npeople's behaviour when selecting and purchasing clothes online. Our findings\nshow that shopping websites suffer from inaccurate, misleading, and\ncontradictory clothing descriptions; that VI people mainly rely on (unreliable)\nsearch tools and check product descriptions by reviewing customer comments. Our\nfindings also indicate that VI people are hesitant to accept assistance from\nautomated, but that trust in such systems could be improved if researchers can\ndevelop systems that better accommodate users' needs and preferences.",
        "translated": "视力受损者在日常工作中经常面临挑战，购买衣服是最具挑战性的工作之一。许多人从事网上购物，这消除了实体购物的一些挑战。然而，网上购物的服装受到许多其他限制和障碍。需要更多的研究来解决这些挑战，现存的工作往往基于他们的调查结果仅仅访谈，只提供主观的，回忆偏见的信息。我们使用观察和访谈的方法进行了两个互补的研究，以填补在线选择和购买服装时对 VI 人群行为的理解差距。我们的研究结果表明，购物网站容易受到不准确、误导和自相矛盾的服装描述的困扰; VI 用户主要依靠(不可靠的)搜索工具，通过查看顾客评论来检查产品描述。我们的研究结果还表明，VI 人士不愿意接受自动化系统的帮助，但如果研究人员能够开发出更好地适应用户需求和偏好的系统，那么对这种系统的信任就可以得到改善。"
    },
    {
        "title": "InstructIE: A Chinese Instruction-based Information Extraction Dataset",
        "url": "http://arxiv.org/abs/2305.11527v1",
        "pub_date": "2023-05-19",
        "summary": "We introduce a new Information Extraction (IE) task dubbed Instruction-based\nIE, which aims to ask the system to follow specific instructions or guidelines\nto extract information. To facilitate research in this area, we construct a\ndataset called InstructIE, consisting of 270,000 weakly supervised data from\nChinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We\nfurther evaluate the performance of various baseline models on the InstructIE\ndataset. The results reveal that although current models exhibit promising\nperformance, there is still room for improvement. Furthermore, we conduct a\ncomprehensive case study analysis, underlining the challenges inherent in the\nInstruction-based IE task. Code and dataset are available at\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.",
        "translated": "我们引入了一个新的基于指令的信息抽取(IE)任务，其目的是要求系统遵循特定的指令或指南来提取信息。为了促进这一领域的研究，我们构建了一个名为 DirectIE 的数据集，由来自中文维基百科的270,000个弱监督数据和1000个高质量的众包注释实例组成。我们进一步评估了各种基线模型在 DirectIE 数据集上的性能。结果表明，虽然目前的模型表现出良好的性能，仍然有改进的空间。此外，我们进行了一个全面的案例研究分析，强调了基于教学的 IE 任务固有的挑战。代码和数据集可在 https://github.com/zjunlp/deepke/tree/main/example/llm 下载。"
    },
    {
        "title": "Recouple Event Field via Probabilistic Bias for Event Extraction",
        "url": "http://arxiv.org/abs/2305.11498v1",
        "pub_date": "2023-05-19",
        "summary": "Event Extraction (EE), aiming to identify and classify event triggers and\narguments from event mentions, has benefited from pre-trained language models\n(PLMs). However, existing PLM-based methods ignore the information of\ntrigger/argument fields, which is crucial for understanding event schemas. To\nthis end, we propose a Probabilistic reCoupling model enhanced Event extraction\nframework (ProCE). Specifically, we first model the syntactic-related event\nfields as probabilistic biases, to clarify the event fields from ambiguous\nentanglement. Furthermore, considering multiple occurrences of the same\ntriggers/arguments in EE, we explore probabilistic interaction strategies among\nmultiple fields of the same triggers/arguments, to recouple the corresponding\nclarified distributions and capture more latent information fields. Experiments\non EE datasets demonstrate the effectiveness and generalization of our proposed\napproach.",
        "translated": "事件提取(EE) ，旨在从事件提及中识别和分类事件触发器和参数，已经受益于预训练语言模型(PLM)。然而，现有的基于 PLM 的方法忽略了触发器/参数字段的信息，这对于理解事件模式是至关重要的。为此，我们提出了一个概率重耦合模型增强的事件抽取框架(ProCE)。具体来说，我们首先将与句法相关的事件字段建模为概率偏差，以澄清来自模糊纠缠的事件字段。此外，考虑到同一触发器/参数在 EE 中的多次出现，我们探索了同一触发器/参数的多个域之间的概率交互策略，以重新耦合相应的澄清分布并捕获更多的潜在信息域。在 EE 数据集上的实验证明了该方法的有效性和推广性。"
    },
    {
        "title": "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks",
        "url": "http://arxiv.org/abs/2305.11430v1",
        "pub_date": "2023-05-19",
        "summary": "While LLMs have shown great success in understanding and generating text in\ntraditional conversational settings, their potential for performing ill-defined\ncomplex tasks is largely under-studied. Indeed, we are yet to conduct\ncomprehensive benchmarking studies with multiple LLMs that are exclusively\nfocused on a complex task. However, conducting such benchmarking studies is\nchallenging because of the large variations in LLMs' performance when different\nprompt types/styles are used and different degrees of detail are provided in\nthe prompts. To address this issue, the paper proposes a general taxonomy that\ncan be used to design prompts with specific properties in order to perform a\nwide range of complex tasks. This taxonomy will allow future benchmarking\nstudies to report the specific categories of prompts used as part of the study,\nenabling meaningful comparisons across different studies. Also, by establishing\na common standard through this taxonomy, researchers will be able to draw more\naccurate conclusions about LLMs' performance on a specific complex task.",
        "translated": "虽然 LLM 在理解和生成传统会话环境中的文本方面取得了巨大的成功，但它们执行定义不清的复杂任务的潜力在很大程度上还没有得到充分的研究。事实上，我们还没有进行全面的基准研究与多个 LLM，专门集中在一个复杂的任务。然而，进行这样的基准测试研究是具有挑战性的，因为当使用不同的提示类型/风格和提示中提供不同程度的细节时，LLM 的性能有很大的差异。为了解决这个问题，本文提出了一个通用分类法，可用于设计具有特定属性的提示符，以便执行范围广泛的复杂任务。这种分类法将使未来的基准研究能够报告作为研究的一部分使用的特定类别的提示，使不同研究之间的有意义的比较成为可能。此外，通过建立一个共同的标准通过这个分类，研究人员将能够得出更准确的结论 LLM 的表现在一个特定的复杂的任务。"
    },
    {
        "title": "Online Learning in a Creator Economy",
        "url": "http://arxiv.org/abs/2305.11381v1",
        "pub_date": "2023-05-19",
        "summary": "The creator economy has revolutionized the way individuals can profit through\nonline platforms. In this paper, we initiate the study of online learning in\nthe creator economy by modeling the creator economy as a three-party game\nbetween the users, platform, and content creators, with the platform\ninteracting with the content creator under a principal-agent model through\ncontracts to encourage better content. Additionally, the platform interacts\nwith the users to recommend new content, receive an evaluation, and ultimately\nprofit from the content, which can be modeled as a recommender system.\n  Our study aims to explore how the platform can jointly optimize the contract\nand recommender system to maximize the utility in an online learning fashion.\nWe primarily analyze and compare two families of contracts: return-based\ncontracts and feature-based contracts. Return-based contracts pay the content\ncreator a fraction of the reward the platform gains. In contrast, feature-based\ncontracts pay the content creator based on the quality or features of the\ncontent, regardless of the reward the platform receives. We show that under\nsmoothness assumptions, the joint optimization of return-based contracts and\nrecommendation policy provides a regret $\\Theta(T^{2/3})$. For the\nfeature-based contract, we introduce a definition of intrinsic dimension $d$ to\ncharacterize the hardness of learning the contract and provide an upper bound\non the regret $\\mathcal{O}(T^{(d+1)/(d+2)})$. The upper bound is tight for the\nlinear family.",
        "translated": "创造者经济彻底改变了个人通过在线平台获利的方式。本文通过将创造者经济建模为用户、平台和内容创造者之间的三方博弈，平台与内容创造者在委托-代理模式下通过契约互动来鼓励更好的内容，开展了创造者经济中在线学习的研究。此外，该平台与用户互动，推荐新内容，接受评估，并最终从内容中获利，这些内容可以被建模为推荐系统。我们的研究旨在探讨这个平台如何能够共同优化合同和推荐系统，以便在网上学习的模式中最大限度地发挥效用。我们主要分析和比较了两类契约: 基于回报的契约和基于特征的契约。基于回报的合同支付给内容创作者的报酬只是平台收益的一小部分。相比之下，基于特性的合同根据内容的质量或特性支付给内容创作者，而不管平台获得什么报酬。结果表明，在平滑假设下，基于回报的合同和推荐策略的联合优化得到了遗憾的 $Θ (T ^ {2/3}) $。对于基于特征的契约，我们引入了本征维度 $d $的定义来描述学习契约的难度，并给出了遗憾 $数学{ O }(T ^ {(d + 1)/(d + 2)}) $的上界。线性族的上界是紧的。"
    },
    {
        "title": "Copy Recurrent Neural Network Structure Network",
        "url": "http://arxiv.org/abs/2305.13250v1",
        "pub_date": "2023-05-22",
        "summary": "Electronic Health Record (EHR) coding involves automatically classifying EHRs\ninto diagnostic codes. While most previous research treats this as a\nmulti-label classification task, generating probabilities for each code and\nselecting those above a certain threshold as labels, these approaches often\noverlook the challenge of identifying complex diseases. In this study, our\nfocus is on detecting complication diseases within EHRs.\n  We propose a novel coarse-to-fine ICD path generation framework called the\nCopy Recurrent Neural Network Structure Network (CRNNet), which employs a Path\nGenerator (PG) and a Path Discriminator (PD) for EHR coding. By using RNNs to\ngenerate sequential outputs and incorporating a copy module, we efficiently\nidentify complication diseases. Our method achieves a 57.30\\% ratio of complex\ndiseases in predictions, outperforming state-of-the-art and previous\napproaches.\n  Additionally, through an ablation study, we demonstrate that the copy\nmechanism plays a crucial role in detecting complex diseases.",
        "translated": "电子健康记录(EHR)编码涉及将 EHR 自动分类为诊断代码。虽然大多数以前的研究将其视为一个多标签分类任务，为每个代码产生概率，并选择那些高于某个阈值的代码作为标签，但这些方法往往忽视了识别复杂疾病的挑战。在这项研究中，我们的重点是检测并发症的 EHR 疾病。我们提出了一个新的由粗到精的 ICD 路径生成框架，称为拷贝递归神经网络结构网络(crnNet) ，它使用路径生成器(PG)和路径鉴别器(PD)进行电子健康记录(eHR)编码。通过使用 RNN 产生序列输出和合并拷贝模块，我们有效地识别并发症疾病。我们的方法在预测复杂疾病方面达到了57.30% 的比例，超过了最先进的方法和以前的方法。此外，通过消融研究，我们证明复制机制在检测复杂疾病中起着至关重要的作用。"
    },
    {
        "title": "Challenging Decoder helps in Masked Auto-Encoder Pre-training for Dense\n  Passage Retrieval",
        "url": "http://arxiv.org/abs/2305.13197v1",
        "pub_date": "2023-05-22",
        "summary": "Recently, various studies have been directed towards exploring dense passage\nretrieval techniques employing pre-trained language models, among which the\nmasked auto-encoder (MAE) pre-training architecture has emerged as the most\npromising. The conventional MAE framework relies on leveraging the passage\nreconstruction of decoder to bolster the text representation ability of\nencoder, thereby enhancing the performance of resulting dense retrieval\nsystems. Within the context of building the representation ability of the\nencoder through passage reconstruction of decoder, it is reasonable to\npostulate that a ``more demanding'' decoder will necessitate a corresponding\nincrease in the encoder's ability. To this end, we propose a novel token\nimportance aware masking strategy based on pointwise mutual information to\nintensify the challenge of the decoder. Importantly, our approach can be\nimplemented in an unsupervised manner, without adding additional expenses to\nthe pre-training phase. Our experiments verify that the proposed method is both\neffective and robust on large-scale supervised passage retrieval datasets and\nout-of-domain zero-shot retrieval benchmarks.",
        "translated": "近年来，各种研究都致力于探索使用预训练语言模型的密集通道检索技术，其中掩蔽自动编码器(MAE)预训练结构是最有前途的一种。传统的 MAE 框架依赖于利用解码器的通道重构来增强编码器的文本表示能力，从而提高密集检索系统的性能。在通过解码器的通道重构来建立编码器的表示能力的背景下，假设“更高要求”的解码器需要相应提高编码器的表示能力是合理的。为此，我们提出了一种新颖的基于点间互信息的标记重要性感知掩蔽策略，以增强解码器的挑战性。重要的是，我们的方法可以在一个无监督的方式实施，而不增加额外的费用，预培训阶段。实验结果表明，该方法对于大规模有监督通道检索数据集和域外零镜头检索基准具有良好的鲁棒性和有效性。"
    },
    {
        "title": "TEIMMA: The First Content Reuse Annotator for Text, Images, and Math",
        "url": "http://arxiv.org/abs/2305.13193v1",
        "pub_date": "2023-05-22",
        "summary": "This demo paper presents the first tool to annotate the reuse of text,\nimages, and mathematical formulae in a document pair -- TEIMMA. Annotating\ncontent reuse is particularly useful to develop plagiarism detection\nalgorithms. Real-world content reuse is often obfuscated, which makes it\nchallenging to identify such cases. TEIMMA allows entering the obfuscation type\nto enable novel classifications for confirmed cases of plagiarism. It enables\nrecording different reuse types for text, images, and mathematical formulae in\nHTML and supports users by visualizing the content reuse in a document pair\nusing similarity detection methods for text and math.",
        "translated": "本演示文件介绍了第一个注释文本、图像和数学公式在文档对中的重用的工具—— TEIMMA。注释内容重用对于开发剽窃检测算法特别有用。真实世界的内容重用通常是模糊的，这使得识别这种情况变得很困难。TEIMMA 允许输入模糊类型，以便对确认的剽窃案件进行新的分类。它支持在 HTML 中记录文本、图像和数学公式的不同重用类型，并通过使用文本和数学的相似性检测方法可视化文档对中的内容重用来支持用户。"
    },
    {
        "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
        "url": "http://arxiv.org/abs/2305.13172v1",
        "pub_date": "2023-05-22",
        "summary": "Recent advancements in deep learning have precipitated the emergence of large\nlanguage models (LLMs) which exhibit an impressive aptitude for understanding\nand producing text akin to human language. Despite the ability to train highly\ncapable LLMs, the methodology for maintaining their relevancy and rectifying\nerrors remains elusive. To that end, the past few years have witnessed a surge\nin techniques for editing LLMs, the objective of which is to alter the behavior\nof LLMs within a specific domain without negatively impacting performance\nacross other inputs. This paper embarks on a deep exploration of the problems,\nmethods, and opportunities relating to model editing for LLMs. In particular,\nwe provide an exhaustive overview of the task definition and challenges\nassociated with model editing, along with an in-depth empirical analysis of the\nmost progressive methods currently at our disposal. We also build a new\nbenchmark dataset to facilitate a more robust evaluation and pinpoint enduring\nissues intrinsic to existing techniques. Our objective is to provide valuable\ninsights into the effectiveness and feasibility of each model editing\ntechnique, thereby assisting the research community in making informed\ndecisions when choosing the most appropriate method for a specific task or\ncontext. Code and datasets will be available at\nhttps://github.com/zjunlp/EasyEdit.",
        "translated": "深度学习的最新进展催生了大型语言模型(LLM)的出现，它们在理解和产生类似于人类语言的文本方面表现出令人印象深刻的天赋。尽管有能力培训高能力的 LLM，但保持其相关性和纠正错误的方法仍然是难以捉摸的。为此，过去几年见证了 LLM 编辑技术的激增，其目标是改变特定领域内 LLM 的行为，而不会对其他输入的性能产生负面影响。本文对 LLM 模型编辑的问题、方法和机会进行了深入的探讨。特别是，我们提供了任务定义和与模型编辑有关的挑战的详尽概述，以及对我们目前掌握的最进步的方法的深入实证分析。我们还建立了一个新的基准数据集，以促进更强大的评估，并确定持久的问题内在的现有技术。我们的目标是提供有价值的见解，每个模型编辑技术的有效性和可行性，从而协助研究界作出知情的决定时，选择最适当的方法，具体的任务或背景。代码和数据集将在 https://github.com/zjunlp/easyedit 提供。"
    },
    {
        "title": "LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities\n  and Future Opportunities",
        "url": "http://arxiv.org/abs/2305.13168v1",
        "pub_date": "2023-05-22",
        "summary": "This paper presents an exhaustive quantitative and qualitative evaluation of\nLarge Language Models (LLMs) for Knowledge Graph (KG) construction and\nreasoning. We employ eight distinct datasets that encompass aspects including\nentity, relation and event extraction, link prediction, and question answering.\nEmpirically, our findings suggest that GPT-4 outperforms ChatGPT in the\nmajority of tasks and even surpasses fine-tuned models in certain reasoning and\nquestion-answering datasets. Moreover, our investigation extends to the\npotential generalization ability of LLMs for information extraction, which\nculminates in the presentation of the Virtual Knowledge Extraction task and the\ndevelopment of the VINE dataset. Drawing on these empirical findings, we\nfurther propose AutoKG, a multi-agent-based approach employing LLMs for KG\nconstruction and reasoning, which aims to chart the future of this field and\noffer exciting opportunities for advancement. We anticipate that our research\ncan provide invaluable insights for future undertakings of KG\\footnote{Code and\ndatasets will be available in https://github.com/zjunlp/AutoKG.",
        "translated": "本文对知识图(KG)构造和推理的大语言模型(LLM)进行了详尽的定量和定性评价。我们使用八个不同的数据集，包括实体、关系和事件提取、链接预测和问题回答。经验上，我们的研究结果表明，GPT-4在大多数任务中的表现优于 ChatGPT，甚至在某些推理和问答数据集中优于微调模型。此外，我们的研究扩展到 LLM 对信息抽取的潜在推广能力，最终导致虚拟知识提取任务的介绍和 VINE 数据集的开发。基于这些实证研究结果，我们进一步提出了 AutoKG，这是一种基于多主体的方法，利用 LLM 进行 KG 的构建和推理，旨在描绘这一领域的未来，并提供令人兴奋的发展机会。我们期望我们的研究能为幼稚园日后的工作提供宝贵的意见。{ https://github.com/zjunlp/autokg 及数据集将可供参考。"
    },
    {
        "title": "Rethinking the Evaluation for Conversational Recommendation in the Era\n  of Large Language Models",
        "url": "http://arxiv.org/abs/2305.13112v1",
        "pub_date": "2023-05-22",
        "summary": "The recent success of large language models (LLMs) has shown great potential\nto develop more powerful conversational recommender systems (CRSs), which rely\non natural language conversations to satisfy user needs. In this paper, we\nembark on an investigation into the utilization of ChatGPT for conversational\nrecommendation, revealing the inadequacy of the existing evaluation protocol.\nIt might over-emphasize the matching with the ground-truth items or utterances\ngenerated by human annotators, while neglecting the interactive nature of being\na capable CRS. To overcome the limitation, we further propose an interactive\nEvaluation approach based on LLMs named iEvaLM that harnesses LLM-based user\nsimulators. Our evaluation approach can simulate various interaction scenarios\nbetween users and systems. Through the experiments on two publicly available\nCRS datasets, we demonstrate notable improvements compared to the prevailing\nevaluation protocol. Furthermore, we emphasize the evaluation of\nexplainability, and ChatGPT showcases persuasive explanation generation for its\nrecommendations. Our study contributes to a deeper comprehension of the\nuntapped potential of LLMs for CRSs and provides a more flexible and\neasy-to-use evaluation framework for future research endeavors. The codes and\ndata are publicly available at https://github.com/RUCAIBox/iEvaLM-CRS.",
        "translated": "大型语言模型(LLM)最近的成功显示了开发更强大的会话推荐系统(CRS)的巨大潜力，CRS 依赖于自然语言会话来满足用户的需求。本文对 ChatGPT 在会话推荐中的应用进行了研究，揭示了现有评价协议的不足之处。它可能过分强调与地面真相项目或人类注释者产生的话语的匹配，而忽视了作为一个有能力的 CRS 的互动性质。为了克服这一局限性，我们进一步提出了一种基于 LLM 的交互式评估方法 iEvaLM，该方法利用了基于 LLM 的用户模拟器。我们的评估方法可以模拟用户和系统之间的各种交互场景。通过对两个公开可用的 CRS 数据集的实验，我们发现与现行的评估协议相比有显著的改进。此外，我们强调可解释性的评价，ChatGPT 展示了其建议的说服性解释生成。我们的研究有助于更深入地了解 LLM 在 CRS 中尚未开发的潜力，并为未来的研究工作提供了一个更加灵活和易于使用的评估框架。这些代码和数据可以在 https://github.com/rucaibox/ievalm-crs 上公开获得。"
    },
    {
        "title": "Making Language Models Better Tool Learners with Execution Feedback",
        "url": "http://arxiv.org/abs/2305.13068v1",
        "pub_date": "2023-05-22",
        "summary": "Tools serve as pivotal interfaces that enable humans to understand and\nreshape the world. With the advent of foundational models, AI systems can\nutilize tools to expand their capabilities and interact with the world.\nExisting tool learning methodologies, encompassing supervised fine-tuning and\nprompt engineering approaches, often induce language models to utilize tools\nindiscriminately, as complex problems often exceed their own competencies.\nHowever, introducing tools for simple tasks, which the models themselves can\nreadily resolve, can inadvertently propagate errors rather than enhance\nperformance. This leads to the research question: can we teach language models\nwhen and how to use tools? To meet this need, we propose Tool leaRning wIth\nexeCution fEedback (TRICE), a two-stage end-to-end framework that enables the\nmodel to continually learn through feedback derived from tool execution,\nthereby learning when and how to use tools effectively. Experimental results,\nbacked by further analysis, show that TRICE can make the language model to\nselectively use tools by decreasing the model's dependency on tools while\nenhancing the performance. Code and datasets will be available in\nhttps://github.com/zjunlp/trice.",
        "translated": "工具作为关键的接口，使人类能够理解和重塑世界。随着基础模型的出现，人工智能系统可以利用工具来扩展它们的能力，并与世界互动。现有的工具学习方法，包括有监督的微调和及时的工程方法，经常诱导语言模型不加区分地使用工具，因为复杂的问题往往超出了它们自己的能力。然而，引入用于简单任务的工具(模型本身可以很容易地解决这些任务)可能会在无意中传播错误，而不是提高性能。这就引出了一个研究问题: 我们可以教语言模型何时以及如何使用工具吗？为了满足这一需求，我们提出工具学习与执行反馈(TRICE) ，一个两阶段的端到端框架，使模型能够通过反馈不断学习从工具执行，从而学习何时和如何有效地使用工具。实验结果表明，TRICE 能够使语言模型有选择地使用工具，降低模型对工具的依赖性，同时提高语言的性能。代码和数据集将以 https://github.com/zjunlp/trice 形式提供。"
    },
    {
        "title": "Evaluating and Enhancing Structural Understanding Capabilities of Large\n  Language Models on Tables via Input Designs",
        "url": "http://arxiv.org/abs/2305.13062v1",
        "pub_date": "2023-05-22",
        "summary": "Large language models (LLMs) are becoming attractive as few-shot reasoners to\nsolve NL-related tasks. However, there is still much to be learned about how\nwell LLMs understand structured data, such as tables. While it is true that\ntables can be used as inputs to LLMs with serialization, there lack\ncomprehensive studies examining whether LLMs can truly comprehend such data. In\nthis paper we try to understand this by designing a benchmark to evaluate\nstructural understanding capabilities (SUC) of LLMs. The benchmark we create\nincludes seven tasks, each with their own unique challenges, e.g,, cell lookup,\nrow retrieval and size detection. We run a series of evaluations on GPT-3\nfamily models (e.g., text-davinci-003). We discover that the performance varied\ndepending on a number of input choices, including table input format, content\norder, role prompting and partition marks. Drawing from the insights gained\nthrough the benchmark evaluations, we then propose self-augmentation for\neffective structural prompting, e.g., critical value / range identification\nusing LLMs' internal knowledge. When combined with carefully chosen input\nchoices, these structural prompting methods lead to promising improvements in\nLLM performance on a variety of tabular tasks, e.g., TabFact($\\uparrow2.31\\%$),\nHybridQA($\\uparrow2.13\\%$), SQA($\\uparrow2.72\\%$), Feverous($\\uparrow0.84\\%$),\nand ToTTo($\\uparrow5.68\\%$). We believe our benchmark and proposed prompting\nmethods can serve as a simple yet generic selection for future research. The\ncode and data are released in\nhttps://anonymous.4open.science/r/StructuredLLM-76F3.",
        "translated": "大型语言模型(LLM)作为解决大型语言相关任务的少量推理工具正变得越来越有吸引力。然而，关于 LLM 如何很好地理解结构化数据(如表) ，还有很多东西需要学习。虽然表确实可以用作具有序列化的 LLM 的输入，但是缺乏全面的研究来检查 LLM 是否能够真正理解这些数据。在本文中，我们试图通过设计一个基准来评估 LLM 的结构理解能力(SUC)来理解这一点。我们创建的基准测试包括七个任务，每个任务都有其独特的挑战，例如，单元格查找、行检索和大小检测。我们对 GPT-3家族模型(例如 text-davinci-003)进行了一系列的评估。我们发现，性能取决于许多输入选择，包括表输入格式、内容顺序、角色提示和分区标记。根据基准评估所获得的见解，我们提出自我增强的有效结构激励，例如，利用 LLM 的内部知识识识别临界值/范围。当结合精心选择的输入选择时，这些结构化的提示方法导致了各种表格任务的 LLM 性能的有希望的改善，例如 TabFact ($uparrow2.31% $) ，HybridQA ($uparrow2.13% $) ，SQA ($uparrow2.72% $) ，Feverous ($uparrow0.84% $)和 ToTTo ($uparrow5.68% $)。我们相信，我们的基准和提议的激励方法可以作为一个简单而通用的选择，为未来的研究。代码和数据以 https://anonymous.4open.science/r/structuredllm-76f3的形式发布。"
    },
    {
        "title": "Attentive Graph-based Text-aware Preference Modeling for Top-N\n  Recommendation",
        "url": "http://arxiv.org/abs/2305.12976v1",
        "pub_date": "2023-05-22",
        "summary": "Textual data are commonly used as auxiliary information for modeling user\npreference nowadays. While many prior works utilize user reviews for rating\nprediction, few focus on top-N recommendation, and even few try to incorporate\nitem textual contents such as title and description. Though delivering\npromising performance for rating prediction, we empirically find that many\nreview-based models cannot perform comparably well on top-N recommendation.\nAlso, user reviews are not available in some recommendation scenarios, while\nitem textual contents are more prevalent. On the other hand, recent graph\nconvolutional network (GCN) based models demonstrate state-of-the-art\nperformance for top-N recommendation. Thus, in this work, we aim to further\nimprove top-N recommendation by effectively modeling both item textual content\nand high-order connectivity in user-item graph. We propose a new model named\nAttentive Graph-based Text-aware Recommendation Model (AGTM). Extensive\nexperiments are provided to justify the rationality and effectiveness of our\nmodel design.",
        "translated": "文本数据是当今建立用户偏好模型的常用辅助信息。虽然许多以前的作品利用用户评论进行评分预测，但很少关注前 N 名的推荐，甚至很少尝试合并项目文本内容，如标题和描述。通过实证研究，我们发现许多基于评论的模型在排名前 N 的推荐中表现不佳。此外，在某些推荐场景中，用户评论是不可用的，而项目文本内容更为普遍。另一方面，最近基于图卷积网络(GCN)的模型展示了最高 N 推荐的最新性能。因此，在本研究中，我们的目标是通过有效地建立用户项目图中项目文本内容和高阶连通性的模型，进一步改善最高 N 推荐。提出了一种基于注意图的文本感知推荐模型(AGTM)。通过大量实验验证了模型设计的合理性和有效性。"
    },
    {
        "title": "It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for\n  Recommendation",
        "url": "http://arxiv.org/abs/2305.12922v1",
        "pub_date": "2023-05-22",
        "summary": "Linear autoencoder models learn an item-to-item weight matrix via convex\noptimization with L2 regularization and zero-diagonal constraints. Despite\ntheir simplicity, they have shown remarkable performance compared to\nsophisticated non-linear models. This paper aims to theoretically understand\nthe properties of two terms in linear autoencoders. Through the lens of\nsingular value decomposition (SVD) and principal component analysis (PCA), it\nis revealed that L2 regularization enhances the impact of high-ranked PCs.\nMeanwhile, zero-diagonal constraints reduce the impact of low-ranked PCs,\nleading to performance degradation for unpopular items. Inspired by this\nanalysis, we propose simple-yet-effective linear autoencoder models using\ndiagonal inequality constraints, called Relaxed Linear AutoEncoder (RLAE) and\nRelaxed Denoising Linear AutoEncoder (RDLAE). We prove that they generalize\nlinear autoencoders by adjusting the degree of diagonal constraints.\nExperimental results demonstrate that our models are comparable or superior to\nstate-of-the-art linear and non-linear models on six benchmark datasets; they\nsignificantly improve the accuracy of long-tail items. These results also\nsupport our theoretical insights on regularization and diagonal constraints in\nlinear autoencoders.",
        "translated": "线性自动编码器模型通过 L2正则化和零对角约束的凸优化学习一个项目对项目的权重矩阵。尽管它们很简单，但与复杂的非线性模型相比，它们表现出了显著的性能。本文旨在从理论上理解线性自动编码器中两项的性质。通过奇异值分解(SVD)和主成分分析(PCA)透镜，我们发现二语正规化增强了高等级个人电脑的影响。与此同时，零对角线约束减少了低排名个人电脑的影响，导致不受欢迎项目的性能下降。受此分析的启发，我们提出了使用对角不等式约束的简单而有效的线性自动编码器模型，称为松弛线性自动编码器(RLAE)和松弛去噪线性自动编码器(RDLAE)。我们证明了它们通过调整对角线约束的程度来推广线性自动编码器。实验结果表明，在六个基准数据集上，我们的模型与最先进的线性和非线性模型具有可比性或优越性，它们显著提高了长尾项目的准确性。这些结果也支持我们对线性自动编码器的正则化和对角线约束的理论认识。"
    },
    {
        "title": "Anchor Prediction: Automatic Refinement of Internet Links",
        "url": "http://arxiv.org/abs/2305.14337v1",
        "pub_date": "2023-05-23",
        "summary": "Internet links enable users to deepen their understanding of a topic by\nproviding convenient access to related information. However, the majority of\nlinks are unanchored -- they link to a target webpage as a whole, and readers\nmay expend considerable effort localizing the specific parts of the target\nwebpage that enrich their understanding of the link's source context. To help\nreaders effectively find information in linked webpages, we introduce the task\nof anchor prediction, where the goal is to identify the specific part of the\nlinked target webpage that is most related to the source linking context. We\nrelease the AuthorAnchors dataset, a collection of 34K naturally-occurring\nanchored links, which reflect relevance judgments by the authors of the source\narticle. To model reader relevance judgments, we annotate and release\nReaderAnchors, an evaluation set of anchors that readers find useful. Our\nanalysis shows that effective anchor prediction often requires jointly\nreasoning over lengthy source and target webpages to determine their implicit\nrelations and identify parts of the target webpage that are related but not\nredundant. We benchmark a performant T5-based ranking approach to establish\nbaseline performance on the task, finding ample room for improvement.",
        "translated": ""
    },
    {
        "title": "VIP5: Towards Multimodal Foundation Models for Recommendation",
        "url": "http://arxiv.org/abs/2305.14302v1",
        "pub_date": "2023-05-23",
        "summary": "Computer Vision (CV), Natural Language Processing (NLP), and Recommender\nSystems (RecSys) are three prominent AI applications that have traditionally\ndeveloped independently, resulting in disparate modeling and engineering\nmethodologies. This has impeded the ability for these fields to directly\nbenefit from each other's advancements. With the increasing availability of\nmultimodal data on the web, there is a growing need to consider various\nmodalities when making recommendations for users. With the recent emergence of\nfoundation models, large language models have emerged as a potential\ngeneral-purpose interface for unifying different modalities and problem\nformulations. In light of this, we propose the development of a multimodal\nfoundation model by considering both visual and textual modalities under the P5\nrecommendation paradigm (VIP5) to unify various modalities and recommendation\ntasks. This will enable the processing of vision, language, and personalization\ninformation in a shared architecture for improved recommendations. To achieve\nthis, we introduce multimodal personalized prompts to accommodate multiple\nmodalities under a shared format. Additionally, we propose a\nparameter-efficient training method for foundation models, which involves\nfreezing the backbone and fine-tuning lightweight adapters, resulting in\nimproved recommendation performance and increased efficiency in terms of\ntraining time and memory usage.",
        "translated": ""
    },
    {
        "title": "Simulating News Recommendation Ecosystem for Fun and Profit",
        "url": "http://arxiv.org/abs/2305.14103v1",
        "pub_date": "2023-05-23",
        "summary": "Understanding the evolution of online news communities is essential for\ndesigning more effective news recommender systems. However, due to the lack of\nappropriate datasets and platforms, the existing literature is limited in\nunderstanding the impact of recommender systems on this evolutionary process\nand the underlying mechanisms, resulting in sub-optimal system designs that may\naffect long-term utilities. In this work, we propose SimuLine, a simulation\nplatform to dissect the evolution of news recommendation ecosystems and present\na detailed analysis of the evolutionary process and underlying mechanisms.\nSimuLine first constructs a latent space well reflecting the human behaviors,\nand then simulates the news recommendation ecosystem via agent-based modeling.\nBased on extensive simulation experiments and the comprehensive analysis\nframework consisting of quantitative metrics, visualization, and textual\nexplanations, we analyze the characteristics of each evolutionary phase from\nthe perspective of life-cycle theory, and propose a relationship graph\nillustrating the key factors and affecting mechanisms. Furthermore, we explore\nthe impacts of recommender system designing strategies, including the\nutilization of cold-start news, breaking news, and promotion, on the\nevolutionary process, which shed new light on the design of recommender\nsystems.",
        "translated": ""
    },
    {
        "title": "BM25 Query Augmentation Learned End-to-End",
        "url": "http://arxiv.org/abs/2305.14087v1",
        "pub_date": "2023-05-23",
        "summary": "Given BM25's enduring competitiveness as an information retrieval baseline,\nwe investigate to what extent it can be even further improved by augmenting and\nre-weighting its sparse query-vector representation. We propose an approach to\nlearning an augmentation and a re-weighting end-to-end, and we find that our\napproach improves performance over BM25 while retaining its speed. We\nfurthermore find that the learned augmentations and re-weightings transfer well\nto unseen datasets.",
        "translated": ""
    },
    {
        "title": "Message Intercommunication for Inductive Relation Reasoning",
        "url": "http://arxiv.org/abs/2305.14074v1",
        "pub_date": "2023-05-23",
        "summary": "Inductive relation reasoning for knowledge graphs, aiming to infer missing\nlinks between brand-new entities, has drawn increasing attention. The models\ndeveloped based on Graph Inductive Learning, called GraIL-based models, have\nshown promising potential for this task. However, the uni-directional\nmessage-passing mechanism hinders such models from exploiting hidden mutual\nrelations between entities in directed graphs. Besides, the enclosing subgraph\nextraction in most GraIL-based models restricts the model from extracting\nenough discriminative information for reasoning. Consequently, the expressive\nability of these models is limited. To address the problems, we propose a novel\nGraIL-based inductive relation reasoning model, termed MINES, by introducing a\nMessage Intercommunication mechanism on the Neighbor-Enhanced Subgraph.\nConcretely, the message intercommunication mechanism is designed to capture the\nomitted hidden mutual information. It introduces bi-directed information\ninteractions between connected entities by inserting an undirected/bi-directed\nGCN layer between uni-directed RGCN layers. Moreover, inspired by the success\nof involving more neighbors in other graph-based tasks, we extend the\nneighborhood area beyond the enclosing subgraph to enhance the information\ncollection for inductive relation reasoning. Extensive experiments on twelve\ninductive benchmark datasets demonstrate that our MINES outperforms existing\nstate-of-the-art models, and show the effectiveness of our intercommunication\nmechanism and reasoning on the neighbor-enhanced subgraph.",
        "translated": ""
    },
    {
        "title": "When the Music Stops: Tip-of-the-Tongue Retrieval for Music",
        "url": "http://arxiv.org/abs/2305.14072v1",
        "pub_date": "2023-05-23",
        "summary": "We present a study of Tip-of-the-tongue (ToT) retrieval for music, where a\nsearcher is trying to find an existing music entity, but is unable to succeed\nas they cannot accurately recall important identifying information. ToT\ninformation needs are characterized by complexity, verbosity, uncertainty, and\npossible false memories. We make four contributions. (1) We collect a dataset -\n$ToT_{Music}$ - of 2,278 information needs and ground truth answers. (2) We\nintroduce a schema for these information needs and show that they often involve\nmultiple modalities encompassing several Music IR subtasks such as lyric\nsearch, audio-based search, audio fingerprinting, and text search. (3) We\nunderscore the difficulty of this task by benchmarking a standard text\nretrieval approach on this dataset. (4) We investigate the efficacy of query\nreformulations generated by a large language model (LLM), and show that they\nare not as effective as simply employing the entire information need as a query\n- leaving several open questions for future research.",
        "translated": ""
    },
    {
        "title": "DAPR: A Benchmark on Document-Aware Passage Retrieval",
        "url": "http://arxiv.org/abs/2305.13915v1",
        "pub_date": "2023-05-23",
        "summary": "Recent neural retrieval mainly focuses on ranking short texts and is\nchallenged with long documents. Existing work mainly evaluates either ranking\npassages or whole documents. However, there are many cases where the users want\nto find a relevant passage within a long document from a huge corpus, e.g.\nlegal cases, research papers, etc. In this scenario, the passage often provides\nlittle document context and thus challenges the current approaches to finding\nthe correct document and returning accurate results. To fill this gap, we\npropose and name this task Document-Aware Passage Retrieval (DAPR) and build a\nbenchmark including multiple datasets from various domains, covering both DAPR\nand whole-document retrieval. In experiments, we extend the state-of-the-art\nneural passage retrievers with document-level context via different approaches\nincluding prepending document summary, pooling over passage representations,\nand hybrid retrieval with BM25. The hybrid-retrieval systems, the overall best,\ncan only improve on the DAPR tasks marginally while significantly improving on\nthe document-retrieval tasks. This motivates further research in developing\nbetter retrieval systems for the new task. The code and the data are available\nat https://github.com/kwang2049/dapr",
        "translated": ""
    },
    {
        "title": "Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search\n  Engines",
        "url": "http://arxiv.org/abs/2305.13859v1",
        "pub_date": "2023-05-23",
        "summary": "Auto-regressive search engines emerge as a promising paradigm for next-gen\ninformation retrieval systems. These methods work with Seq2Seq models, where\neach query can be directly mapped to the identifier of its relevant document.\nAs such, they are praised for merits like being end-to-end differentiable.\nHowever, auto-regressive search engines also confront challenges in retrieval\nquality, given the requirement for the exact generation of the document\nidentifier. That's to say, the targeted document will be missed from the\nretrieval result if a false prediction about its identifier is made in any step\nof the generation process. In this work, we propose a novel framework, namely\nAutoTSG (Auto-regressive Search Engine with Term-Set Generation), which is\nfeatured by 1) the unordered term-based document identifier and 2) the\nset-oriented generation pipeline. With AutoTSG, any permutation of the term-set\nidentifier will lead to the retrieval of the corresponding document, thus\nlargely relaxing the requirement of exact generation. Besides, the Seq2Seq\nmodel is enabled to flexibly explore the optimal permutation of the document\nidentifier for the presented query, which may further contribute to the\nretrieval quality. AutoTSG is empirically evaluated with Natural Questions and\nMS MARCO, where notable improvements can be achieved against the existing\nauto-regressive search engines.",
        "translated": ""
    },
    {
        "title": "Advances and Challenges of Multi-task Learning Method in Recommender\n  System: A Survey",
        "url": "http://arxiv.org/abs/2305.13843v1",
        "pub_date": "2023-05-23",
        "summary": "Multi-task learning has been widely applied in computational vision, natural\nlanguage processing and other fields, which has achieved well performance. In\nrecent years, a lot of work about multi-task learning recommender system has\nbeen yielded, but there is no previous literature to summarize these works. To\nbridge this gap, we provide a systematic literature survey about multi-task\nrecommender systems, aiming to help researchers and practitioners quickly\nunderstand the current progress in this direction. In this survey, we first\nintroduce the background and the motivation of the multi-task learning-based\nrecommender systems. Then we provide a taxonomy of multi-task learning-based\nrecommendation methods according to the different stages of multi-task learning\ntechniques, which including task relationship discovery, model architecture and\noptimization strategy. Finally, we raise discussions on the application and\npromising future directions in this area.",
        "translated": ""
    },
    {
        "title": "Continual Learning on Dynamic Graphs via Parameter Isolation",
        "url": "http://arxiv.org/abs/2305.13825v1",
        "pub_date": "2023-05-23",
        "summary": "Many real-world graph learning tasks require handling dynamic graphs where\nnew nodes and edges emerge. Dynamic graph learning methods commonly suffer from\nthe catastrophic forgetting problem, where knowledge learned for previous\ngraphs is overwritten by updates for new graphs. To alleviate the problem,\ncontinual graph learning methods are proposed. However, existing continual\ngraph learning methods aim to learn new patterns and maintain old ones with the\nsame set of parameters of fixed size, and thus face a fundamental tradeoff\nbetween both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN)\nfor continual learning on dynamic graphs that circumvents the tradeoff via\nparameter isolation and expansion. Our motivation lies in that different\nparameters contribute to learning different graph patterns. Based on the idea,\nwe expand model parameters to continually learn emerging graph patterns.\nMeanwhile, to effectively preserve knowledge for unaffected patterns, we find\nparameters that correspond to them via optimization and freeze them to prevent\nthem from being rewritten. Experiments on eight real-world datasets corroborate\nthe effectiveness of PI-GNN compared to state-of-the-art baselines.",
        "translated": ""
    },
    {
        "title": "NCHO: Unsupervised Learning for Neural 3D Composition of Humans and\n  Objects",
        "url": "http://arxiv.org/abs/2305.14345v1",
        "pub_date": "2023-05-23",
        "summary": "Deep generative models have been recently extended to synthesizing 3D digital\nhumans. However, previous approaches treat clothed humans as a single chunk of\ngeometry without considering the compositionality of clothing and accessories.\nAs a result, individual items cannot be naturally composed into novel\nidentities, leading to limited expressiveness and controllability of generative\n3D avatars. While several methods attempt to address this by leveraging\nsynthetic data, the interaction between humans and objects is not authentic due\nto the domain gap, and manual asset creation is difficult to scale for a wide\nvariety of objects. In this work, we present a novel framework for learning a\ncompositional generative model of humans and objects (backpacks, coats,\nscarves, and more) from real-world 3D scans. Our compositional model is\ninteraction-aware, meaning the spatial relationship between humans and objects,\nand the mutual shape change by physical contact is fully incorporated. The key\nchallenge is that, since humans and objects are in contact, their 3D scans are\nmerged into a single piece. To decompose them without manual annotations, we\npropose to leverage two sets of 3D scans of a single person with and without\nobjects. Our approach learns to decompose objects and naturally compose them\nback into a generative human model in an unsupervised manner. Despite our\nsimple setup requiring only the capture of a single subject with objects, our\nexperiments demonstrate the strong generalization of our model by enabling the\nnatural composition of objects to diverse identities in various poses and the\ncomposition of multiple objects, which is unseen in training data.",
        "translated": "深层生成模型最近已经扩展到合成3D 数字人类。然而，以前的方法没有考虑到衣服和配件的组合性，而是把穿着衣服的人当作一个单一的几何块来对待。因此，个别项目不能自然地组成新的身份，导致有限的表现力和可控性的生成3D 化身。虽然有几种方法试图通过利用合成数据来解决这个问题，但是由于领域间的差距，人与对象之间的交互并不真实，而且手动资产创建难以适用于各种各样的对象。在这项工作中，我们提出了一个新的框架来学习人类和物体(背包，外套，围巾等)的组合生成模型从现实世界的3 d 扫描。我们的构图模型是交互感知的，这意味着人与物体之间的空间关系，以及通过物理接触的相互形状变化被完全纳入。关键的挑战是，因为人类和物体是接触的，他们的3D 扫描合并成一个单一的部分。为了不用手动注释就可以分解它们，我们建议利用一个人的两组3D 扫描，有对象的和没有对象的。我们的方法学会了分解对象，并自然地以无监督的方式将它们重新组合成一个可生成的人类模型。尽管我们的简单设置只需要捕获具有对象的单个主体，但是我们的实验证明了我们的模型的强大泛化，通过使得对象的自然组合以不同姿势的不同身份和多个对象的组合，这在训练数据中是看不到的。"
    },
    {
        "title": "Siamese Masked Autoencoders",
        "url": "http://arxiv.org/abs/2305.14344v1",
        "pub_date": "2023-05-23",
        "summary": "Establishing correspondence between images or scenes is a significant\nchallenge in computer vision, especially given occlusions, viewpoint changes,\nand varying object appearances. In this paper, we present Siamese Masked\nAutoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for\nlearning visual correspondence from videos. SiamMAE operates on pairs of\nrandomly sampled video frames and asymmetrically masks them. These frames are\nprocessed independently by an encoder network, and a decoder composed of a\nsequence of cross-attention layers is tasked with predicting the missing\npatches in the future frame. By masking a large fraction ($95\\%$) of patches in\nthe future frame while leaving the past frame unchanged, SiamMAE encourages the\nnetwork to focus on object motion and learn object-centric representations.\nDespite its conceptual simplicity, features learned via SiamMAE outperform\nstate-of-the-art self-supervised methods on video object segmentation, pose\nkeypoint propagation, and semantic part propagation tasks. SiamMAE achieves\ncompetitive results without relying on data augmentation, handcrafted\ntracking-based pretext tasks, or other techniques to prevent representational\ncollapse.",
        "translated": "建立图像或场景之间的对应关系是计算机视觉中的一个重大挑战，特别是考虑到遮挡、视点变化和不同的物体外观。本文介绍了 Siamese 蒙版自动编码器(SiamMAE) ，它是蒙版自动编码器(MAE)的一个简单扩展，用于从视频中学习视觉对应。SiamMAE 对一对随机采样的视频帧进行操作，并非对称地屏蔽它们。这些帧由编码器网络独立处理，由一系列交叉注意层组成的解码器负责预测未来帧中丢失的补丁。SiamMAE 通过在未来帧中屏蔽大部分补丁(95%) ，同时保持过去帧不变，鼓励网络关注物体运动并学习以物体为中心的表示。尽管概念简单，通过 SiamMAE 学习的特征在视频对象分割、姿态关键点传播和语义部分传播任务方面优于最先进的自监督方法。SiamMAE 无需依赖数据增强、手工制作的基于跟踪的托辞任务或其他技术来防止表象崩溃，就能获得具有竞争力的结果。"
    },
    {
        "title": "Video Prediction Models as Rewards for Reinforcement Learning",
        "url": "http://arxiv.org/abs/2305.14343v1",
        "pub_date": "2023-05-23",
        "summary": "Specifying reward signals that allow agents to learn complex behaviors is a\nlong-standing challenge in reinforcement learning. A promising approach is to\nextract preferences for behaviors from unlabeled videos, which are widely\navailable on the internet. We present Video Prediction Rewards (VIPER), an\nalgorithm that leverages pretrained video prediction models as action-free\nreward signals for reinforcement learning. Specifically, we first train an\nautoregressive transformer on expert videos and then use the video prediction\nlikelihoods as reward signals for a reinforcement learning agent. VIPER enables\nexpert-level control without programmatic task rewards across a wide range of\nDMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction\nmodel allows us to derive rewards for an out-of-distribution environment where\nno expert data is available, enabling cross-embodiment generalization for\ntabletop manipulation. We see our work as starting point for scalable reward\nspecification from unlabeled videos that will benefit from the rapid advances\nin generative modeling. Source code and datasets are available on the project\nwebsite: https://escontrela.me",
        "translated": "指定奖励信号，让代理人学习复杂的行为，是强化学习研究中一个长期存在的挑战。一个有前途的方法是从未标记的视频中提取行为偏好，这些视频在互联网上广泛可用。我们提出了视频预测奖励(VIPER)算法，该算法利用预先训练的视频预测模型作为强化学习的无动作奖励信号。具体来说，我们首先在专家视频上训练一个自回归变换器，然后使用视频预测可能性作为强化学习代理的奖励信号。VIPER 可以实现专家级别的控制，无需程序任务奖励，跨越广泛的 DMC、 Atari 和 RLBench 任务。此外，视频预测模型的推广使我们能够在没有专家数据可用的分布外环境中获得奖励，从而能够对桌面操作进行跨实施例的推广。我们将我们的工作视为从未标记的视频中获得可扩展奖励规范的起点，这些视频将受益于生成建模的快速发展。源代码和数据集可在项目网站下载:  https://escontrela.me"
    },
    {
        "title": "Diffusion Hyperfeatures: Searching Through Time and Space for Semantic\n  Correspondence",
        "url": "http://arxiv.org/abs/2305.14334v1",
        "pub_date": "2023-05-23",
        "summary": "Diffusion models have been shown to be capable of generating high-quality\nimages, suggesting that they could contain meaningful internal representations.\nUnfortunately, the feature maps that encode a diffusion model's internal\ninformation are spread not only over layers of the network, but also over\ndiffusion timesteps, making it challenging to extract useful descriptors. We\npropose Diffusion Hyperfeatures, a framework for consolidating multi-scale and\nmulti-timestep feature maps into per-pixel feature descriptors that can be used\nfor downstream tasks. These descriptors can be extracted for both synthetic and\nreal images using the generation and inversion processes. We evaluate the\nutility of our Diffusion Hyperfeatures on the task of semantic keypoint\ncorrespondence: our method achieves superior performance on the SPair-71k real\nimage benchmark. We also demonstrate that our method is flexible and\ntransferable: our feature aggregation network trained on the inversion features\nof real image pairs can be used on the generation features of synthetic image\npairs with unseen objects and compositions. Our code is available at\n\\url{https://diffusion-hyperfeatures.github.io}.",
        "translated": "扩散模型已被证明能够产生高质量的图像，表明它们可以包含有意义的内部表示。遗憾的是，编码扩散模型内部信息的特征映射不仅分布在网络的各个层上，而且还分布在扩散时间步长上，这使得提取有用的描述符变得非常困难。我们提出了扩散超特征，一个框架，巩固多尺度和多时间步特征映射到每像素特征描述符，可用于下游任务。这些描述符可以提取合成图像和真实图像使用生成和反演过程。我们评估扩散超特征在语义关键点对应任务中的效用: 我们的方法在 SPair-71k 真实图像基准上获得了优越的性能。实验结果表明，该方法具有灵活性和可移植性: 基于实际图像对反演特征的特征聚合网络可以用于具有不可见物体和成分的合成图像对的特征生成。我们的代码可以在 url { https://diffusion-hyperfeatures.github.io }找到。"
    },
    {
        "title": "Prototype Adaption and Projection for Few- and Zero-shot 3D Point Cloud\n  Semantic Segmentation",
        "url": "http://arxiv.org/abs/2305.14335v1",
        "pub_date": "2023-05-23",
        "summary": "In this work, we address the challenging task of few-shot and zero-shot 3D\npoint cloud semantic segmentation. The success of few-shot semantic\nsegmentation in 2D computer vision is mainly driven by the pre-training on\nlarge-scale datasets like imagenet. The feature extractor pre-trained on\nlarge-scale 2D datasets greatly helps the 2D few-shot learning. However, the\ndevelopment of 3D deep learning is hindered by the limited volume and instance\nmodality of datasets due to the significant cost of 3D data collection and\nannotation. This results in less representative features and large intra-class\nfeature variation for few-shot 3D point cloud segmentation. As a consequence,\ndirectly extending existing popular prototypical methods of 2D few-shot\nclassification/segmentation into 3D point cloud segmentation won't work as well\nas in 2D domain. To address this issue, we propose a Query-Guided Prototype\nAdaption (QGPA) module to adapt the prototype from support point clouds feature\nspace to query point clouds feature space. With such prototype adaption, we\ngreatly alleviate the issue of large feature intra-class variation in point\ncloud and significantly improve the performance of few-shot 3D segmentation.\nBesides, to enhance the representation of prototypes, we introduce a\nSelf-Reconstruction (SR) module that enables prototype to reconstruct the\nsupport mask as well as possible. Moreover, we further consider zero-shot 3D\npoint cloud semantic segmentation where there is no support sample. To this\nend, we introduce category words as semantic information and propose a\nsemantic-visual projection model to bridge the semantic and visual spaces. Our\nproposed method surpasses state-of-the-art algorithms by a considerable 7.90%\nand 14.82% under the 2-way 1-shot setting on S3DIS and ScanNet benchmarks,\nrespectively. Code is available at https://github.com/heshuting555/PAP-FZS3D.",
        "translated": "在这项工作中，我们解决了具有挑战性的任务少镜头和零镜头三维点云语义分割。二维计算机视觉中少镜头语义分割的成功主要是由对大规模数据集(如图像网)的预训练所驱动的。在大规模二维数据集上预训练的特征提取器对二维少镜头学习有很大的帮助。然而，由于三维数据的采集和注释成本较高，数据集的体积和实例形式有限，阻碍了三维深度学习的发展。这导致了少镜头三维点云分割的代表性较差的特征和较大的类内特征变化。因此，将现有流行的二维少镜头分类/分割原型方法直接扩展到三维点云分割将不能像在二维领域那样有效。针对这一问题，提出了一种基于查询引导的原型适配(QGPA)模块，将原型从支持点云特征空间调整到查询点云特征空间。采用这种原型自适应方法，大大减轻了点云中特征类内变化大的问题，显著提高了少镜头三维分割的性能。此外，为了提高原型的表示能力，我们引入了自重构(SR)模块，使原型能够尽可能地重构支撑掩模。此外，在没有支持样本的情况下，我们进一步考虑了零拍3D 点云语义分割。为此，我们引入类别词作为语义信息，并提出一个语义-视觉投影模型，以连接语义和视觉空间。在 S3DIS 和 ScanNet 基准的双向单镜头设置下，我们提出的方法分别以7.90% 和14.82% 的优势超越了最先进的算法。密码可于 https://github.com/heshuting555/pap-fzs3d 索取。"
    },
    {
        "title": "Large Language Models are Frame-level Directors for Zero-shot\n  Text-to-Video Generation",
        "url": "http://arxiv.org/abs/2305.14330v1",
        "pub_date": "2023-05-23",
        "summary": "In the paradigm of AI-generated content (AIGC), there has been increasing\nattention in extending pre-trained text-to-image (T2I) models to text-to-video\n(T2V) generation. Despite their effectiveness, these frameworks face challenges\nin maintaining consistent narratives and handling rapid shifts in scene\ncomposition or object placement from a single user prompt. This paper\nintroduces a new framework, dubbed DirecT2V, which leverages instruction-tuned\nlarge language models (LLMs) to generate frame-by-frame descriptions from a\nsingle abstract user prompt. DirecT2V utilizes LLM directors to divide user\ninputs into separate prompts for each frame, enabling the inclusion of\ntime-varying content and facilitating consistent video generation. To maintain\ntemporal consistency and prevent object collapse, we propose a novel value\nmapping method and dual-softmax filtering. Extensive experimental results\nvalidate the effectiveness of the DirecT2V framework in producing visually\ncoherent and consistent videos from abstract user prompts, addressing the\nchallenges of zero-shot video generation.",
        "translated": "在人工智能生成内容(AIGC)的范式中，将预先训练好的文本到图像(T2I)模型扩展到文本到视频(T2V)生成已经受到越来越多的关注。尽管这些框架很有效，但它们在保持一致的叙述和处理来自单一用户提示的场景构成或物体放置的快速变化方面面临挑战。本文介绍了一个名为 DirecT2V 的新框架，它利用指令调优的大型语言模型(LLM)从单个抽象用户提示符生成一帧一帧的描述。DirecT2V 利用 LLM 控制器将用户输入划分为每个帧的单独提示，从而能够包含时变内容并促进一致的视频生成。为了保持时间一致性和防止对象崩溃，提出了一种新的值映射方法和双软极大值滤波。广泛的实验结果验证了 DirecT2V 框架在从抽象用户提示生成视觉一致性和一致性视频方面的有效性，解决了零拍摄视频生成的挑战。"
    },
    {
        "title": "Improving Factuality and Reasoning in Language Models through Multiagent\n  Debate",
        "url": "http://arxiv.org/abs/2305.14325v1",
        "pub_date": "2023-05-23",
        "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nlanguage generation, understanding, and few-shot learning in recent years. An\nextensive body of work has explored how their performance may be further\nimproved through the tools of prompting, ranging from verification,\nself-consistency, or intermediate scratchpads. In this paper, we present a\ncomplementary approach to improve language responses where multiple language\nmodel instances propose and debate their individual responses and reasoning\nprocesses over multiple rounds to arrive at a common final answer. Our findings\nindicate that this approach significantly enhances mathematical and strategic\nreasoning across a number of tasks. We also demonstrate that our approach\nimproves the factual validity of generated content, reducing fallacious answers\nand hallucinations that contemporary models are prone to. Our approach may be\ndirectly applied to existing black-box models and uses identical procedure and\nprompts for all tasks we investigate. Overall, our findings suggest that such\n\"society of minds\" approach has the potential to significantly advance the\ncapabilities of LLMs and pave the way for further breakthroughs in language\ngeneration and understanding.",
        "translated": "近年来，大语言模型(LLM)在语言生成、理解和短镜头学习等方面表现出了显著的能力。大量的工作已经探索了如何通过提示工具进一步提高他们的性能，从验证，自我一致性，或中间的暂存器。在本文中，我们提出了一个互补的方法来改善语言反应，其中多个语言模型实例提出和辩论他们的个别反应和推理过程，多轮得出一个共同的最终答案。我们的研究结果表明，这种方法显着提高了数学和战略推理的一些任务。我们还证明，我们的方法提高了生成内容的实际有效性，减少了当代模型容易产生的谬误答案和幻觉。我们的方法可以直接应用于现有的黑盒模型，并对我们调查的所有任务使用相同的过程和提示。总的来说，我们的研究结果表明，这种“心灵社会”的方法有潜力显着提高语言学习者的能力，并为语言生成和理解的进一步突破铺平道路。"
    },
    {
        "title": "Text-guided 3D Human Generation from 2D Collections",
        "url": "http://arxiv.org/abs/2305.14312v1",
        "pub_date": "2023-05-23",
        "summary": "3D human modeling has been widely used for engaging interaction in gaming,\nfilm, and animation. The customization of these characters is crucial for\ncreativity and scalability, which highlights the importance of controllability.\nIn this work, we introduce Text-guided 3D Human Generation (\\texttt{T3H}),\nwhere a model is to generate a 3D human, guided by the fashion description.\nThere are two goals: 1) the 3D human should render articulately, and 2) its\noutfit is controlled by the given text. To address this \\texttt{T3H} task, we\npropose Compositional Cross-modal Human (CCH). CCH adopts cross-modal attention\nto fuse compositional human rendering with the extracted fashion semantics.\nEach human body part perceives relevant textual guidance as its visual\npatterns. We incorporate the human prior and semantic discrimination to enhance\n3D geometry transformation and fine-grained consistency, enabling it to learn\nfrom 2D collections for data efficiency. We conduct evaluations on DeepFashion\nand SHHQ with diverse fashion attributes covering the shape, fabric, and color\nof upper and lower clothing. Extensive experiments demonstrate that CCH\nachieves superior results for \\texttt{T3H} with high efficiency.",
        "translated": "3D 人体建模已经广泛应用于游戏、电影和动画中的交互。这些字符的定制对于创造性和可扩展性至关重要，这突出了可控性的重要性。在这项工作中，我们介绍了文本引导的三维人类生成(texttt { T3H }) ，其中一个模型是生成一个三维人，在时尚描述的指导下。有两个目标: 1)3D 人应该清晰地渲染，2)它的装备是由给定的文本控制。为了解决这个文本{ T3H }任务，我们提出了组合跨模态人(CCH)。CCH 采用交叉模态注意将提取的时尚语义融合到组合人体绘制中。人体的每个部分都将相关的文本指导视为其视觉模式。我们结合了人类先验和语义识别，以增强三维几何变换和细粒度的一致性，使其能够学习从2D 集合的数据效率。我们对 DeepFashion 和 SHHQ 进行评估，它们具有多种时尚属性，包括上衣和下衣的形状、面料和颜色。大量的实验表明，CCH 对 texttt { T3H }具有较高的效率，取得了较好的效果。"
    },
    {
        "title": "Hierarchical Adaptive Voxel-guided Sampling for Real-time Applications\n  in Large-scale Point Clouds",
        "url": "http://arxiv.org/abs/2305.14306v1",
        "pub_date": "2023-05-23",
        "summary": "While point-based neural architectures have demonstrated their efficacy, the\ntime-consuming sampler currently prevents them from performing real-time\nreasoning on scene-level point clouds. Existing methods attempt to overcome\nthis issue by using random sampling strategy instead of the commonly-adopted\nfarthest point sampling~(FPS), but at the expense of lower performance. So the\neffectiveness/efficiency trade-off remains under-explored. In this paper, we\nreveal the key to high-quality sampling is ensuring an even spacing between\npoints in the subset, which can be naturally obtained through a grid. Based on\nthis insight, we propose a hierarchical adaptive voxel-guided point sampler\nwith linear complexity and high parallelization for real-time applications.\nExtensive experiments on large-scale point cloud detection and segmentation\ntasks demonstrate that our method achieves competitive performance with the\nmost powerful FPS, at an amazing speed that is more than 100 times faster. This\nbreakthrough in efficiency addresses the bottleneck of the sampling step when\nhandling scene-level point clouds. Furthermore, our sampler can be easily\nintegrated into existing models and achieves a 20$\\sim$80\\% reduction in\nruntime with minimal effort. The code will be available at\nhttps://github.com/OuyangJunyuan/pointcloud-3d-detector-tensorrt",
        "translated": "虽然基于点的神经结构已经证明了它们的功效，但耗时的采样器目前阻止它们对场景级别的点云进行实时推理。现有的方法试图用随机抽样策略代替常用的最远点抽样，但是以牺牲较低的性能为代价来克服这一问题。因此，有效性/效率之间的权衡仍未得到充分探讨。在本文中，我们揭示了高质量采样的关键是确保子集中点之间的均匀间距，这可以通过网格自然获得。在此基础上，我们提出了一种分层自适应体素引导的点采样器，它具有线性复杂度和高并行性，适用于实时应用。大规模点云检测和分割任务的大量实验表明，我们的方法实现了与最强大的 FPS 具有竞争力的性能，以惊人的速度，超过100倍的速度。这一效率上的突破解决了处理场景级点云时采样步骤的瓶颈。此外，我们的采样器可以很容易地集成到现有的模型，并实现20美元西姆 $80% 的运行时减少最小的努力。代码将在 https://github.com/ouyangjunyuan/pointcloud-3d-detector-tensorrt 公布"
    },
    {
        "title": "A Laplacian Pyramid Based Generative H&amp;E Stain Augmentation Network",
        "url": "http://arxiv.org/abs/2305.14301v1",
        "pub_date": "2023-05-23",
        "summary": "Hematoxylin and Eosin (H&amp;E) staining is a widely used sample preparation\nprocedure for enhancing the saturation of tissue sections and the contrast\nbetween nuclei and cytoplasm in histology images for medical diagnostics.\nHowever, various factors, such as the differences in the reagents used, result\nin high variability in the colors of the stains actually recorded. This\nvariability poses a challenge in achieving generalization for machine-learning\nbased computer-aided diagnostic tools. To desensitize the learned models to\nstain variations, we propose the Generative Stain Augmentation Network (G-SAN)\n-- a GAN-based framework that augments a collection of cell images with\nsimulated yet realistic stain variations. At its core, G-SAN uses a novel and\nhighly computationally efficient Laplacian Pyramid (LP) based generator\narchitecture, that is capable of disentangling stain from cell morphology.\nThrough the task of patch classification and nucleus segmentation, we show that\nusing G-SAN-augmented training data provides on average 15.7% improvement in F1\nscore and 7.3% improvement in panoptic quality, respectively. Our code is\navailable at https://github.com/lifangda01/GSAN-Demo.",
        "translated": "苏木精-伊红(H & E)染色是一种广泛应用的提高组织切片饱和度和增强组织学图像中细胞核和细胞质对比度的样品制备方法。然而，各种因素，例如使用的试剂的差异，导致实际记录的污渍颜色的高度可变性。这种可变性对基于机器学习的计算机辅助诊断工具的普及提出了挑战。为了使学习的模型对染色变化不敏感，我们提出生成染色增强网络(G-SAN)——一种基于 GAN 的框架，用模拟但真实的染色变化增强细胞图像集合。在其核心，G-SAN 使用了一种新的和高度计算效率的拉普拉斯金字塔(LP)为基础的生成器架构，这是能够从细胞形态学分离染色。通过斑块分类和细胞核分割实验，我们发现使用 G-SAN 增强训练数据，F1评分平均提高15.7% ，视觉质量平均提高7.3% 。我们的代码可以在 https://github.com/lifangda01/gsan-demo 找到。"
    },
    {
        "title": "Balancing the Picture: Debiasing Vision-Language Datasets with Synthetic\n  Contrast Sets",
        "url": "http://arxiv.org/abs/2305.15407v1",
        "pub_date": "2023-05-24",
        "summary": "Vision-language models are growing in popularity and public visibility to\ngenerate, edit, and caption images at scale; but their outputs can perpetuate\nand amplify societal biases learned during pre-training on uncurated image-text\npairs from the internet. Although debiasing methods have been proposed, we\nargue that these measurements of model bias lack validity due to dataset bias.\nWe demonstrate there are spurious correlations in COCO Captions, the most\ncommonly used dataset for evaluating bias, between background context and the\ngender of people in-situ. This is problematic because commonly-used bias\nmetrics (such as Bias@K) rely on per-gender base rates. To address this issue,\nwe propose a novel dataset debiasing pipeline to augment the COCO dataset with\nsynthetic, gender-balanced contrast sets, where only the gender of the subject\nis edited and the background is fixed. However, existing image editing methods\nhave limitations and sometimes produce low-quality images; so, we introduce a\nmethod to automatically filter the generated images based on their similarity\nto real images. Using our balanced synthetic contrast sets, we benchmark bias\nin multiple CLIP-based models, demonstrating how metrics are skewed by\nimbalance in the original COCO images. Our results indicate that the proposed\napproach improves the validity of the evaluation, ultimately contributing to\nmore realistic understanding of bias in vision-language models.",
        "translated": "视觉语言模型在大规模生成、编辑和标题图像方面越来越受欢迎和公众可见度越来越高; 但是它们的输出可以延续和放大在互联网上未经策划的图像-文本对的预培训中学到的社会偏见。虽然已经提出了消除偏差的方法，但是我们认为由于数据集的偏差，这些模型偏差的测量缺乏有效性。我们证明在 COCO 标题中存在虚假的相关性，COCO 标题是最常用于评估偏倚的数据集，背景环境和现场人员的性别之间存在虚假的相关性。这是有问题的，因为常用的偏见指标(如偏见@K)依赖于每个性别的基础比率。为了解决这一问题，我们提出了一种新的数据集去偏流水线，以增加合成的，性别平衡的对比集 COCO 数据集，其中只编辑主题的性别和背景是固定的。然而，现有的图像编辑方法存在一定的局限性，有时会产生低质量的图像，因此，我们提出了一种基于图像与真实图像相似度的自动过滤方法。使用我们的平衡合成对比度集，我们在多个基于 CLIP 的模型基准偏差，演示了如何在原始 COCO 图像的不平衡度量偏斜。我们的研究结果表明，提出的方法提高了评价的有效性，最终有助于更现实的理解偏见的视觉语言模型。"
    },
    {
        "title": "RoMa: Revisiting Robust Losses for Dense Feature Matching",
        "url": "http://arxiv.org/abs/2305.15404v1",
        "pub_date": "2023-05-24",
        "summary": "Dense feature matching is an important computer vision task that involves\nestimating all correspondences between two images of a 3D scene. In this paper,\nwe revisit robust losses for matching from a Markov chain perspective, yielding\ntheoretical insights and large gains in performance. We begin by constructing a\nunifying formulation of matching as a Markov chain, based on which we identify\ntwo key stages which we argue should be decoupled for matching. The first is\nthe coarse stage, where the estimated result needs to be globally consistent.\nThe second is the refinement stage, where the model needs precise localization\ncapabilities. Inspired by the insight that these stages concern distinct\nissues, we propose a coarse matcher following the regression-by-classification\nparadigm that provides excellent globally consistent, albeit not exactly\nlocalized, matches. This is followed by a local feature refinement stage using\nwell-motivated robust regression losses, yielding extremely precise matches.\nOur proposed approach, which we call RoMa, achieves significant improvements\ncompared to the state-of-the-art. Code is available at\nhttps://github.com/Parskatt/RoMa",
        "translated": "密集特征匹配是一项重要的计算机视觉任务，它涉及到估计三维场景中两幅图像之间的所有对应关系。在本文中，我们从马尔可夫链的角度重新审视匹配的鲁棒性损失，产生理论见解和性能的大幅提高。我们首先构造一个统一的匹配公式作为一个马尔可夫链，在此基础上，我们确定了两个关键的阶段，我们认为应该解耦匹配。第一个阶段是粗略阶段，其中估计的结果需要具有全局一致性。第二个阶段是精化阶段，在这个阶段模型需要精确的定位能力。受到这些阶段关注不同问题的洞察力的启发，我们提出了遵循分类回归范式的粗匹配器，它提供了优秀的全局一致性匹配，尽管不是完全本地化的匹配。然后是局部特征细化阶段，使用动机良好的鲁棒回归损失，产生非常精确的匹配。我们提出的方法，我们称之为 RoMa，与最先进的技术相比，取得了显著的改进。密码可于 https://github.com/parskatt/roma 索取"
    },
    {
        "title": "Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape",
        "url": "http://arxiv.org/abs/2305.15399v1",
        "pub_date": "2023-05-24",
        "summary": "Synthesizing novel 3D models that resemble the input example has long been\npursued by researchers and artists in computer graphics. In this paper, we\npresent Sin3DM, a diffusion model that learns the internal patch distribution\nfrom a single 3D textured shape and generates high-quality variations with fine\ngeometry and texture details. Training a diffusion model directly in 3D would\ninduce large memory and computational cost. Therefore, we first compress the\ninput into a lower-dimensional latent space and then train a diffusion model on\nit. Specifically, we encode the input 3D textured shape into triplane feature\nmaps that represent the signed distance and texture fields of the input. The\ndenoising network of our diffusion model has a limited receptive field to avoid\noverfitting, and uses triplane-aware 2D convolution blocks to improve the\nresult quality. Aside from randomly generating new samples, our model also\nfacilitates applications such as retargeting, outpainting and local editing.\nThrough extensive qualitative and quantitative evaluation, we show that our\nmodel can generate 3D shapes of various types with better quality than prior\nmethods.",
        "translated": "长期以来，计算机图形学的研究人员和艺术家一直致力于合成类似于输入样本的新颖3D 模型。本文提出了一种扩散模型 Sin3DM，该模型从单个三维纹理形状中学习内部斑块分布，并生成具有精细几何和纹理细节的高质量变化。直接在三维空间中训练扩散模型会产生大量的内存和计算开销。因此，我们首先将输入压缩到一个低维的潜在空间，然后在其上训练一个扩散模型。具体来说，我们将输入的三维纹理形状编码成三平面特征映射，表示输入的有符号距离和纹理字段。为了避免过拟合，扩散模型的去噪网络具有有限的接收域，并且使用了三平面感知的二维卷积块来提高结果的质量。除了随机产生新的样本，我们的模型还促进应用程序，如重定向，外绘和本地编辑。通过广泛的定性和定量评价，我们表明我们的模型可以生成各种类型的三维形状，比以往的方法更好的质量。"
    },
    {
        "title": "LayoutGPT: Compositional Visual Planning and Generation with Large\n  Language Models",
        "url": "http://arxiv.org/abs/2305.15393v1",
        "pub_date": "2023-05-24",
        "summary": "Attaining a high degree of user controllability in visual generation often\nrequires intricate, fine-grained inputs like layouts. However, such inputs\nimpose a substantial burden on users when compared to simple text inputs. To\naddress the issue, we study how Large Language Models (LLMs) can serve as\nvisual planners by generating layouts from text conditions, and thus\ncollaborate with visual generative models. We propose LayoutGPT, a method to\ncompose in-context visual demonstrations in style sheet language to enhance the\nvisual planning skills of LLMs. LayoutGPT can generate plausible layouts in\nmultiple domains, ranging from 2D images to 3D indoor scenes. LayoutGPT also\nshows superior performance in converting challenging language concepts like\nnumerical and spatial relations to layout arrangements for faithful\ntext-to-image generation. When combined with a downstream image generation\nmodel, LayoutGPT outperforms text-to-image models/systems by 20-40% and\nachieves comparable performance as human users in designing visual layouts for\nnumerical and spatial correctness. Lastly, LayoutGPT achieves comparable\nperformance to supervised methods in 3D indoor scene synthesis, demonstrating\nits effectiveness and potential in multiple visual domains.",
        "translated": "在可视化生成中获得高度的用户可控性通常需要复杂的、细粒度的输入，如布局。然而，与简单的文本输入相比，这种输入对用户造成了相当大的负担。为了解决这个问题，我们研究了大语言模型(LLM)如何通过根据文本条件生成布局来充当可视化规划器，从而与可视化生成模型进行协作。我们提出了 LayoutGPT，一种用样式表语言组合上下文视觉演示的方法，以提高 LLM 的视觉规划技巧。LayoutGPT 可以在多个领域生成合理的布局，从2D 图像到3D 室内场景。LayoutGPT 在将具有挑战性的语言概念(如数值和空间关系)转换为可靠的文本到图像生成的布局安排方面也表现出优越的性能。结合下游图像生成模型，LayoutGPT 的性能比文本到图像的模型/系统高出20-40% ，并且在数值和空间正确性的可视化布局设计方面达到与人类用户相当的性能。最后，LayoutGPT 在三维室内场景合成中实现了与监督方法相当的性能，证明了其在多视觉领域中的有效性和潜力。"
    },
    {
        "title": "A Neural Space-Time Representation for Text-to-Image Personalization",
        "url": "http://arxiv.org/abs/2305.15391v1",
        "pub_date": "2023-05-24",
        "summary": "A key aspect of text-to-image personalization methods is the manner in which\nthe target concept is represented within the generative process. This choice\ngreatly affects the visual fidelity, downstream editability, and disk space\nneeded to store the learned concept. In this paper, we explore a new\ntext-conditioning space that is dependent on both the denoising process\ntimestep (time) and the denoising U-Net layers (space) and showcase its\ncompelling properties. A single concept in the space-time representation is\ncomposed of hundreds of vectors, one for each combination of time and space,\nmaking this space challenging to optimize directly. Instead, we propose to\nimplicitly represent a concept in this space by optimizing a small neural\nmapper that receives the current time and space parameters and outputs the\nmatching token embedding. In doing so, the entire personalized concept is\nrepresented by the parameters of the learned mapper, resulting in a compact,\nyet expressive, representation. Similarly to other personalization methods, the\noutput of our neural mapper resides in the input space of the text encoder. We\nobserve that one can significantly improve the convergence and visual fidelity\nof the concept by introducing a textual bypass, where our neural mapper\nadditionally outputs a residual that is added to the output of the text\nencoder. Finally, we show how one can impose an importance-based ordering over\nour implicit representation, providing users control over the reconstruction\nand editability of the learned concept using a single trained model. We\ndemonstrate the effectiveness of our approach over a range of concepts and\nprompts, showing our method's ability to generate high-quality and controllable\ncompositions without fine-tuning any parameters of the generative model itself.",
        "translated": "文本到图像个性化方法的一个关键方面是目标概念在生成过程中的表示方式。这种选择极大地影响了视觉保真度、下游可编辑性和存储所学概念所需的磁盘空间。在本文中，我们探索了一个新的文本条件空间，它同时依赖于去噪过程的时间步长(时间)和去噪的 U-Net 层(空间) ，并展示了其引人注目的性质。时空表示中的一个概念由数百个向量组成，每个向量对应于时间和空间的组合，这使得直接优化这个空间具有挑战性。相反，我们建议通过优化一个接收当前时间和空间参数并输出匹配令牌嵌入的小型神经映射器来隐式表示这个空间中的一个概念。在这样做时，整个个性化的概念是由学习映射器的参数表示，导致一个紧凑，但表达，表示。与其他个性化方法类似，我们的神经映射器的输出驻留在文本编码器的输入空间中。我们观察到，通过引入文本旁路，可以显著提高概念的收敛性和视觉保真度，其中我们的神经映射器额外输出一个残差，添加到文本编码器的输出。最后，我们展示了如何在我们的隐式表示上强加一个基于重要性的排序，使用一个单一的训练模型为用户提供对所学概念的重构和可编辑性的控制。我们通过一系列的概念和提示展示了我们的方法的有效性，展示了我们的方法能够生成高质量和可控的合成物，而不需要对生成模型本身的任何参数进行微调。"
    },
    {
        "title": "What can generic neural networks learn from a child's visual experience?",
        "url": "http://arxiv.org/abs/2305.15372v1",
        "pub_date": "2023-05-24",
        "summary": "Young children develop sophisticated internal models of the world based on\ntheir egocentric visual experience. How much of this is driven by innate\nconstraints and how much is driven by their experience? To investigate these\nquestions, we train state-of-the-art neural networks on a realistic proxy of a\nchild's visual experience without any explicit supervision or domain-specific\ninductive biases. Specifically, we train both embedding models and generative\nmodels on 200 hours of headcam video from a single child collected over two\nyears. We train a total of 72 different models, exploring a range of model\narchitectures and self-supervised learning algorithms, and comprehensively\nevaluate their performance in downstream tasks. The best embedding models\nperform at 70% of a highly performant ImageNet-trained model on average. They\nalso learn broad semantic categories without any labeled examples and learn to\nlocalize semantic categories in an image without any location supervision.\nHowever, these models are less object-centric and more background-sensitive\nthan comparable ImageNet-trained models. Generative models trained with the\nsame data successfully extrapolate simple properties of partially masked\nobjects, such as their texture, color, orientation, and rough outline, but\nstruggle with finer object details. We replicate our experiments with two other\nchildren and find very similar results. Broadly useful high-level visual\nrepresentations are thus robustly learnable from a representative sample of a\nchild's visual experience without strong inductive biases.",
        "translated": "幼儿根据自我中心的视觉经验，发展出复杂的内在世界模型。这其中有多少是由先天约束驱动的，又有多少是由他们的经验驱动的？为了研究这些问题，我们训练最先进的神经网络，在没有任何明确的监督或领域特定的归纳偏见的情况下，对儿童的视觉经验进行现实的替代。具体来说，我们训练嵌入模型和生成模型的200个小时的头部摄像头视频从一个孩子收集了两年多。我们总共训练了72个不同的模型，探索了一系列模型结构和自我监督学习算法，并全面评估了它们在下游任务中的表现。最好的嵌入模型在高性能 ImageNet 训练模型中的平均执行率为70% 。他们还学习广泛的语义类别没有任何标记的例子和学习本地化的语义类别在一个图像没有任何位置监督。然而，与可比较的 ImageNet 训练模型相比，这些模型更少的以对象为中心，更多的是对背景敏感。使用相同数据训练的生成模型成功地推断出部分遮蔽对象的简单属性，例如它们的纹理、颜色、方向和粗略轮廓，但是难以获得更精细的对象细节。我们在另外两个孩子身上做了同样的实验，得到了非常相似的结果。因此，广泛有用的高层次视觉表征可以从一个具有代表性的儿童视觉经验样本中强有力地学习，而没有强烈的归纳偏见。"
    },
    {
        "title": "SAMScore: A Semantic Structural Similarity Metric for Image Translation\n  Evaluation",
        "url": "http://arxiv.org/abs/2305.15367v1",
        "pub_date": "2023-05-24",
        "summary": "Image translation has wide applications, such as style transfer and modality\nconversion, usually aiming to generate images having both high degrees of\nrealism and faithfulness. These problems remain difficult, especially when it\nis important to preserve semantic structures. Traditional image-level\nsimilarity metrics are of limited use, since the semantics of an image are\nhigh-level, and not strongly governed by pixel-wise faithfulness to an original\nimage. Towards filling this gap, we introduce SAMScore, a generic semantic\nstructural similarity metric for evaluating the faithfulness of image\ntranslation models. SAMScore is based on the recent high-performance Segment\nAnything Model (SAM), which can perform semantic similarity comparisons with\nstandout accuracy. We applied SAMScore on 19 image translation tasks, and found\nthat it is able to outperform all other competitive metrics on all of the\ntasks. We envision that SAMScore will prove to be a valuable tool that will\nhelp to drive the vibrant field of image translation, by allowing for more\nprecise evaluations of new and evolving translation models. The code is\navailable at https://github.com/Kent0n-Li/SAMScore.",
        "translated": "意象翻译在文体转换、情态转换等方面有着广泛的应用，通常意象翻译的目的是生成逼真度高、忠实度高的意象。这些问题仍然很难解决，特别是在保护语义结构很重要的情况下。传统的图像级相似度指标的用途有限，因为图像的语义是高级的，并且不受像素级对原始图像的忠实度的强烈支配。为了填补这个空白，我们引入了 SAMScore，这是一个通用的语义结构相似性指标，用于评估图像翻译模型的可靠性。SAMScore 是基于最新的高性能分段任意模型(Segment AnyModel，SAM) ，它可以执行语义相似度比较，具有突出的准确性。我们将 SAMScore 应用于19个图像翻译任务，发现它在所有任务中的表现都优于其他竞争指标。我们设想 SAMScore 将被证明是一个有价值的工具，通过允许对新的和不断发展的翻译模式进行更精确的评估，将有助于推动图像翻译这一充满活力的领域。密码可在 https://github.com/kent0n-li/samscore 查阅。"
    },
    {
        "title": "Boundary Attention Mapping (BAM): Fine-grained saliency maps for\n  segmentation of Burn Injuries",
        "url": "http://arxiv.org/abs/2305.15365v1",
        "pub_date": "2023-05-24",
        "summary": "Burn injuries can result from mechanisms such as thermal, chemical, and\nelectrical insults. A prompt and accurate assessment of burns is essential for\ndeciding definitive clinical treatments. Currently, the primary approach for\nburn assessments, via visual and tactile observations, is approximately 60%-80%\naccurate. The gold standard is biopsy and a close second would be non-invasive\nmethods like Laser Doppler Imaging (LDI) assessments, which have up to 97%\naccuracy in predicting burn severity and the required healing time. In this\npaper, we introduce a machine learning pipeline for assessing burn severities\nand segmenting the regions of skin that are affected by burn. Segmenting 2D\ncolour images of burns allows for the injured versus non-injured skin to be\ndelineated, clearly marking the extent and boundaries of the localized\nburn/region-of-interest, even during remote monitoring of a burn patient. We\ntrained a convolutional neural network (CNN) to classify four severities of\nburns. We built a saliency mapping method, Boundary Attention Mapping (BAM),\nthat utilises this trained CNN for the purpose of accurately localizing and\nsegmenting the burn regions from skin burn images. We demonstrated the\neffectiveness of our proposed pipeline through extensive experiments and\nevaluations using two datasets; 1) A larger skin burn image dataset consisting\nof 1684 skin burn images of four burn severities, 2) An LDI dataset that\nconsists of a total of 184 skin burn images with their associated LDI scans.\nThe CNN trained using the first dataset achieved an average F1-Score of 78% and\nmicro/macro- average ROC of 85% in classifying the four burn severities.\nMoreover, a comparison between the BAM results and LDI results for measuring\ninjury boundary showed that the segmentations generated by our method achieved\n91.60% accuracy, 78.17% sensitivity, and 93.37% specificity.",
        "translated": "烧伤可能是由热、化学和电气等机制造成的。及时和准确的评估烧伤是决定明确的临床治疗是必不可少的。目前，烧伤评估的主要方法，通过视觉和触觉观察，大约60% -80% 的准确率。黄金标准是活组织检查，紧随其后的是非侵入性方法，如激光多普勒成像(LDI)评估，它在预测烧伤严重程度和所需的愈合时间方面有高达97% 的准确性。在本文中，我们介绍了一个机器学习管道，用于评估烧伤的严重程度和分割皮肤受烧伤影响的区域。分割烧伤的二维彩色图像允许描绘受伤与未受伤的皮肤，即使在远程监测烧伤患者期间，也清楚地标记局部烧伤/感兴趣区域的范围和边界。我们训练了一个卷积神经网络(CNN)来分类烧伤的四种严重程度。我们建立了一个突出映射方法，边界注意映射(BAM) ，利用这个训练的 CNN 的目的是准确定位和分割烧伤区域从皮肤烧伤图像。我们通过使用两个数据集进行广泛的实验和评估，证明了我们提出的管道的有效性; 1)由1684个四种烧伤严重程度的皮肤烧伤图像组成的更大的皮肤烧伤图像数据集，2)总共由184个皮肤烧伤图像及其相关的 LDI 扫描组成的 LDI 数据集。使用第一个数据集训练的美国有线电视新闻网在对四种烧伤严重程度进行分类时，平均达到了78% 的 f1-得分和85% 的微观/宏观平均 ROC。此外，测量损伤边界的 BAM 结果与 LDI 结果之间的比较显示，由我们的方法产生的分割达到91.60% 的准确性，78.17% 的灵敏度和93.37% 的特异性。"
    },
    {
        "title": "Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image\n  Super-Resolution",
        "url": "http://arxiv.org/abs/2305.15357v1",
        "pub_date": "2023-05-24",
        "summary": "Diffusion models, as a kind of powerful generative model, have given\nimpressive results on image super-resolution (SR) tasks. However, due to the\nrandomness introduced in the reverse process of diffusion models, the\nperformances of diffusion-based SR models are fluctuating at every time of\nsampling, especially for samplers with few resampled steps. This inherent\nrandomness of diffusion models results in ineffectiveness and instability,\nmaking it challenging for users to guarantee the quality of SR results.\nHowever, our work takes this randomness as an opportunity: fully analyzing and\nleveraging it leads to the construction of an effective plug-and-play sampling\nmethod that owns the potential to benefit a series of diffusion-based SR\nmethods. More in detail, we propose to steadily sample high-quality SR images\nfrom pretrained diffusion-based SR models by solving diffusion ordinary\ndifferential equations (diffusion ODEs) with optimal boundary conditions (BCs)\nand analyze the characteristics between the choices of BCs and their\ncorresponding SR results. Our analysis shows the route to obtain an\napproximately optimal BC via an efficient exploration in the whole space. The\nquality of SR results sampled by the proposed method with fewer steps\noutperforms the quality of results sampled by current methods with randomness\nfrom the same pretrained diffusion-based SR model, which means that our\nsampling method ``boosts'' current diffusion-based SR models without any\nadditional training.",
        "translated": "扩散模型作为一种强大的生成模型，在图像超分辨率(SR)任务中给出了令人印象深刻的结果。然而，由于扩散模型反向过程的随机性，基于扩散的 SR 模型在每次采样时的性能都会发生波动，特别是对于重采样步数较少的采样者。这种扩散模型固有的随机性导致无效性和不稳定性，使得用户难以保证 SR 结果的质量。然而，我们的工作把这种随机性作为一个机会: 充分分析和利用它导致建立一个有效的即插即用的抽样方法，拥有受益于一系列基于扩散的 SR 方法的潜力。具体来说，我们提出了通过求解具有最优边界条件的扩散常微分方程，从基于扩散的预训练 SR 模型中稳定地采集高质量的 SR 图像，并分析了扩散常微分方程的选择与其相应 SR 结果之间的特点。我们的分析表明，通过在整个空间进行有效的探索，可以获得一个近似最优 BC 的路径。本文提出的方法采样的 SR 结果的质量较少的步骤优于目前的方法采样的结果的质量与随机性从相同的预先训练的扩散为基础的 SR 模型，这意味着我们的采样方法“推动”目前的扩散为基础的 SR 模型没有任何额外的训练。"
    },
    {
        "title": "Mitigating Biased Activation in Weakly-supervised Object Localization\n  via Counterfactual Learning",
        "url": "http://arxiv.org/abs/2305.15354v1",
        "pub_date": "2023-05-24",
        "summary": "In this paper, we focus on an under-explored issue of biased activation in\nprior weakly-supervised object localization methods based on Class Activation\nMapping (CAM). We analyze the cause of this problem from a causal view and\nattribute it to the co-occurring background confounders. Following this\ninsight, we propose a novel Counterfactual Co-occurring Learning (CCL) paradigm\nto synthesize the counterfactual representations via coupling constant\nforeground and unrealized backgrounds in order to cut off their co-occurring\nrelationship. Specifically, we design a new network structure called\nCounterfactual-CAM, which embeds the counterfactual representation perturbation\nmechanism into the vanilla CAM-based model. This mechanism is responsible for\ndecoupling foreground as well as background and synthesizing the counterfactual\nrepresentations. By training the detection model with these synthesized\nrepresentations, we compel the model to focus on the constant foreground\ncontent while minimizing the influence of distracting co-occurring background.\nTo our best knowledge, it is the first attempt in this direction. Extensive\nexperiments on several benchmarks demonstrate that Counterfactual-CAM\nsuccessfully mitigates the biased activation problem, achieving improved object\nlocalization accuracy.",
        "translated": "本文研究了基于类激活映射(CAM)的弱监督目标定位方法中存在的偏向激活问题。我们从因果关系的角度分析了这一问题的原因，并将其归因于共同发生的背景混杂因素。根据这一观点，我们提出了一种新的反事实共现学习范式，通过耦合常数前景和未实现背景来综合反事实表征，以切断它们之间的共现关系。具体来说，我们设计了一种新的网络结构，称为反事实-CAM，它将反事实表示扰动机制嵌入到普通的基于 CAM 的模型中。该机制负责解耦前景和背景，并综合反事实表示。通过训练这些综合表征的检测模型，我们迫使模型集中在恒定的前景内容，同时尽量减少干扰共现背景的影响。据我们所知，这是朝这个方向的第一次尝试。在几个基准上的大量实验表明，反事实 CAM 成功地缓解了有偏激活问题，提高了目标定位精度。"
    },
    {
        "title": "Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models",
        "url": "http://arxiv.org/abs/2305.16322v1",
        "pub_date": "2023-05-25",
        "summary": "Text-to-Image diffusion models have made tremendous progress over the past\ntwo years, enabling the generation of highly realistic images based on\nopen-domain text descriptions. However, despite their success, text\ndescriptions often struggle to adequately convey detailed controls, even when\ncomposed of long and complex texts. Moreover, recent studies have also shown\nthat these models face challenges in understanding such complex texts and\ngenerating the corresponding images. Therefore, there is a growing need to\nenable more control modes beyond text description. In this paper, we introduce\nUni-ControlNet, a novel approach that allows for the simultaneous utilization\nof different local controls (e.g., edge maps, depth map, segmentation masks)\nand global controls (e.g., CLIP image embeddings) in a flexible and composable\nmanner within one model. Unlike existing methods, Uni-ControlNet only requires\nthe fine-tuning of two additional adapters upon frozen pre-trained\ntext-to-image diffusion models, eliminating the huge cost of training from\nscratch. Moreover, thanks to some dedicated adapter designs, Uni-ControlNet\nonly necessitates a constant number (i.e., 2) of adapters, regardless of the\nnumber of local or global controls used. This not only reduces the fine-tuning\ncosts and model size, making it more suitable for real-world deployment, but\nalso facilitate composability of different conditions. Through both\nquantitative and qualitative comparisons, Uni-ControlNet demonstrates its\nsuperiority over existing methods in terms of controllability, generation\nquality and composability. Code is available at\n\\url{https://github.com/ShihaoZhaoZSH/Uni-ControlNet}.",
        "translated": "在过去的两年中，文本到图像的扩散模型取得了巨大的进展，使得基于开放域文本描述的高度真实感图像的生成成为可能。然而，尽管成功，文本描述往往难以充分传达详细的控制，即使是组成了长期和复杂的文本。此外，最近的研究也表明，这些模型在理解这些复杂的文本和生成相应的图像面临挑战。因此，越来越需要在文本描述之外启用更多的控制模式。在本文中，我们介绍了 Uni-ControlNet，一种新的方法，允许同时利用不同的局部控件(例如，边缘映射，深度映射，分割掩码)和全局控件(例如，CLIP 图像嵌入)在一个灵活和可组合的方式在一个模型。与现有的方法不同，Uni-ControlNet 只需要在冻结的预先训练的文本到图像扩散模型上对另外两个适配器进行微调，从而消除了从头开始训练的巨大成本。此外，由于一些专用的适配器设计，Uni-ControlNet 只需要一个常数(即2)的适配器，而不管所使用的本地或全局控件的数量。这不仅降低了微调成本和模型大小，使其更适合于实际部署，而且还促进了不同条件的可组合性。通过定量和定性比较，Uni-ControlNet 在可控性、生成质量和可组合性等方面均优于现有方法。代码可在网址{ https://github.com/shihaozhaozsh/uni-controlnet }下载。"
    },
    {
        "title": "Eclipse: Disambiguating Illumination and Materials using Unintended\n  Shadows",
        "url": "http://arxiv.org/abs/2305.16321v1",
        "pub_date": "2023-05-25",
        "summary": "Decomposing an object's appearance into representations of its materials and\nthe surrounding illumination is difficult, even when the object's 3D shape is\nknown beforehand. This problem is ill-conditioned because diffuse materials\nseverely blur incoming light, and is ill-posed because diffuse materials under\nhigh-frequency lighting can be indistinguishable from shiny materials under\nlow-frequency lighting. We show that it is possible to recover precise\nmaterials and illumination -- even from diffuse objects -- by exploiting\nunintended shadows, like the ones cast onto an object by the photographer who\nmoves around it. These shadows are a nuisance in most previous inverse\nrendering pipelines, but here we exploit them as signals that improve\nconditioning and help resolve material-lighting ambiguities. We present a\nmethod based on differentiable Monte Carlo ray tracing that uses images of an\nobject to jointly recover its spatially-varying materials, the surrounding\nillumination environment, and the shapes of the unseen light occluders who\ninadvertently cast shadows upon it.",
        "translated": "分解一个物体的外观到其材料和周围照明的表示是困难的，即使当物体的三维形状是已知的。这个问题是病态的，因为漫反射材料严重模糊入射光，而且是病态的，因为在高频照明下漫反射材料可以与低频照明下发光材料难以区分。我们展示了通过利用意想不到的阴影(如摄影师在物体周围移动时投射到物体上的阴影)来恢复精确的材料和照明——即使是从漫反射的物体上也是可能的。这些阴影在大多数以前的反向渲染管道中是一个麻烦，但在这里我们利用它们作为改善条件反射和帮助解决材质-照明模糊的信号。我们提出了一种基于可微蒙特卡罗射线追踪的方法，该方法利用一个物体的图像来共同恢复其空间变化的材料，周围的照明环境，以及无意中在其上投射阴影的看不见的光遮挡物的形状。"
    },
    {
        "title": "Image is First-order Norm+Linear Autoregressive",
        "url": "http://arxiv.org/abs/2305.16319v1",
        "pub_date": "2023-05-25",
        "summary": "This paper reveals that every image can be understood as a first-order\nnorm+linear autoregressive process, referred to as FINOLA, where norm+linear\ndenotes the use of normalization before the linear model. We demonstrate that\nimages of size 256$\\times$256 can be reconstructed from a compressed vector\nusing autoregression up to a 16$\\times$16 feature map, followed by upsampling\nand convolution. This discovery sheds light on the underlying partial\ndifferential equations (PDEs) governing the latent feature space. Additionally,\nwe investigate the application of FINOLA for self-supervised learning through a\nsimple masked prediction technique. By encoding a single unmasked quadrant\nblock, we can autoregressively predict the surrounding masked region.\nRemarkably, this pre-trained representation proves effective for image\nclassification and object detection tasks, even in lightweight networks,\nwithout requiring fine-tuning. The code will be made publicly available.",
        "translated": "本文揭示了每幅图像都可以理解为一阶范数 + 线性自回归过程，称为 FINOLA，其中范数 + 线性表示在线性模型之前使用归一化。我们证明了大小为256美元乘以256美元的图像可以从一个压缩向量重建使用自回归高达16美元乘以16美元的特征映射，然后上采样和卷积。这一发现揭示了控制潜在特征空间的基本偏微分方程(PDE)。此外，我们还通过一个简单的掩蔽预测技术研究了 FINOLA 在自监督学习中的应用。通过编码一个未遮蔽的象限块，我们可以自回归地预测周围的遮蔽区域。值得注意的是，这种预先训练的表示被证明对图像分类和目标检测任务非常有效，即使在轻量级网络中，也不需要进行微调。代码将公开发布。"
    },
    {
        "title": "Referred by Multi-Modality: A Unified Temporal Transformer for Video\n  Object Segmentation",
        "url": "http://arxiv.org/abs/2305.16318v1",
        "pub_date": "2023-05-25",
        "summary": "Recently, video object segmentation (VOS) referred by multi-modal signals,\ne.g., language and audio, has evoked increasing attention in both industry and\nacademia. It is challenging for exploring the semantic alignment within\nmodalities and the visual correspondence across frames. However, existing\nmethods adopt separate network architectures for different modalities, and\nneglect the inter-frame temporal interaction with references. In this paper, we\npropose MUTR, a Multi-modal Unified Temporal transformer for Referring video\nobject segmentation. With a unified framework for the first time, MUTR adopts a\nDETR-style transformer and is capable of segmenting video objects designated by\neither text or audio reference. Specifically, we introduce two strategies to\nfully explore the temporal relations between videos and multi-modal signals.\nFirstly, for low-level temporal aggregation before the transformer, we enable\nthe multi-modal references to capture multi-scale visual cues from consecutive\nvideo frames. This effectively endows the text or audio signals with temporal\nknowledge and boosts the semantic alignment between modalities. Secondly, for\nhigh-level temporal interaction after the transformer, we conduct inter-frame\nfeature communication for different object embeddings, contributing to better\nobject-wise correspondence for tracking along the video. On Ref-YouTube-VOS and\nAVSBench datasets with respective text and audio references, MUTR achieves\n+4.2% and +4.2% J&amp;F improvements to state-of-the-art methods, demonstrating our\nsignificance for unified multi-modal VOS. Code is released at\nhttps://github.com/OpenGVLab/MUTR.",
        "translated": "近年来，基于语言、音频等多模态信号的视频对象分割技术引起了业界和学术界的广泛关注。这对于探索模式内的语义对齐和跨框架的视觉对应是一个挑战。然而，现有的方法针对不同的模式采用不同的网络结构，而忽略了帧间与参考文献的时间交互。本文提出了一种多模态统一时态转换器 MUTR，用于参考视频对象分割。MUTR 首次采用了统一的框架，采用了 DETR 风格的变换器，能够对文本或音频参考指定的视频对象进行分割。具体来说，我们引入了两种策略来充分探索视频和多模态信号之间的时间关系。首先，对于转换前的低级时间聚合，我们使多模态参考能够从连续的视频帧中捕获多尺度的视觉线索。这有效地赋予了文本或音频信号时间知识，并提高了形态之间的语义对齐。其次，对于变压器后的高层次时间交互，针对不同的目标嵌入进行帧间特征通信，有助于提高视频跟踪的目标对应性。在 Ref-YouTube-VOS 和 AVSBench 数据集上，各自的文本和音频参考，MUTR 对最先进的方法实现了 + 4.2% 和 + 4.2% 的 J & F 改进，表明了我们对统一的多模态 VOS 的重要性。代码在 https://github.com/opengvlab/mutr 发布。"
    },
    {
        "title": "Making Vision Transformers Truly Shift-Equivariant",
        "url": "http://arxiv.org/abs/2305.16316v1",
        "pub_date": "2023-05-25",
        "summary": "For computer vision tasks, Vision Transformers (ViTs) have become one of the\ngo-to deep net architectures. Despite being inspired by Convolutional Neural\nNetworks (CNNs), ViTs remain sensitive to small shifts in the input image. To\naddress this, we introduce novel designs for each of the modules in ViTs, such\nas tokenization, self-attention, patch merging, and positional encoding. With\nour proposed modules, we achieve truly shift-equivariant ViTs on four\nwell-established models, namely, Swin, SwinV2, MViTv2, and CvT, both in theory\nand practice. Empirically, we tested these models on image classification and\nsemantic segmentation, achieving competitive performance across three different\ndatasets while maintaining 100% shift consistency.",
        "translated": "在计算机视觉任务中，视觉变换器(ViTs)已经成为一种常用的深层网络体系结构。尽管受到卷积神经网络(CNN)的启发，ViTs 仍然对输入图像的微小变化敏感。为了解决这个问题，我们为 ViT 中的每个模块引入了新的设计，例如标记化、自注意、补丁合并和位置编码。通过我们提出的模块，我们在理论和实践上实现了四个已经建立的模型，即 Swin，SwinV2，MViTv2和 CvT 上的真正的移位等变 VIT。经验上，我们在图像分类和语义分割上测试了这些模型，在保持100% 移位一致性的同时，在三个不同的数据集上实现了竞争性能。"
    },
    {
        "title": "NAP: Neural 3D Articulation Prior",
        "url": "http://arxiv.org/abs/2305.16315v1",
        "pub_date": "2023-05-25",
        "summary": "We propose Neural 3D Articulation Prior (NAP), the first 3D deep generative\nmodel to synthesize 3D articulated object models. Despite the extensive\nresearch on generating 3D objects, compositions, or scenes, there remains a\nlack of focus on capturing the distribution of articulated objects, a common\nobject category for human and robot interaction. To generate articulated\nobjects, we first design a novel articulation tree/graph parameterization and\nthen apply a diffusion-denoising probabilistic model over this representation\nwhere articulated objects can be generated via denoising from random complete\ngraphs. In order to capture both the geometry and the motion structure whose\ndistribution will affect each other, we design a graph-attention denoising\nnetwork for learning the reverse diffusion process. We propose a novel distance\nthat adapts widely used 3D generation metrics to our novel task to evaluate\ngeneration quality, and experiments demonstrate our high performance in\narticulated object generation. We also demonstrate several conditioned\ngeneration applications, including Part2Motion, PartNet-Imagination,\nMotion2Part, and GAPart2Object.",
        "translated": "我们提出了神经三维关节优先级(nAP) ，这是第一个合成三维关节物体模型的三维深度生成模型。尽管在生成三维物体、构图或场景方面有着广泛的研究，但是对于捕捉关节物体的分布这一人机交互的常见对象类别仍然缺乏关注。为了生成关节对象，我们首先设计了一个新的关节树/图形参量化，然后应用扩散去噪概率模型，通过从随机完整图中去噪来生成关节对象。为了捕捉反向扩散过程中几何和运动结构的相互影响，我们设计了一个图注意去噪网络来学习反向扩散过程。我们提出了一个新的距离，适应广泛使用的三维生成度量的新任务，以评估生成质量，实验表明我们的高性能的铰接对象生成。我们还演示了几个条件生成应用程序，包括 Part2Motion、 PartNet-Imagination、 Motion2Part 和 GAPart2Object。"
    },
    {
        "title": "Banana: Banach Fixed-Point Network for Pointcloud Segmentation with\n  Inter-Part Equivariance",
        "url": "http://arxiv.org/abs/2305.16314v1",
        "pub_date": "2023-05-25",
        "summary": "Equivariance has gained strong interest as a desirable network property that\ninherently ensures robust generalization. However, when dealing with complex\nsystems such as articulated objects or multi-object scenes, effectively\ncapturing inter-part transformations poses a challenge, as it becomes entangled\nwith the overall structure and local transformations. The interdependence of\npart assignment and per-part group action necessitates a novel equivariance\nformulation that allows for their co-evolution. In this paper, we present\nBanana, a Banach fixed-point network for equivariant segmentation with\ninter-part equivariance by construction. Our key insight is to iteratively\nsolve a fixed-point problem, where point-part assignment labels and per-part\nSE(3)-equivariance co-evolve simultaneously. We provide theoretical derivations\nof both per-step equivariance and global convergence, which induces an\nequivariant final convergent state. Our formulation naturally provides a strict\ndefinition of inter-part equivariance that generalizes to unseen inter-part\nconfigurations. Through experiments conducted on both articulated objects and\nmulti-object scans, we demonstrate the efficacy of our approach in achieving\nstrong generalization under inter-part transformations, even when confronted\nwith substantial changes in pointcloud geometry and topology.",
        "translated": "等方差作为一种理想的网络属性，在本质上确保了鲁棒的推广，已经引起了人们的极大兴趣。然而，当处理复杂的系统，如铰接对象或多对象场景，有效地捕获部分间的转换提出了一个挑战，因为它成为纠缠在整体结构和局部转换。部分分配和每部分群体行为的相互依赖性需要一个新的等方差公式，允许它们的协同演化。本文提出了一种基于构造的 Banana 不动点网络，用于部分间等方差的等变分割。我们的主要见解是迭代求解一个不动点问题，其中点部分分配标签和每部分 SE (3)-等方差同时共同演化。我们给出了每步等方差和全局收敛的理论推导，得到了一个等变的最终收敛状态。我们的公式自然提供了一个严格的部分间等方差的定义，推广到看不见的部分间配置。通过对关联对象和多目标扫描的实验，我们证明了该方法在部分间转换下实现强泛化的有效性，即使在面临点云几何和拓扑结构的实质性变化时也是如此。"
    },
    {
        "title": "Break-A-Scene: Extracting Multiple Concepts from a Single Image",
        "url": "http://arxiv.org/abs/2305.16311v1",
        "pub_date": "2023-05-25",
        "summary": "Text-to-image model personalization aims to introduce a user-provided concept\nto the model, allowing its synthesis in diverse contexts. However, current\nmethods primarily focus on the case of learning a single concept from multiple\nimages with variations in backgrounds and poses, and struggle when adapted to a\ndifferent scenario. In this work, we introduce the task of textual scene\ndecomposition: given a single image of a scene that may contain several\nconcepts, we aim to extract a distinct text token for each concept, enabling\nfine-grained control over the generated scenes. To this end, we propose\naugmenting the input image with masks that indicate the presence of target\nconcepts. These masks can be provided by the user or generated automatically by\na pre-trained segmentation model. We then present a novel two-phase\ncustomization process that optimizes a set of dedicated textual embeddings\n(handles), as well as the model weights, striking a delicate balance between\naccurately capturing the concepts and avoiding overfitting. We employ a masked\ndiffusion loss to enable handles to generate their assigned concepts,\ncomplemented by a novel loss on cross-attention maps to prevent entanglement.\nWe also introduce union-sampling, a training strategy aimed to improve the\nability of combining multiple concepts in generated images. We use several\nautomatic metrics to quantitatively compare our method against several\nbaselines, and further affirm the results using a user study. Finally, we\nshowcase several applications of our method. Project page is available at:\nhttps://omriavrahami.com/break-a-scene/",
        "translated": "文本到图像模型个性化旨在向模型引入用户提供的概念，允许在不同的上下文中进行合成。然而，目前的方法主要集中在从背景和姿势不同的多幅图像中学习单一概念的情况下，并在适应不同情景时进行斗争。在这项工作中，我们介绍了文本场景分解的任务: 给定一个场景的单个图像，可能包含几个概念，我们的目标是提取一个不同的文本标记为每个概念，使细粒度控制生成的场景。为此，我们提出用掩码来增强输入图像，以表明目标概念的存在。这些掩码可以由用户提供，也可以由预先训练好的分割模型自动生成。然后，我们提出了一个新的两阶段定制过程，优化了一组专用的文本嵌入(处理) ，以及模型权重，在准确捕捉概念和避免过度拟合之间找到人海万花筒(电影)。我们使用一个掩蔽的扩散损失，使处理能够生成其指定的概念，补充交叉注意地图上的一个新的损失，以防止纠缠。我们还引入了联合采样，这是一种旨在提高生成图像中多个概念组合能力的训练策略。我们使用几个自动指标来定量比较我们的方法与几个基线，并进一步确认结果使用用户研究。最后，我们展示了我们的方法的几个应用。项目网页可于以下 https://omriavrahami.com/break-a-scene/下载:"
    },
    {
        "title": "UMat: Uncertainty-Aware Single Image High Resolution Material Capture",
        "url": "http://arxiv.org/abs/2305.16312v1",
        "pub_date": "2023-05-25",
        "summary": "We propose a learning-based method to recover normals, specularity, and\nroughness from a single diffuse image of a material, using microgeometry\nappearance as our primary cue. Previous methods that work on single images tend\nto produce over-smooth outputs with artifacts, operate at limited resolution,\nor train one model per class with little room for generalization. Previous\nmethods that work on single images tend to produce over-smooth outputs with\nartifacts, operate at limited resolution, or train one model per class with\nlittle room for generalization. In contrast, in this work, we propose a novel\ncapture approach that leverages a generative network with attention and a U-Net\ndiscriminator, which shows outstanding performance integrating global\ninformation at reduced computational complexity. We showcase the performance of\nour method with a real dataset of digitized textile materials and show that a\ncommodity flatbed scanner can produce the type of diffuse illumination required\nas input to our method. Additionally, because the problem might be illposed\n-more than a single diffuse image might be needed to disambiguate the specular\nreflection- or because the training dataset is not representative enough of the\nreal distribution, we propose a novel framework to quantify the model's\nconfidence about its prediction at test time. Our method is the first one to\ndeal with the problem of modeling uncertainty in material digitization,\nincreasing the trustworthiness of the process and enabling more intelligent\nstrategies for dataset creation, as we demonstrate with an active learning\nexperiment.",
        "translated": "我们提出了一个基于学习的方法来恢复法线，反射率和粗糙度从一个单一的漫反射图像的材料，使用显微几何外观作为我们的主要线索。以前用于单幅图像的方法倾向于产生带有工件的过于平滑的输出，在有限的分辨率下操作，或者每类训练一个模型，几乎没有泛化的空间。以前用于单幅图像的方法倾向于产生带有工件的过于平滑的输出，在有限的分辨率下操作，或者每类训练一个模型，几乎没有泛化的空间。相比之下，在这项工作中，我们提出了一种新的捕获方法，利用生成网络的注意力和 U-Net 鉴别器，它显示了在降低计算复杂度的情况下集成全局信息的出色性能。我们展示了我们的方法的性能与数字化纺织材料的真实数据集，并表明，一个商品平板扫描仪可以产生所需的漫反射照明类型作为输入我们的方法。此外，由于问题可能是病态的——消除镜面反射(物理)可能需要不止一张漫反射图像——或者由于训练数据集不足以代表真实分布，我们提出了一个新的框架来量化模型在测试时对其预测的信心。我们的方法是第一个处理材料数字化建模不确定性的问题，提高过程的可信度，使数据集创建更智能的策略，正如我们用一个积极的学习实验所证明的那样。"
    },
    {
        "title": "Securing Deep Generative Models with Universal Adversarial Signature",
        "url": "http://arxiv.org/abs/2305.16310v1",
        "pub_date": "2023-05-25",
        "summary": "Recent advances in deep generative models have led to the development of\nmethods capable of synthesizing high-quality, realistic images. These models\npose threats to society due to their potential misuse. Prior research attempted\nto mitigate these threats by detecting generated images, but the varying traces\nleft by different generative models make it challenging to create a universal\ndetector capable of generalizing to new, unseen generative models. In this\npaper, we propose to inject a universal adversarial signature into an arbitrary\npre-trained generative model, in order to make its generated contents more\ndetectable and traceable. First, the imperceptible optimal signature for each\nimage can be found by a signature injector through adversarial training.\nSubsequently, the signature can be incorporated into an arbitrary generator by\nfine-tuning it with the images processed by the signature injector. In this\nway, the detector corresponding to the signature can be reused for any\nfine-tuned generator for tracking the generator identity. The proposed method\nis validated on the FFHQ and ImageNet datasets with various state-of-the-art\ngenerative models, consistently showing a promising detection rate. Code will\nbe made publicly available at \\url{https://github.com/zengxianyu/genwm}.",
        "translated": "深度生成模型的最新进展导致了能够合成高质量、真实图像的方法的发展。这些模式由于可能被滥用而对社会构成威胁。先前的研究试图通过检测生成的图像来减轻这些威胁，但不同的生成模型留下的不同痕迹使得创建一个能够推广到新的、看不见的生成模型的通用检测器具有挑战性。在这篇文章中，我们建议将一个通用的对抗性签名注入到一个任意的预先训练的生成模型中，以使其生成的内容更加可检测和可追踪。首先，通过对抗训练，利用签名注入器可以找到每幅图像的不可察觉的最优签名。随后，可以通过使用签名注入器处理的图像对签名进行微调，从而将签名合并到任意生成器中。这样，对应于签名的检测器可以重用于任何微调发生器，用于跟踪发生器标识。该方法在 FFHQ 和 ImageNet 数据集上通过各种最先进的生成模型进行了验证，一致地显示出有希望的检测率。代码将在 url { https://github.com/zengxianyu/genwm }公开发布。"
    },
    {
        "title": "NeuManifold: Neural Watertight Manifold Reconstruction with Efficient\n  and High-Quality Rendering Support",
        "url": "http://arxiv.org/abs/2305.17134v1",
        "pub_date": "2023-05-26",
        "summary": "We present a method for generating high-quality watertight manifold meshes\nfrom multi-view input images. Existing volumetric rendering methods are robust\nin optimization but tend to generate noisy meshes with poor topology.\nDifferentiable rasterization-based methods can generate high-quality meshes but\nare sensitive to initialization. Our method combines the benefits of both\nworlds; we take the geometry initialization obtained from neural volumetric\nfields, and further optimize the geometry as well as a compact neural texture\nrepresentation with differentiable rasterizers. Through extensive experiments,\nwe demonstrate that our method can generate accurate mesh reconstructions with\nfaithful appearance that are comparable to previous volume rendering methods\nwhile being an order of magnitude faster in rendering. We also show that our\ngenerated mesh and neural texture reconstruction is compatible with existing\ngraphics pipelines and enables downstream 3D applications such as simulation.\nProject page: https://sarahweiii.github.io/neumanifold/",
        "translated": ""
    },
    {
        "title": "Manifold Regularization for Memory-Efficient Training of Deep Neural\n  Networks",
        "url": "http://arxiv.org/abs/2305.17119v1",
        "pub_date": "2023-05-26",
        "summary": "One of the prevailing trends in the machine- and deep-learning community is\nto gravitate towards the use of increasingly larger models in order to keep\npushing the state-of-the-art performance envelope. This tendency makes access\nto the associated technologies more difficult for the average practitioner and\nruns contrary to the desire to democratize knowledge production in the field.\nIn this paper, we propose a framework for achieving improved memory efficiency\nin the process of learning traditional neural networks by leveraging\ninductive-bias-driven network design principles and layer-wise\nmanifold-oriented regularization objectives. Use of the framework results in\nimproved absolute performance and empirical generalization error relative to\ntraditional learning techniques. We provide empirical validation of the\nframework, including qualitative and quantitative evidence of its effectiveness\non two standard image datasets, namely CIFAR-10 and CIFAR-100. The proposed\nframework can be seamlessly combined with existing network compression methods\nfor further memory savings.",
        "translated": ""
    },
    {
        "title": "Random-Access Neural Compression of Material Textures",
        "url": "http://arxiv.org/abs/2305.17105v1",
        "pub_date": "2023-05-26",
        "summary": "The continuous advancement of photorealism in rendering is accompanied by a\ngrowth in texture data and, consequently, increasing storage and memory\ndemands. To address this issue, we propose a novel neural compression technique\nspecifically designed for material textures. We unlock two more levels of\ndetail, i.e., 16x more texels, using low bitrate compression, with image\nquality that is better than advanced image compression techniques, such as AVIF\nand JPEG XL. At the same time, our method allows on-demand, real-time\ndecompression with random access similar to block texture compression on GPUs,\nenabling compression on disk and memory. The key idea behind our approach is\ncompressing multiple material textures and their mipmap chains together, and\nusing a small neural network, that is optimized for each material, to\ndecompress them. Finally, we use a custom training implementation to achieve\npractical compression speeds, whose performance surpasses that of general\nframeworks, like PyTorch, by an order of magnitude.",
        "translated": ""
    },
    {
        "title": "GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot\n  Attention for Vision-and-Language Navigation",
        "url": "http://arxiv.org/abs/2305.17102v1",
        "pub_date": "2023-05-26",
        "summary": "Most existing works solving Room-to-Room VLN problem only utilize RGB images\nand do not consider local context around candidate views, which lack sufficient\nvisual cues about surrounding environment. Moreover, natural language contains\ncomplex semantic information thus its correlations with visual inputs are hard\nto model merely with cross attention. In this paper, we propose GeoVLN, which\nlearns Geometry-enhanced visual representation based on slot attention for\nrobust Visual-and-Language Navigation. The RGB images are compensated with the\ncorresponding depth maps and normal maps predicted by Omnidata as visual\ninputs. Technically, we introduce a two-stage module that combine local slot\nattention and CLIP model to produce geometry-enhanced representation from such\ninput. We employ V&amp;L BERT to learn a cross-modal representation that\nincorporate both language and vision informations. Additionally, a novel\nmultiway attention module is designed, encouraging different phrases of input\ninstruction to exploit the most related features from visual input. Extensive\nexperiments demonstrate the effectiveness of our newly designed modules and\nshow the compelling performance of the proposed method.",
        "translated": ""
    },
    {
        "title": "ControlVideo: Adding Conditional Control for One Shot Text-to-Video\n  Editing",
        "url": "http://arxiv.org/abs/2305.17098v1",
        "pub_date": "2023-05-26",
        "summary": "In this paper, we present ControlVideo, a novel method for text-driven video\nediting. Leveraging the capabilities of text-to-image diffusion models and\nControlNet, ControlVideo aims to enhance the fidelity and temporal consistency\nof videos that align with a given text while preserving the structure of the\nsource video. This is achieved by incorporating additional conditions such as\nedge maps, fine-tuning the key-frame and temporal attention on the source\nvideo-text pair with carefully designed strategies. An in-depth exploration of\nControlVideo's design is conducted to inform future research on one-shot tuning\nvideo diffusion models. Quantitatively, ControlVideo outperforms a range of\ncompetitive baselines in terms of faithfulness and consistency while still\naligning with the textual prompt. Additionally, it delivers videos with high\nvisual realism and fidelity w.r.t. the source content, demonstrating\nflexibility in utilizing controls containing varying degrees of source video\ninformation, and the potential for multiple control combinations. The project\npage is available at\n\\href{https://ml.cs.tsinghua.edu.cn/controlvideo/}{https://ml.cs.tsinghua.edu.cn/controlvideo/}.",
        "translated": ""
    },
    {
        "title": "GRAtt-VIS: Gated Residual Attention for Auto Rectifying Video Instance\n  Segmentation",
        "url": "http://arxiv.org/abs/2305.17096v1",
        "pub_date": "2023-05-26",
        "summary": "Recent trends in Video Instance Segmentation (VIS) have seen a growing\nreliance on online methods to model complex and lengthy video sequences.\nHowever, the degradation of representation and noise accumulation of the online\nmethods, especially during occlusion and abrupt changes, pose substantial\nchallenges. Transformer-based query propagation provides promising directions\nat the cost of quadratic memory attention. However, they are susceptible to the\ndegradation of instance features due to the above-mentioned challenges and\nsuffer from cascading effects. The detection and rectification of such errors\nremain largely underexplored. To this end, we introduce \\textbf{GRAtt-VIS},\n\\textbf{G}ated \\textbf{R}esidual \\textbf{Att}ention for \\textbf{V}ideo\n\\textbf{I}nstance \\textbf{S}egmentation. Firstly, we leverage a\nGumbel-Softmax-based gate to detect possible errors in the current frame. Next,\nbased on the gate activation, we rectify degraded features from its past\nrepresentation. Such a residual configuration alleviates the need for dedicated\nmemory and provides a continuous stream of relevant instance features.\nSecondly, we propose a novel inter-instance interaction using gate activation\nas a mask for self-attention. This masking strategy dynamically restricts the\nunrepresentative instance queries in the self-attention and preserves vital\ninformation for long-term tracking. We refer to this novel combination of Gated\nResidual Connection and Masked Self-Attention as \\textbf{GRAtt} block, which\ncan easily be integrated into the existing propagation-based framework.\nFurther, GRAtt blocks significantly reduce the attention overhead and simplify\ndynamic temporal modeling. GRAtt-VIS achieves state-of-the-art performance on\nYouTube-VIS and the highly challenging OVIS dataset, significantly improving\nover previous methods. Code is available at\n\\url{https://github.com/Tanveer81/GRAttVIS}.",
        "translated": ""
    },
    {
        "title": "SSSegmenation: An Open Source Supervised Semantic Segmentation Toolbox\n  Based on PyTorch",
        "url": "http://arxiv.org/abs/2305.17091v1",
        "pub_date": "2023-05-26",
        "summary": "This paper presents SSSegmenation, which is an open source supervised\nsemantic image segmentation toolbox based on PyTorch. The design of this\ntoolbox is motivated by MMSegmentation while it is easier to use because of\nfewer dependencies and achieves superior segmentation performance under a\ncomparable training and testing setup. Moreover, the toolbox also provides\nplenty of trained weights for popular and contemporary semantic segmentation\nmethods, including Deeplab, PSPNet, OCRNet, MaskFormer, \\emph{etc}. We expect\nthat this toolbox can contribute to the future development of semantic\nsegmentation. Codes and model zoos are available at\n\\href{https://github.com/SegmentationBLWX/sssegmentation/}{SSSegmenation}.",
        "translated": ""
    },
    {
        "title": "Mindstorms in Natural Language-Based Societies of Mind",
        "url": "http://arxiv.org/abs/2305.17066v1",
        "pub_date": "2023-05-26",
        "summary": "Both Minsky's \"society of mind\" and Schmidhuber's \"learning to think\" inspire\ndiverse societies of large multimodal neural networks (NNs) that solve problems\nby interviewing each other in a \"mindstorm.\" Recent implementations of NN-based\nsocieties of minds consist of large language models (LLMs) and other NN-based\nexperts communicating through a natural language interface. In doing so, they\novercome the limitations of single LLMs, improving multimodal zero-shot\nreasoning. In these natural language-based societies of mind (NLSOMs), new\nagents -- all communicating through the same universal symbolic language -- are\neasily added in a modular fashion. To demonstrate the power of NLSOMs, we\nassemble and experiment with several of them (having up to 129 members),\nleveraging mindstorms in them to solve some practical AI tasks: visual question\nanswering, image captioning, text-to-image synthesis, 3D generation, egocentric\nretrieval, embodied AI, and general language-based task solving. We view this\nas a starting point towards much larger NLSOMs with billions of agents-some of\nwhich may be humans. And with this emergence of great societies of\nheterogeneous minds, many new research questions have suddenly become paramount\nto the future of artificial intelligence. What should be the social structure\nof an NLSOM? What would be the (dis)advantages of having a monarchical rather\nthan a democratic structure? How can principles of NN economies be used to\nmaximize the total reward of a reinforcement learning NLSOM? In this work, we\nidentify, discuss, and try to answer some of these questions.",
        "translated": ""
    },
    {
        "title": "Extremely weakly-supervised blood vessel segmentation with\n  physiologically based synthesis and domain adaptation",
        "url": "http://arxiv.org/abs/2305.17054v1",
        "pub_date": "2023-05-26",
        "summary": "Accurate analysis and modeling of renal functions require a precise\nsegmentation of the renal blood vessels. Micro-CT scans provide image data at\nhigher resolutions, making more small vessels near the renal cortex visible.\nAlthough deep-learning-based methods have shown state-of-the-art performance in\nautomatic blood vessel segmentations, they require a large amount of labeled\ntraining data. However, voxel-wise labeling in micro-CT scans is extremely\ntime-consuming given the huge volume sizes. To mitigate the problem, we\nsimulate synthetic renal vascular trees physiologically while generating\ncorresponding scans of the simulated trees by training a generative model on\nunlabeled scans. This enables the generative model to learn the mapping\nimplicitly without the need for explicit functions to emulate the image\nacquisition process. We further propose an additional segmentation branch over\nthe generative model trained on the generated scans. We demonstrate that the\nmodel can directly segment blood vessels on real scans and validate our method\non both 3D micro-CT scans of rat kidneys and a proof-of-concept experiment on\n2D retinal images. Code and 3D results are available at\nhttps://github.com/miccai2023anony/RenalVesselSeg",
        "translated": ""
    },
    {
        "title": "SelfClean: A Self-Supervised Data Cleaning Strategy",
        "url": "http://arxiv.org/abs/2305.17048v1",
        "pub_date": "2023-05-26",
        "summary": "Most commonly used benchmark datasets for computer vision contain irrelevant\nimages, near duplicates, and label errors. Consequently, model performance on\nthese benchmarks may not be an accurate estimate of generalization ability.\nThis is a particularly acute concern in computer vision for medicine where\ndatasets are typically small, stakes are high, and annotation processes are\nexpensive and error-prone. In this paper, we propose SelfClean, a general\nprocedure to clean up image datasets exploiting a latent space learned with\nself-supervision. By relying on self-supervised learning, our approach focuses\non intrinsic properties of the data and avoids annotation biases. We formulate\ndataset cleaning as either a set of ranking problems, where human experts can\nmake decisions with significantly reduced effort, or a set of scoring problems,\nwhere decisions can be fully automated based on score distributions. We compare\nSelfClean against other algorithms on common computer vision benchmarks\nenhanced with synthetic noise and demonstrate state-of-the-art performance on\ndetecting irrelevant images, near duplicates, and label errors. In addition, we\napply our method to multiple image datasets and confirm an improvement in\nevaluation reliability.",
        "translated": ""
    },
    {
        "title": "RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths",
        "url": "http://arxiv.org/abs/2305.18295v1",
        "pub_date": "2023-05-29",
        "summary": "Text-to-image generation has recently witnessed remarkable achievements. We\nintroduce a text-conditional image diffusion model, termed RAPHAEL, to generate\nhighly artistic images, which accurately portray the text prompts, encompassing\nmultiple nouns, adjectives, and verbs. This is achieved by stacking tens of\nmixture-of-experts (MoEs) layers, i.e., space-MoE and time-MoE layers, enabling\nbillions of diffusion paths (routes) from the network input to the output. Each\npath intuitively functions as a \"painter\" for depicting a particular textual\nconcept onto a specified image region at a diffusion timestep. Comprehensive\nexperiments reveal that RAPHAEL outperforms recent cutting-edge models, such as\nStable Diffusion, ERNIE-ViLG 2.0, DeepFloyd, and DALL-E 2, in terms of both\nimage quality and aesthetic appeal. Firstly, RAPHAEL exhibits superior\nperformance in switching images across diverse styles, such as Japanese comics,\nrealism, cyberpunk, and ink illustration. Secondly, a single model with three\nbillion parameters, trained on 1,000 A100 GPUs for two months, achieves a\nstate-of-the-art zero-shot FID score of 6.61 on the COCO dataset. Furthermore,\nRAPHAEL significantly surpasses its counterparts in human evaluation on the\nViLG-300 benchmark. We believe that RAPHAEL holds the potential to propel the\nfrontiers of image generation research in both academia and industry, paving\nthe way for future breakthroughs in this rapidly evolving field. More details\ncan be found on a project webpage: https://raphael-painter.github.io/.",
        "translated": ""
    },
    {
        "title": "Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept\n  Customization of Diffusion Models",
        "url": "http://arxiv.org/abs/2305.18292v1",
        "pub_date": "2023-05-29",
        "summary": "Public large-scale text-to-image diffusion models, such as Stable Diffusion,\nhave gained significant attention from the community. These models can be\neasily customized for new concepts using low-rank adaptations (LoRAs). However,\nthe utilization of multiple concept LoRAs to jointly support multiple\ncustomized concepts presents a challenge. We refer to this scenario as\ndecentralized multi-concept customization, which involves single-client concept\ntuning and center-node concept fusion. In this paper, we propose a new\nframework called Mix-of-Show that addresses the challenges of decentralized\nmulti-concept customization, including concept conflicts resulting from\nexisting single-client LoRA tuning and identity loss during model fusion.\nMix-of-Show adopts an embedding-decomposed LoRA (ED-LoRA) for single-client\ntuning and gradient fusion for the center node to preserve the in-domain\nessence of single concepts and support theoretically limitless concept fusion.\nAdditionally, we introduce regionally controllable sampling, which extends\nspatially controllable sampling (e.g., ControlNet and T2I-Adaptor) to address\nattribute binding and missing object problems in multi-concept sampling.\nExtensive experiments demonstrate that Mix-of-Show is capable of composing\nmultiple customized concepts with high fidelity, including characters, objects,\nand scenes.",
        "translated": ""
    },
    {
        "title": "LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and\n  Unlabeled Image Collections",
        "url": "http://arxiv.org/abs/2305.18287v1",
        "pub_date": "2023-05-29",
        "summary": "Recently, large-scale pre-trained Vision and Language (VL) models have set a\nnew state-of-the-art (SOTA) in zero-shot visual classification enabling\nopen-vocabulary recognition of potentially unlimited set of categories defined\nas simple language prompts. However, despite these great advances, the\nperformance of these zeroshot classifiers still falls short of the results of\ndedicated (closed category set) classifiers trained with supervised fine\ntuning. In this paper we show, for the first time, how to reduce this gap\nwithout any labels and without any paired VL data, using an unlabeled image\ncollection and a set of texts auto-generated using a Large Language Model (LLM)\ndescribing the categories of interest and effectively substituting labeled\nvisual instances of those categories. Using our label-free approach, we are\nable to attain significant performance improvements over the zero-shot\nperformance of the base VL model and other contemporary methods and baselines\non a wide variety of datasets, demonstrating absolute improvement of up to\n11.7% (3.8% on average) in the label-free setting. Moreover, despite our\napproach being label-free, we observe 1.3% average gains over leading few-shot\nprompting baselines that do use 5-shot supervision.",
        "translated": ""
    },
    {
        "title": "Photoswap: Personalized Subject Swapping in Images",
        "url": "http://arxiv.org/abs/2305.18286v1",
        "pub_date": "2023-05-29",
        "summary": "In an era where images and visual content dominate our digital landscape, the\nability to manipulate and personalize these images has become a necessity.\nEnvision seamlessly substituting a tabby cat lounging on a sunlit window sill\nin a photograph with your own playful puppy, all while preserving the original\ncharm and composition of the image. We present Photoswap, a novel approach that\nenables this immersive image editing experience through personalized subject\nswapping in existing images. Photoswap first learns the visual concept of the\nsubject from reference images and then swaps it into the target image using\npre-trained diffusion models in a training-free manner. We establish that a\nwell-conceptualized visual subject can be seamlessly transferred to any image\nwith appropriate self-attention and cross-attention manipulation, maintaining\nthe pose of the swapped subject and the overall coherence of the image.\nComprehensive experiments underscore the efficacy and controllability of\nPhotoswap in personalized subject swapping. Furthermore, Photoswap\nsignificantly outperforms baseline methods in human ratings across subject\nswapping, background preservation, and overall quality, revealing its vast\napplication potential, from entertainment to professional editing.",
        "translated": ""
    },
    {
        "title": "Contextual Object Detection with Multimodal Large Language Models",
        "url": "http://arxiv.org/abs/2305.18279v1",
        "pub_date": "2023-05-29",
        "summary": "Recent Multimodal Large Language Models (MLLMs) are remarkable in\nvision-language tasks, such as image captioning and question answering, but\nlack the essential perception ability, i.e., object detection. In this work, we\naddress this limitation by introducing a novel research problem of contextual\nobject detection -- understanding visible objects within different human-AI\ninteractive contexts. Three representative scenarios are investigated,\nincluding the language cloze test, visual captioning, and question answering.\nMoreover, we present ContextDET, a unified multimodal model that is capable of\nend-to-end differentiable modeling of visual-language contexts, so as to\nlocate, identify, and associate visual objects with language inputs for\nhuman-AI interaction. Our ContextDET involves three key submodels: (i) a visual\nencoder for extracting visual representations, (ii) a pre-trained LLM for\nmultimodal context decoding, and (iii) a visual decoder for predicting bounding\nboxes given contextual object words. The new generate-then-detect framework\nenables us to detect object words within human vocabulary. Extensive\nexperiments show the advantages of ContextDET on our proposed CODE benchmark,\nopen-vocabulary detection, and referring image segmentation. Github:\nhttps://github.com/yuhangzang/ContextDET.",
        "translated": ""
    },
    {
        "title": "3DTeethSeg'22: 3D Teeth Scan Segmentation and Labeling Challenge",
        "url": "http://arxiv.org/abs/2305.18277v1",
        "pub_date": "2023-05-29",
        "summary": "Teeth localization, segmentation, and labeling from intra-oral 3D scans are\nessential tasks in modern dentistry to enhance dental diagnostics, treatment\nplanning, and population-based studies on oral health. However, developing\nautomated algorithms for teeth analysis presents significant challenges due to\nvariations in dental anatomy, imaging protocols, and limited availability of\npublicly accessible data. To address these challenges, the 3DTeethSeg'22\nchallenge was organized in conjunction with the International Conference on\nMedical Image Computing and Computer Assisted Intervention (MICCAI) in 2022,\nwith a call for algorithms tackling teeth localization, segmentation, and\nlabeling from intraoral 3D scans. A dataset comprising a total of 1800 scans\nfrom 900 patients was prepared, and each tooth was individually annotated by a\nhuman-machine hybrid algorithm. A total of 6 algorithms were evaluated on this\ndataset. In this study, we present the evaluation results of the 3DTeethSeg'22\nchallenge. The 3DTeethSeg'22 challenge code can be accessed at:\nhttps://github.com/abenhamadou/3DTeethSeg22_challenge",
        "translated": ""
    },
    {
        "title": "Reconstructing the Mind's Eye: fMRI-to-Image with Contrastive Learning\n  and Diffusion Priors",
        "url": "http://arxiv.org/abs/2305.18274v1",
        "pub_date": "2023-05-29",
        "summary": "We present MindEye, a novel fMRI-to-image approach to retrieve and\nreconstruct viewed images from brain activity. Our model comprises two parallel\nsubmodules that are specialized for retrieval (using contrastive learning) and\nreconstruction (using a diffusion prior). MindEye can map fMRI brain activity\nto any high dimensional multimodal latent space, like CLIP image space,\nenabling image reconstruction using generative models that accept embeddings\nfrom this latent space. We comprehensively compare our approach with other\nexisting methods, using both qualitative side-by-side comparisons and\nquantitative evaluations, and show that MindEye achieves state-of-the-art\nperformance in both reconstruction and retrieval tasks. In particular, MindEye\ncan retrieve the exact original image even among highly similar candidates\nindicating that its brain embeddings retain fine-grained image-specific\ninformation. This allows us to accurately retrieve images even from large-scale\ndatabases like LAION-5B. We demonstrate through ablations that MindEye's\nperformance improvements over previous methods result from specialized\nsubmodules for retrieval and reconstruction, improved training techniques, and\ntraining models with orders of magnitude more parameters. Furthermore, we show\nthat MindEye can better preserve low-level image features in the\nreconstructions by using img2img, with outputs from a separate autoencoder. All\ncode is available on GitHub.",
        "translated": ""
    },
    {
        "title": "Pix2Repair: Implicit Shape Restoration from Images",
        "url": "http://arxiv.org/abs/2305.18273v1",
        "pub_date": "2023-05-29",
        "summary": "We present Pix2Repair, an automated shape repair approach that generates\nrestoration shapes from images to repair fractured objects. Prior repair\napproaches require a high-resolution watertight 3D mesh of the fractured object\nas input. Input 3D meshes must be obtained using expensive 3D scanners, and\nscanned meshes require manual cleanup, limiting accessibility and scalability.\nPix2Repair takes an image of the fractured object as input and automatically\ngenerates a 3D printable restoration shape. We contribute a novel shape\nfunction that deconstructs a latent code representing the fractured object into\na complete shape and a break surface. We show restorations for synthetic\nfractures from the Geometric Breaks and Breaking Bad datasets, and cultural\nheritage objects from the QP dataset, and for real fractures from the Fantastic\nBreaks dataset. We overcome challenges in restoring axially symmetric objects\nby predicting view-centered restorations. Our approach outperforms shape\ncompletion approaches adapted for shape repair in terms of chamfer distance,\nearth mover's distance, normal consistency, and percent restorations generated.",
        "translated": ""
    },
    {
        "title": "Gen-L-Video: Multi-Text to Long Video Generation via Temporal\n  Co-Denoising",
        "url": "http://arxiv.org/abs/2305.18264v1",
        "pub_date": "2023-05-29",
        "summary": "Leveraging large-scale image-text datasets and advancements in diffusion\nmodels, text-driven generative models have made remarkable strides in the field\nof image generation and editing. This study explores the potential of extending\nthe text-driven ability to the generation and editing of multi-text conditioned\nlong videos. Current methodologies for video generation and editing, while\ninnovative, are often confined to extremely short videos (typically less than\n24 frames) and are limited to a single text condition. These constraints\nsignificantly limit their applications given that real-world videos usually\nconsist of multiple segments, each bearing different semantic information. To\naddress this challenge, we introduce a novel paradigm dubbed as Gen-L-Video,\ncapable of extending off-the-shelf short video diffusion models for generating\nand editing videos comprising hundreds of frames with diverse semantic segments\nwithout introducing additional training, all while preserving content\nconsistency. We have implemented three mainstream text-driven video generation\nand editing methodologies and extended them to accommodate longer videos imbued\nwith a variety of semantic segments with our proposed paradigm. Our\nexperimental outcomes reveal that our approach significantly broadens the\ngenerative and editing capabilities of video diffusion models, offering new\npossibilities for future research and applications. The code is available at\nhttps://github.com/G-U-N/Gen-L-Video.",
        "translated": ""
    },
    {
        "title": "Synfeal: A Data-Driven Simulator for End-to-End Camera Localization",
        "url": "http://arxiv.org/abs/2305.18260v1",
        "pub_date": "2023-05-29",
        "summary": "Collecting real-world data is often considered the bottleneck of Artificial\nIntelligence, stalling the research progress in several fields, one of which is\ncamera localization. End-to-end camera localization methods are still\noutperformed by traditional methods, and we argue that the inconsistencies\nassociated with the data collection techniques are restraining the potential of\nend-to-end methods. Inspired by the recent data-centric paradigm, we propose a\nframework that synthesizes large localization datasets based on realistic 3D\nreconstructions of the real world. Our framework, termed Synfeal: Synthetic\nfrom Real, is an open-source, data-driven simulator that synthesizes RGB images\nby moving a virtual camera through a realistic 3D textured mesh, while\ncollecting the corresponding ground-truth camera poses. The results validate\nthat the training of camera localization algorithms on datasets generated by\nSynfeal leads to better results when compared to datasets generated by\nstate-of-the-art methods. Using Synfeal, we conducted the first analysis of the\nrelationship between the size of the dataset and the performance of camera\nlocalization algorithms. Results show that the performance significantly\nincreases with the dataset size. Our results also suggest that when a large\nlocalization dataset with high quality is available, training from scratch\nleads to better performances. Synfeal is publicly available at\nhttps://github.com/DanielCoelho112/synfeal.",
        "translated": ""
    },
    {
        "title": "Forensic Video Steganalysis in Spatial Domain by Noise Residual\n  Convolutional Neural Network",
        "url": "http://arxiv.org/abs/2305.18070v1",
        "pub_date": "2023-05-29",
        "summary": "This research evaluates a convolutional neural network (CNN) based approach\nto forensic video steganalysis. A video steganography dataset is created to\ntrain a CNN to conduct forensic steganalysis in the spatial domain. We use a\nnoise residual convolutional neural network to detect embedded secrets since a\nsteganographic embedding process will always result in the modification of\npixel values in video frames. Experimental results show that the CNN-based\napproach can be an effective method for forensic video steganalysis and can\nreach a detection rate of 99.96%. Keywords: Forensic, Steganalysis, Deep\nSteganography, MSU StegoVideo, Convolutional Neural Networks",
        "translated": "这项研究评估了一种基于卷积神经网络(CNN)的法医视频隐写分析方法。建立了一个视频隐写数据集，用于训练 CNN 在空间域中进行取证隐写分析。我们使用噪声残余卷积神经网络来检测嵌入的秘密，因为隐写嵌入过程总是会导致视频帧中像素值的修改。实验结果表明，基于细胞神经网络的方法是一种有效的法医视频隐写分析方法，检测率可达99.96% 。关键词: 取证，隐写分析，深度隐写术，MSU 隐写视频，卷积神经网络"
    },
    {
        "title": "Key Rate Analysis of a 3-State Twin-Field Quantum Key Distribution\n  Protocol in the Finite-key Regime",
        "url": "http://arxiv.org/abs/2305.18006v2",
        "pub_date": "2023-05-29",
        "summary": "When analysing Quantum Key Distribution (QKD) protocols several metrics can\nbe determined, but one of the most important is the Secret Key Rate. The Secret\nKey Rate is the number of bits per transmission that result in being part of a\nSecret Key between two parties. There are equations that give the Secret Key\nRate, for example, for the BB84 protocol, equation 52 from [1, p.1032] gives\nthe Secret Key Rate for a given Quantum Bit Error Rate (QBER). However, the\nanalysis leading to equations such as these often rely on an Asymptotic\napproach, where it is assumed that an infinite number of transmissions are sent\nbetween the two communicating parties (henceforth denoted as Alice and Bob). In\na practical implementation this is obviously impossible. Moreover, some QKD\nprotocols belong to a category called Asymmetric protocols, for which it is\nsignificantly more difficult to perform such an analysis. As such, there is\ncurrently a lot of investigation into a different approach called the\nFinite-key regime. Work by Bunandar et al. [2] has produced code that used\nSemi-Definite Programming to produce lower bounds on the Secret Key Rate of\neven Asymmetric protocols. Our work looks at devising a novel QKD protocol\ntaking inspiration from both the 3-state version of BB84 [3], and the\nTwin-Field protocol [4], and then using this code to perform analysis of the\nnew protocol.",
        "translated": "在分析量子密钥分配(QKD)协议时，可以确定几个度量，但其中最重要的是密钥速率。密钥速率是每次传输的比特数，它导致成为双方之间密钥的一部分。有些公式给出了密钥速率，例如 BB84协议，[1，p. 1032]中的公式52给出了给定量子误码率(QBER)的密钥速率。然而，导致这些方程的分析往往依赖于渐近方法，其中假定在两个通信方之间发送无限数量的传输(以下称为 Alice 和 Bob)。在实际的实现中，这显然是不可能的。此外，一些 QKD 协议属于一类称为非对称协议，其中执行这样的分析是非常困难的。因此，目前有很多研究的不同的方法称为有限键制度。Bunandar 等人的工作[2]已经产生了使用半定规划产生甚至非对称协议的秘密密钥速率的下界的代码。我们的工作着眼于设计一个新颖的 QKD 协议，从 BB84的三态版本[3]和双场协议[4]中获得灵感，然后使用这个代码来执行新协议的分析。"
    },
    {
        "title": "On the Minimal Knowledge Required for Solving Stellar Consensus",
        "url": "http://arxiv.org/abs/2305.17989v1",
        "pub_date": "2023-05-29",
        "summary": "Byzantine Consensus is fundamental for building consistent and fault-tolerant\ndistributed systems. In traditional quorum-based consensus protocols, quorums\nare defined using globally known assumptions shared among all participants.\nMotivated by decentralized applications on open networks, the Stellar\nblockchain relaxes these global assumptions by allowing each participant to\ndefine its quorums using local information. A similar model called Consensus\nwith Unknown Participants (CUP) studies the minimal knowledge required to solve\nconsensus in ad-hoc networks where each participant knows only a subset of\nother participants of the system. We prove that Stellar cannot solve consensus\nusing the initial knowledge provided to participants in the CUP model, even\nthough CUP can. We propose an oracle called sink detector that augments this\nknowledge, enabling Stellar participants to solve consensus.",
        "translated": "拜占庭共识是构建一致性和容错分布式系统的基础。在传统的基于仲裁的协商一致协议中，仲裁是使用所有参与者共享的全局已知假设来定义的。受到开放网络上分散应用的激励，Stellar 区块链通过允许每个参与者使用本地信息定义其法定人数来放松这些全球假设。一个类似的模型称为“与未知参与者达成共识”(CUP) ，它研究在每个参与者只知道系统中其他参与者的一个子集的特定网络中解决达成共识所需的最小知识。我们证明，Stellar 不能利用 CUP 模型中提供给参与者的初始知识来解决一致性问题，即使 CUP 可以。我们提出了一个称为汇检测器的甲骨文，以增加这方面的知识，使恒星的参与者解决共识。"
    },
    {
        "title": "An Experimental Analysis of RowHammer in HBM2 DRAM Chips",
        "url": "http://arxiv.org/abs/2305.17918v1",
        "pub_date": "2023-05-29",
        "summary": "RowHammer (RH) is a significant and worsening security, safety, and\nreliability issue of modern DRAM chips that can be exploited to break memory\nisolation. Therefore, it is important to understand real DRAM chips' RH\ncharacteristics. Unfortunately, no prior work extensively studies the RH\nvulnerability of modern 3D-stacked high-bandwidth memory (HBM) chips, which are\ncommonly used in modern GPUs.\n  In this work, we experimentally characterize the RH vulnerability of a real\nHBM2 DRAM chip. We show that 1) different 3D-stacked channels of HBM2 memory\nexhibit significantly different levels of RH vulnerability (up to 79%\ndifference in bit error rate), 2) the DRAM rows at the end of a DRAM bank (rows\nwith the highest addresses) exhibit significantly fewer RH bitflips than other\nrows, and 3) a modern HBM2 DRAM chip implements undisclosed RH defenses that\nare triggered by periodic refresh operations. We describe the implications of\nour observations on future RH attacks and defenses and discuss future work for\nunderstanding RH in 3D-stacked memories.",
        "translated": "RowHammer (RH)是现代 DRAM 芯片的一个重要且日益严重的安全性、安全性和可靠性问题，可用于打破内存隔离。因此，了解真实 DRAM 芯片的 RH 特性具有重要意义。不幸的是，没有先前的工作广泛研究现代3D 堆叠高带宽存储器(HBM)芯片的 RH 漏洞，这是在现代 GPU 中常用的。在这项工作中，我们实验性地刻画了一个真正的 HBM2 DRAM 芯片的 RH 漏洞。我们表明: 1)不同的3D 堆叠通道的 HBM2存储器表现出显着不同的 RH 脆弱性水平(比特错误率高达79% 的差异) ，2) DRAM 银行结束的 DRAM 行(具有最高地址的行)表现出明显较少的 RH 位翻转比其他行，3)现代 HBM2 DRAM 芯片实现未公开的 RH 防御，由定期刷新操作触发。我们描述了我们的观察对未来 RH 攻击和防御的影响，并讨论了未来在3D 堆积记忆中理解 RH 的工作。"
    },
    {
        "title": "ACETest: Automated Constraint Extraction for Testing Deep Learning\n  Operators",
        "url": "http://arxiv.org/abs/2305.17914v1",
        "pub_date": "2023-05-29",
        "summary": "Deep learning (DL) applications are prevalent nowadays as they can help with\nmultiple tasks. DL libraries are essential for building DL applications.\nFurthermore, DL operators are the important building blocks of the DL\nlibraries, that compute the multi-dimensional data (tensors). Therefore, bugs\nin DL operators can have great impacts. Testing is a practical approach for\ndetecting bugs in DL operators. In order to test DL operators effectively, it\nis essential that the test cases pass the input validity check and are able to\nreach the core function logic of the operators. Hence, extracting the input\nvalidation constraints is required for generating high-quality test cases.\nExisting techniques rely on either human effort or documentation of DL library\nAPIs to extract the constraints. They cannot extract complex constraints and\nthe extracted constraints may differ from the actual code implementation.\n  To address the challenge, we propose ACETest, a technique to automatically\nextract input validation constraints from the code to build valid yet diverse\ntest cases which can effectively unveil bugs in the core function logic of DL\noperators. For this purpose, ACETest can automatically identify the input\nvalidation code in DL operators, extract the related constraints and generate\ntest cases according to the constraints. The experimental results on popular DL\nlibraries, TensorFlow and PyTorch, demonstrate that ACETest can extract\nconstraints with higher quality than state-of-the-art (SOTA) techniques.\nMoreover, ACETest is capable of extracting 96.4% more constraints and detecting\n1.95 to 55 times more bugs than SOTA techniques. In total, we have used ACETest\nto detect 108 previously unknown bugs on TensorFlow and PyTorch, with 87 of\nthem confirmed by the developers. Lastly, five of the bugs were assigned with\nCVE IDs due to their security impacts.",
        "translated": "深度学习(DL)应用程序现在很流行，因为它们可以帮助完成多个任务。DL 库对于构建 DL 应用程序是必不可少的。此外，DL 运算符是计算多维数据(张量)的 DL 库的重要组成部分。因此，DL 操作符中的 bug 会产生很大的影响。测试是检测 DL 操作符错误的一种实用方法。为了有效地测试 DL 算子，测试用例必须通过输入有效性检验，并且能够达到算子的核心函数逻辑。因此，提取输入验证约束是生成高质量测试用例所必需的。现有技术依赖于人工或 DL 库 API 的文档来提取约束。它们不能提取复杂的约束，并且提取的约束可能与实际的代码实现不同。为了应对这一挑战，我们提出了 ACETest，这是一种从代码中自动提取输入验证约束的技术，可以构建有效且多样化的测试用例，有效地揭示 DL 操作符核心功能逻辑中的缺陷。为此，ACETest 可以自动识别 DL 运算符中的输入验证代码，提取相关约束，并根据约束生成测试用例。在流行的 DL 库 TensorFlow 和 PyTorch 上的实验结果表明，ACETest 提取约束的质量比最先进的 SOTA (state-of-art)技术更高。此外，与 SOTA 技术相比，ACETest 能够提取96.4% 以上的约束，检测到1.95到55倍以上的错误。总的来说，我们已经使用 ACETest 检测了 TensorFlow 和 PyTorch 上108个以前未知的 bug，其中87个已经被开发人员证实。最后，由于安全影响，五个 bug 被分配到 CVE ID 中。"
    },
    {
        "title": "Reversible Deep Neural Network Watermarking:Matching the Floating-point\n  Weights",
        "url": "http://arxiv.org/abs/2305.17879v1",
        "pub_date": "2023-05-29",
        "summary": "Static deep neural network (DNN) watermarking embeds watermarks into the\nweights of DNN model by irreversible methods, but this will cause permanent\ndamage to watermarked model and can not meet the requirements of integrity\nauthentication. For these reasons, reversible data hiding (RDH) seems more\nattractive for the copyright protection of DNNs. This paper proposes a novel\nRDH-based static DNN watermarking method by improving the non-reversible\nquantization index modulation (QIM). Targeting the floating-point weights of\nDNNs, the idea of our RDH method is to add a scaled quantization error back to\nthe cover object. Two schemes are designed to realize the integrity protection\nand legitimate authentication of DNNs. Simulation results on training loss and\nclassification accuracy justify the superior feasibility, effectiveness and\nadaptability of the proposed method over histogram shifting (HS).",
        "translated": "静态深度神经网络(DNN)水印通过不可逆的方法将水印嵌入到 DNN 模型的权值中，但这会对水印模型造成永久性的损伤，不能满足完整性认证的要求。由于这些原因，可逆数据隐藏(RDH)似乎对 DNN 的版权保护更具吸引力。提出了一种基于 RDH 的静态 DNN 水印算法，改进了不可逆量化指数调制(QIM)算法。针对 DNN 的浮点权重，我们的 RDH 方法的想法是将一个按比例缩放的量化噪声重新添加到盖对象。设计了两种方案来实现 DNN 的完整性保护和合法认证。训练损失和分类精度的仿真结果证明了该方法优于直方图移位(HS)的可行性、有效性和适应性。"
    },
    {
        "title": "NaturalFinger: Generating Natural Fingerprint with Generative\n  Adversarial Networks",
        "url": "http://arxiv.org/abs/2305.17868v1",
        "pub_date": "2023-05-29",
        "summary": "Deep neural network (DNN) models have become a critical asset of the model\nowner as training them requires a large amount of resource (i.e. labeled data).\nTherefore, many fingerprinting schemes have been proposed to safeguard the\nintellectual property (IP) of the model owner against model extraction and\nillegal redistribution. However, previous schemes adopt unnatural images as the\nfingerprint, such as adversarial examples and noisy images, which can be easily\nperceived and rejected by the adversary. In this paper, we propose\nNaturalFinger which generates natural fingerprint with generative adversarial\nnetworks (GANs). Besides, our proposed NaturalFinger fingerprints the decision\ndifference areas rather than the decision boundary, which is more robust. The\napplication of GAN not only allows us to generate more imperceptible samples,\nbut also enables us to generate unrestricted samples to explore the decision\nboundary.To demonstrate the effectiveness of our fingerprint approach, we\nevaluate our approach against four model modification attacks including\nadversarial training and two model extraction attacks. Experiments show that\nour approach achieves 0.91 ARUC value on the FingerBench dataset (154 models),\nexceeding the optimal baseline (MetaV) over 17\\%.",
        "translated": "深度神经网络(DNN)模型已经成为模型所有者的重要资产，因为训练它们需要大量的资源(即标记数据)。因此，人们提出了许多指纹识别方案来保护模型所有者的知识产权，防止模型提取和非法再分配。然而，以往的方案都是采用非自然的图像作为指纹，如对手的例子和噪声图像，这些都很容易被对手察觉和排斥。本文提出了一种利用生成对抗网络(GAN)生成自然指纹的 NaturalFinger 方法。此外，我们提出的 NaturalFinger 能够识别决策差异区域，而不是更加健壮的决策边界。GAN 的应用不仅使我们能够生成更多不易察觉的样本，而且使我们能够生成不受限制的样本来探索决策边界。为了证明我们的指纹方法的有效性，我们评估了我们的方法对抗四种模型修改攻击，包括对抗性训练和两种模型提取攻击。实验表明，我们的方法在 FingerBench 数据集(154个模型)上达到了0.91 ARUC 值，超过了最佳基线(MetaV)的17% 以上。"
    },
    {
        "title": "NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models",
        "url": "http://arxiv.org/abs/2305.17826v1",
        "pub_date": "2023-05-28",
        "summary": "Prompt-based learning is vulnerable to backdoor attacks. Existing backdoor\nattacks against prompt-based models consider injecting backdoors into the\nentire embedding layers or word embedding vectors. Such attacks can be easily\naffected by retraining on downstream tasks and with different prompting\nstrategies, limiting the transferability of backdoor attacks. In this work, we\npropose transferable backdoor attacks against prompt-based models, called\nNOTABLE, which is independent of downstream tasks and prompting strategies.\nSpecifically, NOTABLE injects backdoors into the encoders of PLMs by utilizing\nan adaptive verbalizer to bind triggers to specific words (i.e., anchors). It\nactivates the backdoor by pasting input with triggers to reach\nadversary-desired anchors, achieving independence from downstream tasks and\nprompting strategies. We conduct experiments on six NLP tasks, three popular\nmodels, and three prompting strategies. Empirical results show that NOTABLE\nachieves superior attack performance (i.e., attack success rate over 90% on all\nthe datasets), and outperforms two state-of-the-art baselines. Evaluations on\nthree defenses show the robustness of NOTABLE. Our code can be found at\nhttps://github.com/RU-System-Software-and-Security/Notable.",
        "translated": "基于提示的学习很容易受到后门攻击。针对基于提示的模型的现有后门攻击考虑将后门注入到整个嵌入层或单词嵌入向量中。这种攻击很容易受到下游任务的再培训和不同的激励策略的影响，从而限制了后门攻击的可转移性。在这项工作中，我们提出了可转移的后门攻击对提示为基础的模型，称为 NOTABLE，这是独立于下游任务和提示策略。具体来说，NOTABLE 通过使用自适应语言表达器将触发器绑定到特定的单词(即锚) ，从而向 PLM 的编码器注入后门。它通过粘贴带有触发器的输入来激活后门，从而达到对手想要的锚，实现对下游任务的独立性并提示策略。我们对六个自然语言处理任务、三个流行的模型和三种激励策略进行了实验。实验结果表明，NOTABLE 具有更好的攻击性能(即所有数据集的攻击成功率都超过90%) ，并且优于两个最先进的基线。对三种防御机制的评估显示了 NOTABLE 的鲁棒性。我们的代码可以在 https://github.com/ru-system-software-and-security/notable 找到。"
    },
    {
        "title": "Ceibaco: REST API and Single Page Application for the generation and\n  evaluation of bijective S-boxes",
        "url": "http://arxiv.org/abs/2305.17798v1",
        "pub_date": "2023-05-28",
        "summary": "In this paper we present the first REST API for the generation and evaluation\nof bijective S-boxes. We also present the first Single Page Application tool\nfor researchers and students that allows the use of a graphical interface. We\ngive a small dataset of classical S-boxes to test the properties evaluations.\nWe show how to define experiments and we include two local search experiments\ninto the proposed tool.",
        "translated": "在本文中，我们提出了第一个 RESTAPI 的生成和评价双射 S 盒。我们还为研究人员和学生提供了第一个允许使用图形界面的单页应用程序工具。我们给出了一个经典 S- 盒的小数据集来检验性质的评价。我们展示了如何定义实验，我们包括两个局部搜索实验到提出的工具。"
    },
    {
        "title": "Amplification trojan network: Attack deep neural networks by amplifying\n  their inherent weakness",
        "url": "http://arxiv.org/abs/2305.17688v1",
        "pub_date": "2023-05-28",
        "summary": "Recent works found that deep neural networks (DNNs) can be fooled by\nadversarial examples, which are crafted by adding adversarial noise on clean\ninputs. The accuracy of DNNs on adversarial examples will decrease as the\nmagnitude of the adversarial noise increase. In this study, we show that DNNs\ncan be also fooled when the noise is very small under certain circumstances.\nThis new type of attack is called Amplification Trojan Attack (ATAttack).\nSpecifically, we use a trojan network to transform the inputs before sending\nthem to the target DNN. This trojan network serves as an amplifier to amplify\nthe inherent weakness of the target DNN. The target DNN, which is infected by\nthe trojan network, performs normally on clean data while being more vulnerable\nto adversarial examples. Since it only transforms the inputs, the trojan\nnetwork can hide in DNN-based pipelines, e.g. by infecting the pre-processing\nprocedure of the inputs before sending them to the DNNs. This new type of\nthreat should be considered in developing safe DNNs.",
        "translated": "最近的研究发现，深层神经网络(DNN)可以被敌对的例子所愚弄，这些例子是通过在干净的输入上添加敌对的噪音而精心设计的。随着对抗噪声的大小增加，DNN 对对抗性实例的准确性将下降。在这项研究中，我们表明，DNN 也可以被愚弄，当噪音是非常小，在某些情况下。这种新型的攻击被称为放大木马攻击。具体来说，我们使用特洛伊木马网络来转换输入，然后将它们发送给目标 DNN。这种木马网络充当放大器，放大目标 DNN 固有的弱点。目标 DNN 被特洛伊木马网络感染，正常执行干净的数据，但更容易受到对手的例子。由于木马网络只转换输入，因此它可以隐藏在基于 DNN 的管道中，例如在将输入发送给 DNN 之前感染输入的预处理过程。在开发安全的 DNN 时，应该考虑这种新型威胁。"
    },
    {
        "title": "What Can We Learn from Unlearnable Datasets?",
        "url": "http://arxiv.org/abs/2305.19254v1",
        "pub_date": "2023-05-30",
        "summary": "In an era of widespread web scraping, unlearnable dataset methods have the\npotential to protect data privacy by preventing deep neural networks from\ngeneralizing. But in addition to a number of practical limitations that make\ntheir use unlikely, we make a number of findings that call into question their\nability to safeguard data. First, it is widely believed that neural networks\ntrained on unlearnable datasets only learn shortcuts, simpler rules that are\nnot useful for generalization. In contrast, we find that networks actually can\nlearn useful features that can be reweighed for high test performance,\nsuggesting that image privacy is not preserved. Unlearnable datasets are also\nbelieved to induce learning shortcuts through linear separability of added\nperturbations. We provide a counterexample, demonstrating that linear\nseparability of perturbations is not a necessary condition. To emphasize why\nlinearly separable perturbations should not be relied upon, we propose an\northogonal projection attack which allows learning from unlearnable datasets\npublished in ICML 2021 and ICLR 2023. Our proposed attack is significantly less\ncomplex than recently proposed techniques.",
        "translated": "在一个广泛使用网页抓取的时代，不可学习的数据集方法有可能通过阻止深层神经网络泛化来保护数据隐私。但是，除了一些实际的限制，使他们的使用不太可能，我们作出了一些调查结果，质疑他们的能力，以保护数据。首先，人们普遍认为，在不可学习的数据集上训练的神经网络只学习快捷方式，简单的规则对泛化没有用处。相比之下，我们发现网络实际上可以学习有用的功能，可以重新权衡高测试性能，这表明图像隐私没有得到保护。无法学习的数据集也被认为能够通过线性可分的的扰动诱导学习捷径。我们提供了一个反例，证明了扰动的线性可分的不是一个必要条件。为了强调为什么不应该依赖于线性可分离的扰动，我们提出了一种正交投影攻击，它允许从 ICML 2021和 ICLR 2023发布的不可学习的数据集中学习。我们提出的攻击比最近提出的技术要简单得多。"
    },
    {
        "title": "Accountable authentication with privacy protection: The Larch system for\n  universal login",
        "url": "http://arxiv.org/abs/2305.19241v1",
        "pub_date": "2023-05-30",
        "summary": "Credential compromise is hard to detect and hard to mitigate. To address this\nproblem, we present larch, an accountable authentication framework with strong\nsecurity and privacy properties. Larch protects user privacy while ensuring\nthat the larch log server correctly records every authentication. Specifically,\nan attacker who compromises a user's device cannot authenticate without\ncreating evidence in the log, and the log cannot learn which web service\n(relying party) the user is authenticating to. To enable fast adoption, larch\nis backwards-compatible with relying parties that support FIDO2, TOTP, and\npassword-based login. Furthermore, larch does not degrade the security and\nprivacy a user already expects: the log server cannot authenticate on behalf of\na user, and larch does not allow relying parties to link a user across\naccounts. We implement larch for FIDO2, TOTP, and password-based login. Given a\nclient with four cores and a log server with eight cores, an authentication\nwith larch takes 150ms for FIDO2, 91ms for TOTP, and 74ms for passwords\n(excluding preprocessing, which takes 1.23s for TOTP).",
        "translated": "证书妥协很难被发现，也很难被减轻。为了解决这个问题，我们提出了落叶松，一个可靠的认证框架，具有强大的安全性和隐私属性。落叶松保护用户隐私，同时确保落叶松日志服务器正确记录每个身份验证。具体来说，攻击用户设备的攻击者如果不在日志中创建证据，就无法进行身份验证，而日志也无法知道用户正在向哪个 Web 服务(依赖方)进行身份验证。为了能够快速采用，落叶松是向后兼容的依赖方，支持 FIDO2，TOTP 和基于密码的登录。此外，落叶松不会降低用户已经预期的安全性和隐私: 日志服务器不能代表用户进行身份验证，而且落叶松不允许依赖方跨账户链接用户。我们为 FIDO2、 TOTP 和基于密码的登录实现了落叶松。给定一个有四个核心的客户机和一个有八个核心的日志服务器，用落叶松进行身份验证需要150ms 的 FIDO2,91ms 的 TOTP 和74ms 的密码(不包括预处理，TOTP 需要1.23 s)。"
    },
    {
        "title": "Adversarial Attacks on Online Learning to Rank with Stochastic Click\n  Models",
        "url": "http://arxiv.org/abs/2305.19218v1",
        "pub_date": "2023-05-30",
        "summary": "We propose the first study of adversarial attacks on online learning to rank.\nThe goal of the adversary is to misguide the online learning to rank algorithm\nto place the target item on top of the ranking list linear times to time\nhorizon $T$ with a sublinear attack cost. We propose generalized list poisoning\nattacks that perturb the ranking list presented to the user. This strategy can\nefficiently attack any no-regret ranker in general stochastic click models.\nFurthermore, we propose a click poisoning-based strategy named attack-then-quit\nthat can efficiently attack two representative OLTR algorithms for stochastic\nclick models. We theoretically analyze the success and cost upper bound of the\ntwo proposed methods. Experimental results based on synthetic and real-world\ndata further validate the effectiveness and cost-efficiency of the proposed\nattack strategies.",
        "translated": "我们首次提出了对网络学习中的对抗性攻击进行排名的研究。对手的目标是误导在线学习排序算法，将目标项目放在排序列表的顶部，时间跨度为线性时间跨度 $T $，带有次线性攻击成本。我们提出了广义列表中毒攻击，扰乱了提供给用户的排名列表。该策略可以有效地攻击一般随机点击模型中的任意无后悔排名。此外，我们提出了一个基于点击中毒的攻击-然后退出策略，可以有效地攻击随机点击模型的两个代表性的 OLTR 算法。我们从理论上分析了这两种方法的成功率和成本上限。基于合成数据和真实数据的实验结果进一步验证了该攻击策略的有效性和性价比。"
    },
    {
        "title": "Design and implementation of intelligent packet filtering in IoT\n  microcontroller-based devices",
        "url": "http://arxiv.org/abs/2305.19214v1",
        "pub_date": "2023-05-30",
        "summary": "Internet of Things (IoT) devices are increasingly pervasive and essential\ncomponents in enabling new applications and services. However, their widespread\nuse also exposes them to exploitable vulnerabilities and flaws that can lead to\nsignificant losses. In this context, ensuring robust cybersecurity measures is\nessential to protect IoT devices from malicious attacks. However, the current\nsolutions that provide flexible policy specifications and higher security\nlevels for IoT devices are scarce. To address this gap, we introduce T800, a\nlow-resource packet filter that utilizes machine learning (ML) algorithms to\nclassify packets in IoT devices. We present a detailed performance benchmarking\nframework and demonstrate T800's effectiveness on the ESP32 system-on-chip\nmicrocontroller and ESP-IDF framework. Our evaluation shows that T800 is an\nefficient solution that increases device computational capacity by excluding\nunsolicited malicious traffic from the processing pipeline. Additionally, T800\nis adaptable to different systems and provides a well-documented performance\nevaluation strategy for security ML-based mechanisms on ESP32-based IoT\nsystems. Our research contributes to improving the cybersecurity of\nresource-constrained IoT devices and provides a scalable, efficient solution\nthat can be used to enhance the security of IoT systems.",
        "translated": "物联网(IoT)设备在支持新的应用程序和服务方面越来越普遍和重要。然而，它们的广泛使用也使它们暴露在可利用的漏洞和缺陷之下，这些漏洞和缺陷可能导致重大损失。在这种情况下，确保强有力的网络安全措施对于保护物联网设备免受恶意攻击至关重要。然而，目前为物联网设备提供灵活策略规范和更高安全级别的解决方案很少。为了解决这个问题，我们引入了 T800，这是一个低资源包过滤器，它利用机器学习(ML)算法对物联网设备中的数据包进行分类。我们提出了一个详细的性能基准测试框架，并在 ESP32系统单片机和 ESP-IDF 框架上验证了 T800的有效性。我们的评估表明，T800是一个有效的解决方案，它通过从处理流水线中排除未经请求的恶意流量来增加设备的计算能力。此外，T800可以适应不同的系统，并且为基于 ESP32的物联网系统上基于 ML 的安全机制提供了一个有据可查的性能评估策略。我们的研究有助于改善资源受限的物联网设备的网络安全，并提供了一个可扩展的、高效的解决方案，可用于提高物联网系统的安全性。"
    },
    {
        "title": "Inferring Private Personal Attributes of Virtual Reality Users from Head\n  and Hand Motion Data",
        "url": "http://arxiv.org/abs/2305.19198v1",
        "pub_date": "2023-05-30",
        "summary": "Motion tracking \"telemetry\" data lies at the core of nearly all modern\nvirtual reality (VR) and metaverse experiences. While generally presumed\ninnocuous, recent studies have demonstrated that motion data actually has the\npotential to uniquely identify VR users. In this study, we go a step further,\nshowing that a variety of private user information can be inferred just by\nanalyzing motion data recorded by VR devices. We conducted a large-scale survey\nof VR users (N=1,006) with dozens of questions ranging from background and\ndemographics to behavioral patterns and health information. We then collected\nVR motion samples of each user playing the game ``Beat Saber,'' and attempted\nto infer their survey responses using just their head and hand motion patterns.\nUsing simple machine learning models, many of these attributes could accurately\nand consistently be inferred from VR motion data alone, highlighting the\npressing need for privacy-preserving mechanisms in multi-user VR applications.",
        "translated": "运动跟踪“遥测”数据是几乎所有现代虚拟现实(VR)和元宇宙体验的核心。虽然一般认为无害，最近的研究已经证明，运动数据实际上有可能唯一识别虚拟现实用户。在这项研究中，我们更进一步，表明各种各样的私人用户信息可以推断只是分析运动数据记录的虚拟现实设备。我们对虚拟现实用户(N = 1,006)进行了一次大规模的调查，问题涉及背景、人口统计学、行为模式和健康信息等多个方面。然后，我们收集了每个玩游戏的用户的虚拟现实运动样本“击败军刀”，并试图推断他们的调查反应，只使用他们的头部和手部运动模式。使用简单的机器学习模型，许多这些属性可以准确和一致地从 VR 运动数据中推断出来，突出了在多用户 VR 应用中保护隐私机制的迫切需要。"
    },
    {
        "title": "Reviewing BPMN as a Modeling Notation for CACAO Security Playbooks",
        "url": "http://arxiv.org/abs/2305.18928v1",
        "pub_date": "2023-05-30",
        "summary": "As cyber systems become increasingly complex and cybersecurity threats become\nmore prominent, defenders must prepare, coordinate, automate, document, and\nshare their response methodologies to the extent possible. The CACAO standard\nwas developed to satisfy the above requirements providing a common\nmachine-readable framework and schema to document cybersecurity operations\nprocesses, including defensive tradecraft and tactics, techniques, and\nprocedures. Although this approach is compelling, a remaining limitation is\nthat CACAO provides no native modeling notation for graphically representing\nplaybooks, which is crucial for simplifying their creation, modification, and\nunderstanding. In contrast, the industry is familiar with BPMN, a\nstandards-based modeling notation for business processes that has also found\nits place in representing cybersecurity processes. This research examines BPMN\nand CACAO and explores the feasibility of using the BPMN modeling notation to\ngraphically represent CACAO security playbooks. The results indicate that\nmapping CACAO and BPMN is attainable at an abstract level; however, conversion\nfrom one encoding to another introduces a degree of complexity due to the\nmultiple ways CACAO constructs can be represented in BPMN and the extensions\nrequired in BPMN to fully support CACAO.",
        "translated": "随着网络系统变得越来越复杂，网络安全威胁变得越来越突出，防御者必须尽可能地准备、协调、自动化、记录和分享他们的应对方法。CACAO 标准是为了满足上述要求而开发的，它提供了一个通用的机器可读框架和模式来记录网络安全操作过程，包括防御性间谍技术和战术、技术和程序。尽管这种方法很有说服力，但是仍然存在一个局限性，即 CACAO 没有提供用于以图形方式表示剧本的本地建模符号，这对于简化剧本的创建、修改和理解至关重要。相比之下，业界熟悉 BPMN，这是一种基于标准的业务流程建模符号，在表示网络安全流程方面也占有一席之地。本研究检视 BPMN 和 CACAO，并探讨使用 BPMN 建模符号以图形化方式表示 CACAO 安全剧本的可行性。结果表明，CACAO 和 BPMN 的映射在抽象层次上是可以实现的; 然而，由于 CACAO 构造可以在 BPMN 中以多种方式表示，并且 BPMN 需要扩展来完全支持 CACAO，因此从一种编码到另一种编码的转换引入了一定程度的复杂性。"
    },
    {
        "title": "Password-Based Authentication and The Experiences of End Users",
        "url": "http://arxiv.org/abs/2305.18909v1",
        "pub_date": "2023-05-30",
        "summary": "Passwords are used majorly for end-user authentication in information and\ncommunication technology (ICT) systems due to its perceived ease of use. The\nuse for end-user authentication extends through mobile, computers and\nnetwork-based products and services. But with the attendant issues relating to\npassword hacks, leakages, and theft largely due to weak, reuse and poor\npassword habits of end-users, the call for passwordless authentication as\nalternative intensifies. All the same, there are missing knowledge of whether\nthese password-based experiences are associated with societal economic status,\neducational qualification of citizens, their age and gender, technological\nadvancements, and depth of penetration. In line with the above, understanding\nthe experience of end-users in developing economy to ascertain their\npassword-based experience has become of interest to the researchers. This paper\naims at measuring the experience of staff and students in University\ncommunities within southeastern Nigeria on password-based authentication\nsystems. These communities have population whose age brackets are majorly\nwithin the ages of 16 and 60 years; have people with requisite educational\nqualifications ranging from Diploma to Doctorate degrees and constitutes good\nnumber of ICT tools consumers. The survey had 291 respondents, and collected\ndata about age, educational qualifications, and gender from these respondents.\nIt also collected information about their password experience in social media\nnetwork, online shopping, electronic health care services, and internet\nbanking. Our analysis using SPSS and report by means of descriptive statistics,\nfrequency distribution, and Chi-Square tests showed that account compromise in\nthe geographical area is not common with the respondents reporting good\nexperience with passwords usage.",
        "translated": "在信息和通信技术(ICT)系统中，由于密码易于使用，它主要用于最终用户身份验证。最终用户认证的使用范围扩大到移动、计算机和基于网络的产品和服务。但是由于最终用户的软弱、重用和糟糕的密码习惯，与密码破解、泄漏和盗窃相关的问题随之而来，要求无密码身份验证作为替代方案的呼声越来越高。尽管如此，对于这些基于密码的体验是否与社会经济地位、公民的教育资格、年龄和性别、技术进步以及渗透深度有关，人们仍然缺乏知识。据此，了解最终用户在发展经济中的经验，以确定其基于密码的经验已成为研究人员感兴趣的问题。本文旨在测量尼日利亚东南部大学社区的教职员工和学生使用基于密码的认证系统的经验。这些社区的人口年龄段主要在16岁和60岁之间; 他们拥有从文凭到博士学位的必要教育资格，是信息和通信技术工具的大量消费者。这项调查有291名受访者，并收集了这些受访者的年龄、学历和性别等方面的数据。它还收集了有关他们在社交媒体网络、网上购物、电子医疗服务和网上银行中的密码体验的信息。我们使用 SPSS 软件进行分析，并通过描述统计学、频率分布和卡方检验进行报告。结果显示，受访者报告密码使用经验丰富的情况并不常见，但经纬度中的帐户泄露情况却不常见。"
    },
    {
        "title": "Majority Voting Approach to Ransomware Detection",
        "url": "http://arxiv.org/abs/2305.18852v1",
        "pub_date": "2023-05-30",
        "summary": "Crypto-ransomware remains a significant threat to governments and companies\nalike, with high-profile cyber security incidents regularly making headlines.\nMany different detection systems have been proposed as solutions to the\never-changing dynamic landscape of ransomware detection. In the majority of\ncases, these described systems propose a method based on the result of a single\ntest performed on either the executable code, the process under investigation,\nits behaviour, or its output. In a small subset of ransomware detection\nsystems, the concept of a scorecard is employed where multiple tests are\nperformed on various aspects of a process under investigation and their results\nare then analysed using machine learning. The purpose of this paper is to\npropose a new majority voting approach to ransomware detection by developing a\nmethod that uses a cumulative score derived from discrete tests based on\ncalculations using algorithmic rather than heuristic techniques. The paper\ndescribes 23 candidate tests, as well as 9 Windows API tests which are\nvalidated to determine both their accuracy and viability for use within a\nransomware detection system. Using a cumulative score calculation approach to\nransomware detection has several benefits, such as the immunity to the\noccasional inaccuracy of individual tests when making its final classification.\nThe system can also leverage multiple tests that can be both comprehensive and\ncomplimentary in an attempt to achieve a broader, deeper, and more robust\nanalysis of the program under investigation. Additionally, the use of multiple\ncollaborative tests also significantly hinders ransomware from masking or\nmodifying its behaviour in an attempt to bypass detection.",
        "translated": "加密勒索软件仍然是对政府和企业的重大威胁，高调的网络安全事件经常成为头条新闻。许多不同的检测系统已被提出作为解决不断变化的动态景观的勒索软件检测。在大多数情况下，这些描述的系统提出一种方法，该方法基于对可执行代码、正在调查的过程、其行为或其输出执行的单个测试的结果。在一小部分勒索软件检测系统中，使用记分卡的概念，对所调查过程的各个方面进行多个测试，然后使用机器学习分析测试结果。本文的目的是提出一种新的多数表决方法来检测勒索软件，通过开发一种方法，使用累积得分从离散测试的基础上计算使用算法而不是启发式技术。本文描述了23个候选测试，以及9个 Windows API 测试，这些测试经过验证，以确定其准确性和可行性，以便在勒索软件检测系统中使用。使用累积分数计算方法进行勒索软件检测有几个好处，例如在进行最终分类时可以免受个别测试偶尔出现的不准确性的影响。该系统还可以利用多个测试，这些测试可以是全面的，也可以是互补的，以便对正在调查的程序进行更广泛、更深入和更健壮的分析。此外，多个协作测试的使用也显著地阻碍了勒索软件掩盖或修改其行为，试图绕过检测。"
    },
    {
        "title": "Methods for Collisions in Some Algebraic Hash Functions",
        "url": "http://arxiv.org/abs/2305.18799v1",
        "pub_date": "2023-05-30",
        "summary": "This paper focuses on devising methods for producing collisions in algebraic\nhash functions that may be seen as generalized forms of the well-known Z\\'emor\nand Tillich-Z\\'emor hash functions. In contrast to some of the previous\napproaches, we attempt to construct collisions in a structured and\ndeterministic manner by constructing messages with triangular or diagonal\nhashes messages. Our method thus provides an alternate deterministic approach\nto the method for finding triangular hashes. We also consider the generalized\nTillich-Z\\'emor hash functions over ${\\mathbb{F}_p}^k$ for $p\\neq 2$, relating\nthe generator matrices to a polynomial recurrence relation, and derive a closed\nform for any arbitrary power of the generators. We then provide conditions for\ncollisions, and a method to maliciously design the system so as to facilitate\neasy collisions, in terms of this polynomial recurrence relation. Our general\nconclusion is that it is very difficult in practice to achieve the theoretical\ncollision conditions efficiently, in both the generalized Z\\'emor and the\ngeneralized Tillich-Z\\'emor cases. Therefore, although the techniques are\ninteresting theoretically, in practice the collision-resistance of the\ngeneralized Z\\'emor functions is reinforced.",
        "translated": "本文重点研究了代数哈希函数中产生碰撞的方法，这些碰撞可以看作是著名的 Z’em 或 Tillich-Z’em 或哈希函数的广义形式。与以前的一些方法相反，我们尝试通过构造具有三角形或对角散列消息的消息来以结构化和确定性的方式构造冲突。因此，我们的方法为寻找三角形散列的方法提供了一种替代的确定性方法。我们还考虑了 ${ mathbb { F } _ p } ^ k $for $p neq 2 $上的广义 Tillich-Z’em 或 hash 函数，将生成器矩阵与多项式递回关系式联系起来，并对生成器的任意幂给出了一个封闭形式。然后，我们提供碰撞的条件，以及一种恶意设计系统的方法，以便根据这个多项式递回关系式方便地进行碰撞。我们的一般结论是，无论是在广义 Z’em 还是在广义 Tillich-Z’em 或情形下，有效地实现理论碰撞条件在实践中都是非常困难的。因此，虽然这些技术在理论上很有趣，但在实践中，广义 Z’em 或函数的抗碰撞能力得到了加强。"
    },
    {
        "title": "Phase Correction using Deep Learning for Satellite-to-Ground CV-QKD",
        "url": "http://arxiv.org/abs/2305.18737v1",
        "pub_date": "2023-05-30",
        "summary": "Coherent measurement of quantum signals used for continuous-variable (CV)\nquantum key distribution (QKD) across satellite-to-ground channels requires\ncompensation of phase wavefront distortions caused by atmospheric turbulence.\nOne compensation technique involves multiplexing classical reference pulses\n(RPs) and the quantum signal, with direct phase measurements on the RPs then\nused to modulate a real local oscillator (RLO) on the ground - a solution that\nalso removes some known attacks on CV-QKD. However, this is a cumbersome task\nin practice - requiring substantial complexity in equipment requirements and\ndeployment. As an alternative to this traditional practice, here we introduce a\nnew method for estimating phase corrections for an RLO by using only intensity\nmeasurements from RPs as input to a convolutional neural network, mitigating\ncompletely the necessity to measure phase wavefronts directly. Conventional\nwisdom dictates such an approach would likely be fruitless. However, we show\nthat the phase correction accuracy needed to provide for non-zero secure key\nrates through satellite-to-ground channels is achieved by our intensity-only\nmeasurements. Our work shows, for the first time, how artificial intelligence\nalgorithms can replace phase-measuring equipment in the context of CV-QKD\ndelivered from space, thereby delivering an alternate deployment paradigm for\nthis global quantum-communication application.",
        "translated": "用于连续变量量子密钥分配(QKD)的量子信号的相干测量需要对大气湍流引起的相位波前畸变进行补偿。一种补偿技术包括复用经典参考脉冲(RPs)和量子信号，对 RPs 进行直接相位测量，然后用于调制地面上的实际本机振荡器(RLO)——这种解决方案也消除了对 CV-QKD 的一些已知攻击。然而，这在实践中是一项繁琐的任务——需要在设备需求和部署方面有相当大的复杂性。作为这种传统做法的替代，我们在这里介绍一种新的估计相位修正的方法，通过只使用来自 RP 的强度测量作为输入到卷积神经网络，完全减少了直接测量相位波阵面的必要性。传统观点认为，这种做法可能是徒劳的。然而，我们表明，所需的相位校正精度，以提供非零安全密钥率通过卫星到地面信道是通过我们的强度只有测量。我们的工作首次展示了人工智能算法如何取代从太空传送的 CV-QKD 环境下的相位测量设备，从而为这种全球量子通信应用提供了一种替代部署范式。"
    },
    {
        "title": "Understanding and Mitigating Copying in Diffusion Models",
        "url": "http://arxiv.org/abs/2305.20086v1",
        "pub_date": "2023-05-31",
        "summary": "Images generated by diffusion models like Stable Diffusion are increasingly\nwidespread. Recent works and even lawsuits have shown that these models are\nprone to replicating their training data, unbeknownst to the user. In this\npaper, we first analyze this memorization problem in text-to-image diffusion\nmodels. While it is widely believed that duplicated images in the training set\nare responsible for content replication at inference time, we observe that the\ntext conditioning of the model plays a similarly important role. In fact, we\nsee in our experiments that data replication often does not happen for\nunconditional models, while it is common in the text-conditional case.\nMotivated by our findings, we then propose several techniques for reducing data\nreplication at both training and inference time by randomizing and augmenting\nimage captions in the training set.",
        "translated": "由稳定扩散等扩散模型产生的图像越来越广泛。最近的工作，甚至诉讼已经表明，这些模型倾向于复制他们的训练数据，用户不知道。本文首先分析了文本-图像扩散模型中的记忆问题。虽然人们普遍认为训练集中的重复图像负责推理时的内容复制，但是我们观察到模型的文本条件作用也起着类似的重要作用。事实上，在我们的实验中，我们看到数据复制通常不会发生在无条件模型中，而在文本条件的情况下却很常见。在我们的研究结果的激励下，我们提出了几种技术，通过在训练集中随机化和增强图像标题来减少训练和推理时间的数据复制。"
    },
    {
        "title": "Tree-Ring Watermarks: Fingerprints for Diffusion Images that are\n  Invisible and Robust",
        "url": "http://arxiv.org/abs/2305.20030v2",
        "pub_date": "2023-05-31",
        "summary": "Watermarking the outputs of generative models is a crucial technique for\ntracing copyright and preventing potential harm from AI-generated content. In\nthis paper, we introduce a novel technique called Tree-Ring Watermarking that\nrobustly fingerprints diffusion model outputs. Unlike existing methods that\nperform post-hoc modifications to images after sampling, Tree-Ring Watermarking\nsubtly influences the entire sampling process, resulting in a model fingerprint\nthat is invisible to humans. The watermark embeds a pattern into the initial\nnoise vector used for sampling. These patterns are structured in Fourier space\nso that they are invariant to convolutions, crops, dilations, flips, and\nrotations. After image generation, the watermark signal is detected by\ninverting the diffusion process to retrieve the noise vector, which is then\nchecked for the embedded signal. We demonstrate that this technique can be\neasily applied to arbitrary diffusion models, including text-conditioned Stable\nDiffusion, as a plug-in with negligible loss in FID. Our watermark is\nsemantically hidden in the image space and is far more robust than watermarking\nalternatives that are currently deployed. Code is available at\nhttps://github.com/YuxinWenRick/tree-ring-watermark.",
        "translated": "对生成模型的输出进行水印是追踪版权和防止人工智能生成内容潜在危害的关键技术。本文介绍了一种新的指纹扩散模型鲁棒输出的树环数字水印技术。与现有的采样后对图像进行事后修改的方法不同，树环水印微妙地影响了整个采样过程，产生了人类看不见的模型指纹。该水印在用于采样的初始噪声矢量中嵌入一个模式。这些图案是在傅里叶空间中构成的，因此它们对卷积、作物、膨胀、翻转和旋转都是不变的。图像生成后，通过反向扩散过程检测水印信号，提取噪声矢量，然后对嵌入信号进行检测。我们证明了这种技术可以很容易地应用于任意的扩散模型，包括文本条件的稳定扩散，作为一个插件，在 FID 的损失可以忽略不计。我们的水印在语义上隐藏在图像空间中，并且比目前部署的水印方案更加健壮。密码可于 https://github.com/yuxinwenrick/tree-ring-watermark 索取。"
    },
    {
        "title": "Hidden Stabilizers, the Isogeny To Endomorphism Ring Problem and the\n  Cryptanalysis of pSIDH",
        "url": "http://arxiv.org/abs/2305.19897v1",
        "pub_date": "2023-05-31",
        "summary": "The Isogeny to Endomorphism Ring Problem (IsERP) asks to compute the\nendomorphism ring of the codomain of an isogeny between supersingular curves in\ncharacteristic $p$ given only a representation for this isogeny, i.e. some data\nand an algorithm to evaluate this isogeny on any torsion point. This problem\nplays a central role in isogeny-based cryptography; it underlies the security\nof pSIDH protocol (ASIACRYPT 2022) and it is at the heart of the recent attacks\nthat broke the SIDH key exchange. Prior to this work, no efficient algorithm\nwas known to solve IsERP for a generic isogeny degree, the hardest case\nseemingly when the degree is prime.\n  In this paper, we introduce a new quantum polynomial-time algorithm to solve\nIsERP for isogenies whose degrees are odd and have $O(\\log\\log p)$ many prime\nfactors. As main technical tools, our algorithm uses a quantum algorithm for\ncomputing hidden Borel subgroups, a group action on supersingular isogenies\nfrom EUROCRYPT 2021, various algorithms for the Deuring correspondence and a\nnew algorithm to lift arbitrary quaternion order elements modulo an odd integer\n$N$ with $O(\\log\\log p)$ many prime factors to powersmooth elements.\n  As a main consequence for cryptography, we obtain a quantum polynomial-time\nkey recovery attack on pSIDH. The technical tools we use may also be of\nindependent interest.",
        "translated": "等值自同态环问题(isERP)要求计算特征 $p $中超奇异曲线之间等值自同态环的余域，只给出这个等值的一个表示，即一些数据和一个算法来评估这个等值在任何扭转点上。这个问题在基于等基因的密码学中起着核心作用; 它是 pSIDH 协议(ASIACRYPT 2022)安全性的基础，也是最近破坏 SIDH 密钥交换的攻击的核心。在这项工作之前，还没有有效的算法来解决一般的等同度 IsERP 问题，最困难的情况似乎是当该度为素数时。本文提出了一种新的量子多项式时间算法，用于求解度数为奇数且具有 $O (log log p) $多素因子的同构体的 IsERP 问题。作为主要的技术工具，该算法采用了计算隐 Borel 子群的量子算法、 EUROCRYPT 2021中对超奇异同构的群作用、 Deuring 通信的各种算法以及提升任意四元数阶元素模的奇数整数 $N $和 $O (log log p) $多素因子的新算法。作为密码学的一个主要结果，我们得到了对 pSIDH 的量子多项式时间密钥恢复攻击。我们使用的技术工具也可能是独立的兴趣。"
    },
    {
        "title": "Lattice-Aided Extraction of Spread-Spectrum Hidden Data",
        "url": "http://arxiv.org/abs/2305.19855v1",
        "pub_date": "2023-05-31",
        "summary": "This paper discusses the problem of extracting spread spectrum hidden data\nfrom the perspective of lattice decoding. Since the conventional blind\nextraction scheme multi-carrier iterative generalize least-squares (M-IGLS) and\nnon-blind extraction scheme minimum mean square error (MMSE) suffer from\nperformance degradation when the carriers lack sufficient orthogonality, we\npresent two novel schemes from the viewpoint of lattice decoding, namely\nmulti-carrier iterative successive interference cancellation (M-ISIC) and\nsphere decoding (SD). The better performance of M-ISIC and SD are confirmed by\nboth theoretical justification and numerical simulations.",
        "translated": "本文从格解码的角度讨论了扩频隐藏数据的提取问题。针对传统的盲提取方案多载波迭代广义最小二乘(M-IGLS)和非盲提取方案最小均方误差(MMSE)在载波缺乏足够正交性时性能下降的问题，从格形译码的角度提出了两种新方案，即多载波迭代逐次干扰抵消(M-ISIC)和球形译码(SD)。理论分析和数值模拟均证实了 M-ISIC 和 SD 具有较好的性能。"
    },
    {
        "title": "Aggregated Zero-knowledge Proof and Blockchain-Empowered Authentication\n  for Autonomous Truck Platooning",
        "url": "http://arxiv.org/abs/2305.19813v1",
        "pub_date": "2023-05-31",
        "summary": "Platooning technologies enable trucks to drive cooperatively and\nautomatically, providing benefits including less fuel consumption, greater road\ncapacity, and safety. This paper introduces an aggregated zero-knowledge proof\nand blockchain-empowered system for privacy-preserving identity verification in\nthe mixed fleet platooning environment. The correctness proof and the security\nanalysis of the proposed authentication scheme are provided, highlighting its\nincreased security and fast performance in comparison to a single-proof design.\nThe blockchain performs the role of verifier within the authentication scheme,\nreducing unnecessary communication overhead. Moreover, the blockchain improves\nsystem resilience by providing fault tolerance to the decentralized\nverification process. Platooning records are stored directly on the digital\nledger to guarantee data immutability and integrity, while the programmable\naccess control policies ensure data privacy. The experimental results\ndemonstrate that the proposed approach can perform authentication on the order\nof milliseconds, regardless of the number of proofs, highlighting feasibility\nfor real-world deployment in truck platooning.",
        "translated": "排队技术使卡车能够合作和自动驾驶，提供的好处包括更少的燃料消耗，更大的道路容量和安全。提出了一种基于区块链授权的混合编队环境下的集成零知识证明系统。给出了该认证方案的正确性证明和安全性分析，与单一证明方案相比，该方案具有更高的安全性和更快的性能。块链在身份验证方案中扮演验证者的角色，减少了不必要的通信开销。此外，区块链通过对分散验证过程提供容错能力，提高了系统的恢复能力。排队记录直接存储在数字分类账上，保证数据的不变性和完整性，而可编程访问控制策略保证数据的隐私性。实验结果表明，该方法可以在毫秒级的时间内进行身份验证，无论验证次数多少，突出了在现实世界中部署卡车排的可行性。"
    },
    {
        "title": "A Hybrid Blockchain-Edge Architecture for Electronic Health Records\n  Management with Attribute-based Cryptographic Mechanisms",
        "url": "http://arxiv.org/abs/2305.19797v1",
        "pub_date": "2023-05-31",
        "summary": "This paper presents a hybrid blockchain-edge architecture for managing\nElectronic Health Records (EHRs) with attribute-based cryptographic mechanisms.\nThe architecture introduces a novel attribute-based signature aggregation\n(ABSA) scheme and multi-authority attribute-based encryption (MA-ABE)\nintegrated with Paillier homomorphic encryption (HE) to protect patients'\nanonymity and safeguard their EHRs. All the EHR activities and access control\nevents are recorded permanently as blockchain transactions. We develop the ABSA\nmodule on Hyperledger Ursa cryptography library, MA-ABE module on OpenABE\ntoolset, and blockchain network on Hyperledger Fabric. We measure the execution\ntime of ABSA's signing and verification functions, MA-ABE with different access\npolicies and homomorphic encryption schemes, and compare the results with other\nexisting blockchain-based EHR systems. We validate the access activities and\nauthentication events recorded in blockchain transactions and evaluate the\ntransaction throughput and latency using Hyperledger Caliper. The results show\nthat the performance meets real-world scenarios' requirements while\nsafeguarding EHR and is robust against unauthorized retrievals.",
        "translated": "提出了一种基于属性加密机制的区块链-边缘混合体系结构来管理电子健康记录(EHR)。该体系结构引入了一种新的基于属性的签名聚合(ABSA)方案和集成了 Paillier 同态加密(HE)的基于多权限属性的加密(MA-ABE) ，以保护患者的匿名性和保护他们的电子病历。所有的 EHR 活动和访问控制事件都被永久地记录为区块链事务。我们在 Hyperledger Ursa 密码库上开发了 ABSA 模块，在 OpenABE 工具集上开发了 MA-ABE 模块，在 Hyperledger Fabric 上开发了区块链网络。我们测量了 ABSA 的签名和验证功能的执行时间，使用不同接入策略和同态加密方案的 MA-ABE，并将结果与其他现有的基于区块链的电子健康记录系统进行了比较。我们验证区块链事务中记录的访问活动和认证事件，并使用 Hyperledger Caliper 评估事务吞吐量和延迟。结果表明，该算法在保护 EHR 的同时，性能满足现实场景的要求，对未经授权的检索具有较强的鲁棒性。"
    },
    {
        "title": "Off-By-One Implementation Error in J-UNIWARD",
        "url": "http://arxiv.org/abs/2305.19776v1",
        "pub_date": "2023-05-31",
        "summary": "J-UNIWARD is a popular steganography method for hiding secret messages in\nJPEG cover images. As a content-adaptive method, J-UNIWARD aims to embed into\ntextured image regions where changes are difficult to detect. To this end,\nJ-UNIWARD first assigns to each DCT coefficient an embedding cost calculated\nbased on the image's Wavelet residual, and then uses a coding method that\nminimizes the cost while embedding the desired payload. Changing one DCT\ncoefficient affects a 23x23 window of Wavelet coefficients. To speed up the\ncostmap computation, the original implementation pre-computes the Wavelet\nresidual and then considers per changed DCT coefficient a 23x23 window of the\nWavelet residual. However, the implementation accesses a window accidentally\nshifted by one pixel to the bottom right. In this report, we evaluate the\neffect of this off-by-one error on the resulting costmaps. Some image blocks\nare over-priced while other image blocks are under-priced, but the difference\nis relatively small. The off-by-one error seems to make little difference for\nlearning-based steganalysis.",
        "translated": "UNIWARD 是一种流行的隐写方法，用于在 JPEG 封面图像中隐藏秘密信息。作为一种内容自适应方法，J-UNIWARD 的目标是嵌入到纹理图像区域的变化是难以检测。为此，J-UNIWARD 首先给每个 DCT 系数分配一个基于图像小波残差计算的嵌入代价，然后使用一种编码方法，在嵌入所需有效载荷的同时使代价最小。改变一个 DCT 系数影响一个23x23窗口的小波系数。为了提高代价图的计算速度，原始实现先对小波残差进行预计算，然后考虑每变化一个 DCT 系数的小波残差窗口为23x23。但是，该实现访问的窗口意外地向右下方移动了一个像素。在这份报告中，我们评估了这种差一错误对最终成本图的影响。一些图像块定价过高，而其他图像块定价过低，但差别相对较小。这种差一错误似乎对基于学习的隐写分析没什么影响。"
    },
    {
        "title": "You Can Run But You Can't Hide: Runtime Protection Against Malicious\n  Package Updates For Node.js",
        "url": "http://arxiv.org/abs/2305.19760v1",
        "pub_date": "2023-05-31",
        "summary": "Maliciously prepared software packages are an extensively leveraged weapon\nfor software supply chain attacks. The detection of malicious packages is\nundoubtedly of high priority and many academic and commercial approaches have\nbeen developed. In the inevitable case of an attack, one needs resilience\nagainst malicious code. To this end, we present a runtime protection for\nNode.js that automatically limits a package's capabilities to an established\nminimum. The detection of required capabilities as well as their enforcement at\nruntime has been implemented and evaluated against known malicious attacks. Our\napproach was able to prevent 9/10 historic attacks with a median install-time\noverhead of less than 0.6 seconds and a median runtime overhead of less than\n0.2 seconds.",
        "translated": "恶意准备的软件包是软件供应链攻击的一种广泛利用的武器。检测恶意软件包无疑是高度优先事项，已经开发了许多学术和商业方法。在攻击不可避免的情况下，人们需要对恶意代码的弹性。为此，我们为 Node.js 提供了一个运行时保护，它自动将包的功能限制到一个确定的最小值。针对已知的恶意攻击，已经实现并评估了所需功能的检测及其在运行时的执行。我们的方法能够阻止9/10的历史性攻击，中位安装时间开销小于0.6秒，中位运行时间开销小于0.2秒。"
    },
    {
        "title": "Concentrated Geo-Privacy",
        "url": "http://arxiv.org/abs/2305.19756v1",
        "pub_date": "2023-05-31",
        "summary": "This paper proposes concentrated geo-privacy (CGP), a privacy notion that can\nbe considered as the counterpart of concentrated differential privacy (CDP) for\ngeometric data. Compared with the previous notion of geo-privacy [ABCP13,\nCABP13], which is the counterpart of standard differential privacy, CGP offers\nmany benefits including simplicity of the mechanism, lower noise scale in high\ndimensions, and better composability known as advanced composition. The last\none is the most important, as it allows us to design complex mechanisms using\nsmaller building blocks while achieving better utilities. To complement this\nresult, we show that the previous notion of geo-privacy inherently does not\nadmit advanced composition even using its approximate version. Next, we study\nthree problems on private geometric data: the identity query, k nearest\nneighbors, and convex hulls. While the first problem has been previously\nstudied, we give the first mechanisms for the latter two under geo-privacy. For\nall three problems, composability is essential in obtaining good utility\nguarantees on the privatized query answer.",
        "translated": "本文提出了集中地理隐私权(cGP) ，这一隐私概念可以被视为几何数据集中差分隐私(cDP)的对应物。与之前的地理隐私概念[ ABCP13，CABP13](与标准差分隐私相对应)相比，CGP 提供了许多优点，包括机制的简单性、高维度的低噪声尺度以及被称为高级合成的更好的可组合性。最后一个是最重要的，因为它使我们能够设计复杂的机制，使用更小的构件，同时实现更好的效用。为了补充这一结果，我们表明，先前的地理隐私概念本质上不承认先进的组成，即使使用其近似版本。接下来，我们研究了私有几何数据的三个问题: 身份查询、 k 最近邻和凸壳。在前人研究的基础上，我们给出了地理隐私条件下后两种情况下的第一种机制。对于所有这三个问题，可组合性对于获得私有化查询答案的良好效用保证是必不可少的。"
    },
    {
        "title": "Adversarial Clean Label Backdoor Attacks and Defenses on Text\n  Classification Systems",
        "url": "http://arxiv.org/abs/2305.19607v1",
        "pub_date": "2023-05-31",
        "summary": "Clean-label (CL) attack is a form of data poisoning attack where an adversary\nmodifies only the textual input of the training data, without requiring access\nto the labeling function. CL attacks are relatively unexplored in NLP, as\ncompared to label flipping (LF) attacks, where the latter additionally requires\naccess to the labeling function as well. While CL attacks are more resilient to\ndata sanitization and manual relabeling methods than LF attacks, they often\ndemand as high as ten times the poisoning budget than LF attacks. In this work,\nwe first introduce an Adversarial Clean Label attack which can adversarially\nperturb in-class training examples for poisoning the training set. We then show\nthat an adversary can significantly bring down the data requirements for a CL\nattack, using the aforementioned approach, to as low as 20% of the data\notherwise required. We then systematically benchmark and analyze a number of\ndefense methods, for both LF and CL attacks, some previously employed solely\nfor LF attacks in the textual domain and others adapted from computer vision.\nWe find that text-specific defenses greatly vary in their effectiveness\ndepending on their properties.",
        "translated": "Clean-label (CL)攻击是数据中毒攻击的一种形式，攻击者只修改训练数据的文本输入，而不需要访问标记函数。与标签翻转(LF)攻击相比，自然语言处理(NLP)中的 CL 攻击相对较少涉及，后者还需要访问标签功能。虽然 CL 攻击比 LF 攻击对数据清理和手动重新标记方法更有弹性，但它们往往需要比 LF 攻击高出10倍的中毒预算。在这项工作中，我们首先介绍了一个对抗性干净标签攻击，它可以对抗性地扰乱课堂上的训练例子中毒的训练集。然后，我们展示了使用上述方法，对手可以显著降低 CL 攻击的数据需求，使其降低到原来需要的数据的20% 。然后，我们系统地基准和分析了一些防御方法，包括 LF 和 CL 攻击，其中一些以前只用于文本领域的 LF 攻击和其他改编自计算机视觉。我们发现，文本特定的防御措施根据其属性的不同，其有效性差异很大。"
    },
    {
        "title": "Interpreting GNN-based IDS Detections Using Provenance Graph Structural\n  Features",
        "url": "http://arxiv.org/abs/2306.00934v1",
        "pub_date": "2023-06-01",
        "summary": "The black-box nature of complex Neural Network (NN)-based models has hindered\ntheir widespread adoption in security domains due to the lack of logical\nexplanations and actionable follow-ups for their predictions. To enhance the\ntransparency and accountability of Graph Neural Network (GNN) security models\nused in system provenance analysis, we propose PROVEXPLAINER, a framework for\nprojecting abstract GNN decision boundaries onto interpretable feature spaces.\n  We first replicate the decision-making process of GNNbased security models\nusing simpler and explainable models such as Decision Trees (DTs). To maximize\nthe accuracy and fidelity of the surrogate models, we propose novel graph\nstructural features founded on classical graph theory and enhanced by extensive\ndata study with security domain knowledge. Our graph structural features are\nclosely tied to problem-space actions in the system provenance domain, which\nallows the detection results to be explained in descriptive, human language.\nPROVEXPLAINER allowed simple DT models to achieve 95% fidelity to the GNN on\nprogram classification tasks with general graph structural features, and 99%\nfidelity on malware detection tasks with a task-specific feature package\ntailored for direct interpretation. The explanations for malware classification\nare demonstrated with case studies of five real-world malware samples across\nthree malware families.",
        "translated": "基于神经网络(NN)的复杂模型的黑箱特性阻碍了它们在安全领域的广泛应用，因为它们的预测缺乏逻辑解释和可操作的后续行动。为了提高图形神经网络(GNN)安全模型在系统起源分析中的透明度和可靠性，提出了 PROVEXPLAINER 框架，该框架将抽象的 GNN 决策边界投影到可解释的特征空间中。我们首先使用更简单和可解释的模型(比如决策树)复制基于 GNN 的安全模型的决策过程。为了最大限度地提高代理模型的准确性和保真度，我们提出了基于经典图论的新的图结构特征，并利用安全领域的知识进行了广泛的数据研究。我们的图形结构特征与系统起源域中的问题空间操作紧密相关，这使得检测结果可以用描述性的人工语言来解释。PROVEXPLAINER 允许简单的 DT 模型在具有一般图形结构特征的程序分类任务上达到95% 的 GNN 保真度，在具有专门用于直接解释的任务特定功能包的恶意软件检测任务上达到99% 的保真度。通过对三个恶意软件家族的五个现实世界恶意软件样本的案例研究，说明了恶意软件分类的解释。"
    },
    {
        "title": "Better Private Linear Regression Through Better Private Feature\n  Selection",
        "url": "http://arxiv.org/abs/2306.00920v1",
        "pub_date": "2023-06-01",
        "summary": "Existing work on differentially private linear regression typically assumes\nthat end users can precisely set data bounds or algorithmic hyperparameters.\nEnd users often struggle to meet these requirements without directly examining\nthe data (and violating privacy). Recent work has attempted to develop\nsolutions that shift these burdens from users to algorithms, but they struggle\nto provide utility as the feature dimension grows. This work extends these\nalgorithms to higher-dimensional problems by introducing a differentially\nprivate feature selection method based on Kendall rank correlation. We prove a\nutility guarantee for the setting where features are normally distributed and\nconduct experiments across 25 datasets. We find that adding this private\nfeature selection step before regression significantly broadens the\napplicability of ``plug-and-play'' private linear regression algorithms at\nlittle additional cost to privacy, computation, or decision-making by the end\nuser.",
        "translated": "关于差别私有线性回归的现有工作通常假设终端用户可以精确设置数据界限或算法超参数。最终用户经常在不直接检查数据(并侵犯隐私)的情况下难以满足这些需求。最近的工作试图开发解决方案，将这些负担从用户转移到算法，但随着功能维度的增长，他们很难提供实用性。本文通过引入一种基于肯德尔秩相关的差分私有特征选择方法，将这些算法推广到高维问题。我们证明了一个实用的设置功能是正态分布的保证，并在25个数据集进行实验。我们发现，在回归之前添加这个私有特性选择步骤，可以显著扩大“即插即用”私有线性回归算法的适用性，而不会增加终端用户的隐私、计算或决策成本。"
    },
    {
        "title": "Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and\n  Compatible Triggers",
        "url": "http://arxiv.org/abs/2306.00816v1",
        "pub_date": "2023-06-01",
        "summary": "Deep neural networks (DNNs) can be manipulated to exhibit specific behaviors\nwhen exposed to specific trigger patterns, without affecting their performance\non normal samples. This type of attack is known as a backdoor attack. Recent\nresearch has focused on designing invisible triggers for backdoor attacks to\nensure visual stealthiness. These triggers have demonstrated strong attack\nperformance even under backdoor defense, which aims to eliminate or suppress\nthe backdoor effect in the model. However, through experimental observations,\nwe have noticed that these carefully designed invisible triggers are often\nsusceptible to visual distortion during inference, such as Gaussian blurring or\nenvironmental variations in real-world scenarios. This phenomenon significantly\nundermines the effectiveness of attacks in practical applications.\nUnfortunately, this issue has not received sufficient attention and has not\nbeen thoroughly investigated. To address this limitation, we propose a novel\napproach called the Visible, Semantic, Sample-Specific, and Compatible trigger\n(VSSC-trigger), which leverages a recent powerful image method known as the\nstable diffusion model. In this approach, a text trigger is utilized as a\nprompt and combined with a benign image. The resulting combination is then\nprocessed by a pre-trained stable diffusion model, generating a corresponding\nsemantic object. This object is seamlessly integrated with the original image,\nresulting in a new realistic image, referred to as the poisoned image.\nExtensive experimental results and analysis validate the effectiveness and\nrobustness of our proposed attack method, even in the presence of visual\ndistortion. We believe that the new trigger proposed in this work, along with\nthe proposed idea to address the aforementioned issues, will have significant\nprospective implications for further advancements in this direction.",
        "translated": "深度神经网络(DNN)可以被操纵，当暴露于特定的触发模式时表现出特定的行为，而不会影响它们在正常样本上的表现。这种类型的攻击被称为后门攻击。最近的研究集中在为后门攻击设计隐形触发器，以确保视觉隐蔽性。这些触发器表现出强大的攻击性能，甚至在后门防御下，旨在消除或抑制后门效应的模型。然而，通过实验观察，我们已经注意到这些精心设计的不可见触发器在推理过程中往往容易受到视觉扭曲的影响，如高斯模糊或现实世界场景中的环境变化。这种现象极大地削弱了攻击在实际应用中的有效性。不幸的是，这个问题没有得到足够的重视，也没有得到彻底的调查。为了解决这一局限性，我们提出了一种新的方法，称为可见的，语义的，样本特定的，兼容的触发器(VSSC 触发器) ，它利用了最近的一个强大的图像方法称为稳定扩散模型。该方法利用文本触发器作为提示，并与良性图像相结合。然后由预先训练好的稳定扩散模型处理得到的组合，生成相应的语义对象。这个物体与原始图像无缝地结合在一起，产生了一个新的逼真的图像，称为中毒图像。大量的实验结果和分析验证了我们提出的攻击方法的有效性和鲁棒性，即使在存在视觉失真的情况下。我们认为，在这项工作中提出的新的触发点，以及处理上述问题的提议，将对朝这个方向取得进一步进展产生重大的预期影响。"
    },
    {
        "title": "SlothSpeech: Denial-of-service Attack Against Speech Recognition Models",
        "url": "http://arxiv.org/abs/2306.00794v1",
        "pub_date": "2023-06-01",
        "summary": "Deep Learning (DL) models have been popular nowadays to execute different\nspeech-related tasks, including automatic speech recognition (ASR). As ASR is\nbeing used in different real-time scenarios, it is important that the ASR model\nremains efficient against minor perturbations to the input. Hence, evaluating\nefficiency robustness of the ASR model is the need of the hour. We show that\npopular ASR models like Speech2Text model and Whisper model have dynamic\ncomputation based on different inputs, causing dynamic efficiency. In this\nwork, we propose SlothSpeech, a denial-of-service attack against ASR models,\nwhich exploits the dynamic behaviour of the model. SlothSpeech uses the\nprobability distribution of the output text tokens to generate perturbations to\nthe audio such that efficiency of the ASR model is decreased. We find that\nSlothSpeech generated inputs can increase the latency up to 40X times the\nlatency induced by benign input.",
        "translated": "深度学习(DL)模型是当今流行的用于执行各种语音相关任务的模型，其中包括自动语音识别(ASR)。由于 ASR 正在不同的实时场景中使用，因此 ASR 模型对于输入的微小扰动保持有效是非常重要的。因此，评估 ASR 模型的效率鲁棒性是当前的需要。我们表明，流行的 ASR 模型，如 Speech2Text 模型和 Whisper 模型，可以基于不同的输入进行动态计算，从而产生动态效率。在这项工作中，我们提出了懒人语音，一个反对 ASR 模型的分布式拒绝服务攻击，它利用了模型的动态行为。SlothLanguage 利用输出文本令牌的概率分布对音频产生扰动，从而降低了 ASR 模型的效率。我们发现懒语音产生的输入可以增加延迟高达40倍的良性输入所引起的延迟。"
    },
    {
        "title": "Impact of using a privacy model on smart buildings data for CO2\n  prediction",
        "url": "http://arxiv.org/abs/2306.00766v1",
        "pub_date": "2023-06-01",
        "summary": "There is a constant trade-off between the utility of the data collected and\nprocessed by the many systems forming the Internet of Things (IoT) revolution\nand the privacy concerns of the users living in the spaces hosting these\nsensors. Privacy models, such as the SITA (Spatial, Identity, Temporal, and\nActivity) model, can help address this trade-off. In this paper, we focus on\nthe problem of $CO_2$ prediction, which is crucial for health monitoring but\ncan be used to monitor occupancy, which might reveal some private information.\nWe apply a number of transformations on a real dataset from a Smart Building to\nsimulate different SITA configurations on the collected data. We use the\ntransformed data with multiple Machine Learning (ML) techniques to analyse the\nperformance of the models to predict $CO_{2}$ levels. Our results show that,\nfor different algorithms, different SITA configurations do not make one\nalgorithm perform better or worse than others, compared to the baseline data;\nalso, in our experiments, the temporal dimension was particularly sensitive,\nwith scores decreasing up to $18.9\\%$ between the original and the transformed\ndata. The results can be useful to show the effect of different levels of data\nprivacy on the data utility of IoT applications, and can also help to identify\nwhich parameters are more relevant for those systems so that higher privacy\nsettings can be adopted while data utility is still preserved.",
        "translated": "在构成物联网革命的许多系统所收集和处理的数据的效用和生活在这些传感器所在空间的用户的隐私问题之间有一个持续的权衡。隐私模型，比如 SITA (空间、身份、时间和活动)模型，可以帮助解决这种权衡。本文主要研究二氧化碳预测问题，这个问题对健康监测至关重要，但可以用来监测入住率，可能会泄露一些私人信息。我们应用一个智能建筑的实际数据集上的一些变换，以模拟不同的 SITA 配置上收集的数据。我们使用多机器学习(ML)技术的转换数据来分析模型的性能，以预测 $CO _ {2} $水平。我们的研究结果表明，对于不同的算法，与基线数据相比，不同的 SITA 配置不会使一种算法执行得更好或更差; 此外，在我们的实验中，时间维度特别敏感，原始数据和转换数据之间的分数下降高达18.9% $。研究结果有助于显示不同级别的数据隐私对物联网应用程序数据效用的影响，也有助于确定哪些参数与这些系统更相关，以便在保留数据效用的同时采用更高的隐私设置。"
    },
    {
        "title": "UNGOML: Automated Classification of unsafe Usages in Go",
        "url": "http://arxiv.org/abs/2306.00694v1",
        "pub_date": "2023-06-01",
        "summary": "The Go programming language offers strong protection from memory corruption.\nAs an escape hatch of these protections, it provides the unsafe package.\nPrevious studies identified that this unsafe package is frequently used in\nreal-world code for several purposes, e.g., serialization or casting types. Due\nto the variety of these reasons, it may be possible to refactor specific usages\nto avoid potential vulnerabilities. However, the classification of unsafe\nusages is challenging and requires the context of the call and the program's\nstructure. In this paper, we present the first automated classifier for unsafe\nusages in Go, UNGOML, to identify what is done with the unsafe package and why\nit is used. For UNGOML, we built four custom deep learning classifiers trained\non a manually labeled data set. We represent Go code as enriched control-flow\ngraphs (CFGs) and solve the label prediction task with one single-vertex and\nthree context-aware classifiers. All three context-aware classifiers achieve a\ntop-1 accuracy of more than 86% for both dimensions, WHAT and WHY. Furthermore,\nin a set-valued conformal prediction setting, we achieve accuracies of more\nthan 93% with mean label set sizes of 2 for both dimensions. Thus, UNGOML can\nbe used to efficiently filter unsafe usages for use cases such as refactoring\nor a security audit. UNGOML: https://github.com/stg-tud/ungoml Artifact:\nhttps://dx.doi.org/10.6084/m9.figshare.22293052",
        "translated": "Go 编程语言提供了强大的内存损坏保护。作为这些保护的逃生出口，它提供了不安全的包。以前的研究表明，这个不安全的包经常用于现实世界的代码中的几个目的，例如，序列化或强制转换类型。由于这些原因的多样性，有可能重构特定的用法以避免潜在的漏洞。然而，不安全使用的分类是具有挑战性的，需要调用的上下文和程序的结构。在本文中，我们提出了第一个自动分类器的不安全使用在围棋，UNGOML，以确定是什么做了不安全的包和为什么使用它。对于 UNGOML，我们建立了四个自定义深度学习分类器，这些分类器用手工标记的数据集进行训练。我们将 Go 代码表示为丰富的控制流图(CFG) ，并用一个单顶点分类器和三个上下文感知分类器解决标签预测任务。所有三个上下文感知分类器在“什么”和“为什么”这两个维度上都达到了86% 以上的最高准确率。此外，在一个集值保角预测集合中，当两个维度的平均标签集大小为2时，我们可以达到93% 以上的准确率。因此，可以使用 UNGOML 对重构或安全审计等用例的不安全使用进行有效过滤。Https://github.com/stg-tud/UNGOML 艺术品:  https://dx.doi.org/10.6084/m9.figshare.22293052"
    },
    {
        "title": "Adversarial Robustness in Unsupervised Machine Learning: A Systematic\n  Review",
        "url": "http://arxiv.org/abs/2306.00687v1",
        "pub_date": "2023-06-01",
        "summary": "As the adoption of machine learning models increases, ensuring robust models\nagainst adversarial attacks is increasingly important. With unsupervised\nmachine learning gaining more attention, ensuring it is robust against attacks\nis vital. This paper conducts a systematic literature review on the robustness\nof unsupervised learning, collecting 86 papers. Our results show that most\nresearch focuses on privacy attacks, which have effective defenses; however,\nmany attacks lack effective and general defensive measures. Based on the\nresults, we formulate a model on the properties of an attack on unsupervised\nlearning, contributing to future research by providing a model to use.",
        "translated": "随着机器学习模型的应用越来越广泛，确保模型对抗对手攻击变得越来越重要。随着非监督式学习受到越来越多的关注，确保它能够抵御攻击至关重要。本文对非监督式学习的稳健性进行了系统的文献回顾，共收集了86篇论文。我们的研究结果表明，大多数的研究集中在隐私攻击，有效的防御，然而，许多攻击缺乏有效的和一般的防御措施。根据研究结果，我们建立了一个攻击非监督式学习的特性模型，通过提供一个可以使用的模型，为未来的研究做出了贡献。"
    },
    {
        "title": "CRS-FL: Conditional Random Sampling for Communication-Efficient and\n  Privacy-Preserving Federated Learning",
        "url": "http://arxiv.org/abs/2306.00674v1",
        "pub_date": "2023-06-01",
        "summary": "Federated Learning (FL), a privacy-oriented distributed ML paradigm, is being\ngaining great interest in Internet of Things because of its capability to\nprotect participants data privacy. Studies have been conducted to address\nchallenges existing in standard FL, including communication efficiency and\nprivacy-preserving. But they cannot achieve the goal of making a tradeoff\nbetween communication efficiency and model accuracy while guaranteeing privacy.\nThis paper proposes a Conditional Random Sampling (CRS) method and implements\nit into the standard FL settings (CRS-FL) to tackle the above-mentioned\nchallenges. CRS explores a stochastic coefficient based on Poisson sampling to\nachieve a higher probability of obtaining zero-gradient unbiasedly, and then\ndecreases the communication overhead effectively without model accuracy\ndegradation. Moreover, we dig out the relaxation Local Differential Privacy\n(LDP) guarantee conditions of CRS theoretically. Extensive experiment results\nindicate that (1) in communication efficiency, CRS-FL performs better than the\nexisting methods in metric accuracy per transmission byte without model\naccuracy reduction in more than 7% sampling ratio (# sampling size / # model\nsize); (2) in privacy-preserving, CRS-FL achieves no accuracy reduction\ncompared with LDP baselines while holding the efficiency, even exceeding them\nin model accuracy under more sampling ratio conditions.",
        "translated": "联邦学习(FL)作为一种面向隐私的分布式机器学习模式，由于其保护参与者数据隐私的能力，正在引起物联网的极大兴趣。为了解决标准 FL 中存在的挑战，包括通信效率和隐私保护，已经进行了多项研究。但是他们不能在保证隐私的同时在通信效率和模型精确性之间取得平衡。本文提出了一种条件随机抽样(CRS)方法，并将其应用到标准 FL 设置(CRS-FL)中，以解决上述问题。CRS 探索一个基于泊松试验的随机系数，以获得更高的无偏获得零梯度的概率，然后在不降低模型精度的情况下有效地降低通信开销。此外，我们从理论上挖掘了 CRS 的松弛局部差分隐私(lDP)保证条件。广泛的实验结果表明: (1)在保持通信效率的同时，CRS-FL 在每传输字节的度量精度方面优于现有的方法，在采样率不降低模型精度7% 以上(# 采样大小/# 模型大小)的情况下; (2)在保护隐私方面，CRS-FL 与 LDP 基线相比，在保持通信效率的情况下，在模型精度方面优于现有方法，甚至在更多采样率条件下优于 LDP 基线。"
    },
    {
        "title": "Physical Attacks on the Railway System",
        "url": "http://arxiv.org/abs/2306.00623v1",
        "pub_date": "2023-06-01",
        "summary": "Recent attacks encouraged public interest in physical security for railways.\nKnowing about and learning from previous attacks is necessary to secure against\nthem. This paper presents a structured data set of physical attacks against\nrailways. We analyze the data regarding the used means, the railway system's\ntarget component, the attacker type, and the geographical distribution of\nattacks. The results indicate a growing heterogeneity of observed attacks in\nthe recent decade compared to the previous decades and centuries, making\nprotecting railways more complex.",
        "translated": "最近的袭击事件激发了公众对铁路实体安全的兴趣。了解并从以前的攻击中吸取教训是防范它们的必要条件。本文提出了一个针对铁路的物理攻击的结构化数据集。我们分析了有关使用的手段，铁路系统的目标组件，攻击者的类型和地理分布的攻击的数据。结果表明，与过去几十年和几个世纪相比，近十年来观察到的攻击日益多样化，使得保护铁路变得更加复杂。"
    },
    {
        "title": "Spying on the Spy: Security Analysis of Hidden Cameras",
        "url": "http://arxiv.org/abs/2306.00610v1",
        "pub_date": "2023-06-01",
        "summary": "Hidden cameras, also called spy cameras, are surveillance tools commonly used\nto spy on people without their knowledge. Whilst previous studies largely\nfocused on investigating the detection of such a camera and the privacy\nimplications, the security of the camera itself has received limited attention.\nCompared with ordinary IP cameras, spy cameras are normally sold in bulk at\ncheap prices and are ubiquitously deployed in hidden places within homes and\nworkplaces. A security compromise of these cameras can have severe\nconsequences. In this paper, we analyse a generic IP camera module, which has\nbeen packaged and re-branded for sale by several spy camera vendors. The module\nis controlled by mobile phone apps. By analysing the Android app and the\ntraffic data, we reverse-engineered the security design of the whole system,\nincluding the module's Linux OS environment, the file structure, the\nauthentication mechanism, the session management, and the communication with a\nremote server. Serious vulnerabilities have been identified in every component.\nCombined together, they allow an adversary to take complete control of a spy\ncamera from anywhere over the Internet, enabling arbitrary code execution. This\nis possible even if the camera is behind a firewall. All that an adversary\nneeds to launch an attack is the camera's serial number, which users sometimes\nunknowingly share in online reviews. We responsibly disclosed our findings to\nthe manufacturer. Whilst the manufacturer acknowledged our work, they showed no\nintention to fix the problems. Patching or recalling the affected cameras is\ninfeasible due to complexities in the supply chain. However, it is prudent to\nassume that bad actors have already been exploiting these flaws. We provide\ndetails of the identified vulnerabilities in order to raise public awareness,\nespecially on the grave danger of disclosing a spy camera's serial number.",
        "translated": "隐藏式摄像机，也称为间谍摄像机，是一种监视工具，通常用于在人们不知情的情况下监视他们。虽然以前的研究主要集中在调查这种相机的检测和隐私的影响，相机本身的安全受到有限的关注。与普通的 IP 摄像头相比，间谍摄像头通常以低廉的价格成批出售，并且无处不在地部署在家庭和工作场所的隐蔽地点。这些摄像头的安全隐患会造成严重后果。本文分析了一种通用的 IP 摄像头模块，该模块已被多家间谍摄像头厂商包装并重新命名销售。该模块由手机应用程序控制。通过对 Android 应用程序和流量数据的分析，对整个系统的安全设计进行了逆向工程，包括模块的 Linux 操作系统环境、文件结构、认证机制、会话管理以及与远程服务器的通信。每个部件都有严重的漏洞。结合在一起，他们允许对手从互联网上的任何地方完全控制间谍摄像头，使任意代码执行。即使摄像头位于防火墙之后，这也是可能的。对手发动攻击所需要的只是相机的序列号，用户有时会在不知情的情况下在网上评论中分享这些序列号。我们负责任地向制造商透露了我们的发现。虽然制造商承认我们的工作，但他们没有表现出解决问题的意图。由于供应链的复杂性，修补或召回受影响的相机是不可行的。然而，假设坏人已经在利用这些缺陷是谨慎的。我们提供已识别漏洞的细节，以提高公众意识，特别是对泄露间谍相机序列号的严重危险。"
    },
    {
        "title": "Harnessing large-language models to generate private synthetic text",
        "url": "http://arxiv.org/abs/2306.01684v1",
        "pub_date": "2023-06-02",
        "summary": "Differentially private (DP) training methods like DP-SGD can protect\nsensitive training data by ensuring that ML models will not reveal private\ninformation. An alternative approach, which this paper studies, is to use a\nsensitive dataset to generate a new synthetic dataset which is differentially\nprivate with respect to the original data. Doing so has several advantages:\nsynthetic data can be reused for other tasks (including for hyper parameter\ntuning), retained indefinitely, or shared with third parties without\nsacrificing privacy.\n  However, obtaining DP data is much harder than introducing DP during\ntraining. To make it feasible for text, recent work has utilized public data by\nstarting with a pre-trained generative language model and privately finetuning\nit on sensitive data. This model can be used to sample a DP synthetic dataset.\nWhile this strategy seems straightforward, executing it has proven problematic.\nPrevious approaches either show significant performance loss, or have, as we\nshow, critical design flaws.\n  In this paper we demonstrate that a proper training objective along with\ntuning fewer parameters results in excellent DP synthetic data quality. Our\napproach is competitive with direct DP-training of downstream classifiers in\nterms of performance on downstream tasks. We also demonstrate that our DP\nsynthetic data is not only useful for downstream classifier training, but also\nto tune those same models.",
        "translated": "差异私有(DP)训练方法，如 DP-SGD，可以保护敏感的训练数据，确保机器学习模型不会显示私人信息。本文研究的另一种方法是使用一个敏感数据集生成一个新的合成数据集，该数据集与原始数据相比具有差异私有性。这样做有几个好处: 合成数据可以重用于其他任务(包括超参数调优) ，可以无限期保留，或者在不牺牲隐私的情况下与第三方共享。然而，在训练过程中获取 DP 数据比引入 DP 要困难得多。为了使其适用于文本，最近的工作利用了公共数据，从预先训练的生成语言模型开始，并私下对敏感数据进行微调。此模型可用于对 DP 合成数据集进行采样。虽然这个策略看起来很简单，但是执行起来却有问题。以前的方法要么显示出显著的性能损失，要么如我们所示，存在严重的设计缺陷。本文证明了适当的训练目标和较少的参数调整可以获得优良的 DP 合成数据质量。在下游任务的性能方面，我们的方法与下游分类器的直接 DP 训练是有竞争力的。我们还证明了我们的 DP 合成数据不仅对于下游分类器的训练是有用的，而且对于调整这些相同的模型也是有用的。"
    },
    {
        "title": "Poisoning Network Flow Classifiers",
        "url": "http://arxiv.org/abs/2306.01655v1",
        "pub_date": "2023-06-02",
        "summary": "As machine learning (ML) classifiers increasingly oversee the automated\nmonitoring of network traffic, studying their resilience against adversarial\nattacks becomes critical. This paper focuses on poisoning attacks, specifically\nbackdoor attacks, against network traffic flow classifiers. We investigate the\nchallenging scenario of clean-label poisoning where the adversary's\ncapabilities are constrained to tampering only with the training data - without\nthe ability to arbitrarily modify the training labels or any other component of\nthe training process. We describe a trigger crafting strategy that leverages\nmodel interpretability techniques to generate trigger patterns that are\neffective even at very low poisoning rates. Finally, we design novel strategies\nto generate stealthy triggers, including an approach based on generative\nBayesian network models, with the goal of minimizing the conspicuousness of the\ntrigger, and thus making detection of an ongoing poisoning campaign more\nchallenging. Our findings provide significant insights into the feasibility of\npoisoning attacks on network traffic classifiers used in multiple scenarios,\nincluding detecting malicious communication and application classification.",
        "translated": "随着机器学习(ML)分类器越来越多地监督网络流量的自动化监控，研究它们对抗对手攻击的弹性变得至关重要。本文主要研究针对网络流量分类器的中毒攻击，特别是后门攻击。我们调查的具有挑战性的场景，清洁标签中毒，其中对手的能力被限制篡改只与训练数据-没有能力任意修改训练标签或任何其他组成部分的训练过程。我们描述了一种触发器制作策略，它利用模型可解释性技术来生成触发器模式，即使在非常低的中毒率下也是有效的。最后，我们设计了新的策略来产生隐秘的触发器，包括一种基于生成贝氏网路模型的方法，目标是最小化触发器的显著性，从而使正在进行的中毒活动的检测更具挑战性。我们的研究结果提供了重要的见解，中毒攻击的网络流量分类器使用在多个场景的可行性，包括检测恶意通信和应用程序分类。"
    },
    {
        "title": "Blockchain Model for Environment/Infrastructure Monitoring in\n  Cloud-Enabled High-Altitude Platform Systems",
        "url": "http://arxiv.org/abs/2306.01616v1",
        "pub_date": "2023-06-02",
        "summary": "The recently accentuated features of augmenting conventional wireless\nnetworks with high altitude platform systems (HAPS) have fueled a plethora of\napplications, which promise to offer new services to ground users, as well to\nenhance the efficiency and pervasion of existing applications. Cloud-enabled\nHAPS, which aims to create HAPS-based datacenters that offer cloud services to\nusers, has particularly emerged as a promising key enabler to provide\nlarge-scale equitable services from the sky. Although offering cloud services\nfrom the HAPS proves to be efficient, its practical deployment at the\nstratosphere level still faces many challenges such as high energy\nrequirements, physical maintenance, and is particularly prone to security\nconsiderations. Safeguarding the cloud-enabled HAPS against various\ncyberattacks is a necessity to guarantee its safe operation. This paper\nproposes a blockchain model to secure cloud-enabled HAPS networks that contain\na large number of HAPS stations from recurring cyberattacks within the context\nof the environment and infrastructure monitoring (EIM) application. To this\nend, the paper first presents a detailed blockchain framework, and describes\nthe ways of integrating the developed framework into the various system\ncomponents. We then discuss the details of the system implementation, including\nthe storing and consuming of cloud transactions, the generation of new blocks,\nand the blockchain consensus protocol that is tailored to the EIM requirements.\nFinally, we present numerical simulations that illustrate the performance of\nthe system in terms of throughput, latency, and resilience to attacks.",
        "translated": "最近强调的用高海拔平台系统(HAPS)增强传统无线网络的特点推动了大量应用，这些应用有望为地面用户提供新的服务，并提高现有应用的效率和普及程度。支持云计算的 HAPS，旨在创建基于 HAPS 的数据中心，为用户提供云服务，已经成为从天而降提供大规模公平服务的一个有前途的关键推动者。尽管 HAPS 提供的云服务被证明是有效的，但它在平流层的实际部署仍然面临许多挑战，如高能耗要求、物理维护，并且特别容易受到安全考虑的影响。保护云端 HAPS 免受各种网络攻击是保证其安全运行的必要条件。本文提出了一种区块链模型，以保护包含大量 HAPS 站点的云支持的 HAPS 网络在环境和基础设施监测(EIM)应用的背景下免受反复出现的网络攻击。为此，本文首先提出了一个详细的区块链框架，并描述了如何将开发的框架集成到各种系统组件中。然后，我们讨论系统实现的细节，包括云事务的存储和使用、新块的生成以及根据 EIM 需求量身定制的块链共识协议。最后，我们给出了数值模拟，说明了系统在吞吐量、延迟和抗攻击能力方面的性能。"
    },
    {
        "title": "Hyperparameter Learning under Data Poisoning: Analysis of the Influence\n  of Regularization via Multiobjective Bilevel Optimization",
        "url": "http://arxiv.org/abs/2306.01613v1",
        "pub_date": "2023-06-02",
        "summary": "Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a\nfraction of the training data is manipulated to deliberately degrade the\nalgorithms' performance. Optimal attacks can be formulated as bilevel\noptimization problems and help to assess their robustness in worst-case\nscenarios. We show that current approaches, which typically assume that\nhyperparameters remain constant, lead to an overly pessimistic view of the\nalgorithms' robustness and of the impact of regularization. We propose a novel\noptimal attack formulation that considers the effect of the attack on the\nhyperparameters and models the attack as a multiobjective bilevel optimization\nproblem. This allows to formulate optimal attacks, learn hyperparameters and\nevaluate robustness under worst-case conditions. We apply this attack\nformulation to several ML classifiers using $L_2$ and $L_1$ regularization. Our\nevaluation on multiple datasets confirms the limitations of previous strategies\nand evidences the benefits of using $L_2$ and $L_1$ regularization to dampen\nthe effect of poisoning attacks.",
        "translated": "机器学习(ML)算法容易受到中毒攻击，其中一小部分训练数据被操纵，故意降低算法的性能。最优攻击可以表述为两级优化问题，并帮助评估它们在最坏情况下的鲁棒性。我们表明，当前的方法，通常假设超参数保持不变，导致过度悲观的看法，算法的健壮性和正则化的影响。我们提出了一种新的最优攻击公式，该公式考虑了攻击对超参数的影响，并将攻击建模为一个多目标双层最佳化问题。这允许制定最佳攻击，学习超参数和评估最坏情况下的健壮性。我们使用 $L _ 2 $和 $L _ 1 $正则化将这种攻击公式应用于多个 ML 分类器。我们对多个数据集的评估证实了以往策略的局限性，并证明了使用 $L _ 2 $和 $L _ 1 $正则化抑制中毒攻击效果的好处。"
    },
    {
        "title": "PassGPT: Password Modeling and (Guided) Generation with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.01545v1",
        "pub_date": "2023-06-02",
        "summary": "Large language models (LLMs) successfully model natural language from vast\namounts of text without the need for explicit supervision. In this paper, we\ninvestigate the efficacy of LLMs in modeling passwords. We present PassGPT, a\nLLM trained on password leaks for password generation. PassGPT outperforms\nexisting methods based on generative adversarial networks (GAN) by guessing\ntwice as many previously unseen passwords. Furthermore, we introduce the\nconcept of guided password generation, where we leverage PassGPT sampling\nprocedure to generate passwords matching arbitrary constraints, a feat lacking\nin current GAN-based strategies. Lastly, we conduct an in-depth analysis of the\nentropy and probability distribution that PassGPT defines over passwords and\ndiscuss their use in enhancing existing password strength estimators.",
        "translated": "大语言模型(LLM)成功地从大量的文本中建模自然语言，而不需要显式的监督。在本文中，我们研究了 LLM 建模密码的功效。我们介绍 PassGPT，它是一个受过密码泄漏培训的 LLM，用于生成密码。PassGPT 的性能优于现有的基于生成对抗网络(GAN)的方法，因为它可以猜测两倍以前未见过的密码。此外，我们还引入了引导密码生成的概念，利用 PassGPT 采样过程生成匹配任意约束的密码，这是目前基于 GAN 的策略所缺乏的。最后，我们对 PassGPT 定义的密码熵和概率分布进行了深入的分析，并讨论了它们在增强现有密码强度估计中的应用。"
    },
    {
        "title": "Guiding Text-to-Text Privatization by Syntax",
        "url": "http://arxiv.org/abs/2306.01471v1",
        "pub_date": "2023-06-02",
        "summary": "Metric Differential Privacy is a generalization of differential privacy\ntailored to address the unique challenges of text-to-text privatization. By\nadding noise to the representation of words in the geometric space of\nembeddings, words are replaced with words located in the proximity of the noisy\nrepresentation. Since embeddings are trained based on word co-occurrences, this\nmechanism ensures that substitutions stem from a common semantic context.\nWithout considering the grammatical category of words, however, this mechanism\ncannot guarantee that substitutions play similar syntactic roles. We analyze\nthe capability of text-to-text privatization to preserve the grammatical\ncategory of words after substitution and find that surrogate texts consist\nalmost exclusively of nouns. Lacking the capability to produce surrogate texts\nthat correlate with the structure of the sensitive texts, we encompass our\nanalysis by transforming the privatization step into a candidate selection\nproblem in which substitutions are directed to words with matching grammatical\nproperties. We demonstrate a substantial improvement in the performance of\ndownstream tasks by up to $4.66\\%$ while retaining comparative privacy\nguarantees.",
        "translated": "公制差分隐私是为了应对文本到文本私有化的独特挑战而量身定做的差分隐私的概括。通过在嵌入的几何空间中的词语表示中添加噪声，将词语替换为位于噪声表示附近的词语。由于嵌入是基于词的共现进行训练的，所以这种机制确保替换来自一个共同的语义上下文。然而，如果不考虑单词的语法范畴，这种机制不能保证替换能够发挥类似的句法作用。我们分析了文本到文本私有化的能力，以保存替换后的单词的语法范畴，并发现替代文本几乎完全由名词组成。由于缺乏产生与敏感文本结构相关的替代文本的能力，我们通过将私有化步骤转化为候选人选择问题来包含我们的分析，其中替换指向具有匹配语法属性的单词。我们证明了在保留相对隐私保障的情况下，下游任务的性能提高了4.66% 。"
    },
    {
        "title": "Network Agnostic MPC with Statistical Security",
        "url": "http://arxiv.org/abs/2306.01401v1",
        "pub_date": "2023-06-02",
        "summary": "We initiate the study of the network agnostic MPC protocols with statistical\nsecurity. Network agnostic protocols give the best possible security guarantees\nirrespective of the underlying network type. We consider the general-adversary\nmodel, where the adversary is characterized by an adversary structure which\nenumerates all possible candidate subsets of corrupt parties. The\n$\\mathcal{Q}^{(k)}$ condition enforces that the union of no $k$ subsets from\nthe adversary structure covers the party set. Given an unconditionally-secure\nPKI setup, known statistically-secure synchronous MPC protocols are secure\nagainst adversary structures satisfying the $\\mathcal{Q}^{(2)}$ condition.\nKnown statistically-secure asynchronous MPC protocols can tolerate\n$\\mathcal{Q}^{(3)}$ adversary structures. Fix a set of $n$ parties $\\mathcal{P}\n= \\{P_1, ... ,P_n\\}$ and adversary structures $\\mathcal{Z}_s$ and\n$\\mathcal{Z}_a$, satisfying the $\\mathcal{Q}^{(2)}$ and $\\mathcal{Q}^{(3)}$\nconditions respectively, where $\\mathcal{Z}_a \\subset \\mathcal{Z}_s$. Then,\ngiven an unconditionally-secure PKI, we ask whether it is possible to design a\nstatistically-secure MPC protocol resilient against $\\mathcal{Z}_s$ and\n$\\mathcal{Z}_a$ in a synchronous and an asynchronous network respectively if\nthe parties in $\\mathcal{P}$ are unaware of the network type. We show that it\nis possible iff $\\mathcal{Z}_s$ and $\\mathcal{Z}_a$ satisfy the\n$\\mathcal{Q}^{(2,1)}$ condition, meaning that the union of any two subsets from\n$\\mathcal{Z}_s$ and any one subset from $\\mathcal{Z}_a$ is a proper subset of\n$\\mathcal{P}$. We design several important network agnostic building blocks\nwith the $\\mathcal{Q}^{(2,1)}$ condition, such as Byzantine broadcast,\nByzantine agreement, information checking protocol, verifiable secret-sharing\nand secure multiplication protocol, whose complexity is polynomial in $n$ and\n$|\\mathcal{Z}_s|$.",
        "translated": "我们开始研究具有统计安全性的网络不可知 MPC 协议。无论底层网络类型如何，网络不可知协议都能提供最好的安全保证。我们考虑一般对手模型，在这个模型中，对手的对手拥有属性结构列举了腐败政党的所有可能的候选子集。$mathcal { Q } ^ {(k)} $条件强制要求对手结构中没有 $k $子集的并集覆盖方集。给定一个无条件安全的 PKI 设置，已知的统计安全的同步 MPC 协议可以安全地对抗满足 $数学{ Q } ^ {(2)} $条件的对手结构。已知的统计安全异步 MPC 协议可以容忍 $精确{ Q } ^ {(3)} $对手结构。修正了一组 $n $方 $数学{ P } = { P _ 1，... ，P _ n } $和对手结构 $数学{ Z } _ s $和 $数学{ Z } _ a $，分别满足 $数学{ Q } ^ {(2)} $和 $数学{ Q } ^ {(3)} $条件，其中 $数学{ Z } _ a 子集数学{ Z } _ s $。然后，给定一个无条件安全的 PKI，我们询问是否有可能设计一个统计安全的 MPC 协议，分别在同步网络和异步网络中分别对抗 $mathcal { Z } s $和 $mathcal { Z } a $，如果 $mathcal { P } $中的各方不知道网络类型。我们证明了 $mathal { Z } _ s $和 $mathal { Z } _ a $满足 $mathal { Q } ^ {(2,1)} $条件的可能性，这意味着 $mathal { Z } _ s $的任意两个子集和 $mathal { Z } _ a $的任意一个子集的并是 $mathal { P } $的一个真子集。设计了几个具有 $数学{ Q } ^ {(2,1)} $条件的重要网络不可知构件，如拜占庭广播、拜占庭协议、信息检查协议、可验证秘密共享和安全乘法协议，其复杂度为 $n $和 $| 数学{ Z } _ s | $。"
    },
    {
        "title": "Adaptive Attractors: A Defense Strategy against ML Adversarial Collusion\n  Attacks",
        "url": "http://arxiv.org/abs/2306.01400v1",
        "pub_date": "2023-06-02",
        "summary": "In the seller-buyer setting on machine learning models, the seller generates\ndifferent copies based on the original model and distributes them to different\nbuyers, such that adversarial samples generated on one buyer's copy would\nlikely not work on other copies. A known approach achieves this using\nattractor-based rewriter which injects different attractors to different\ncopies. This induces different adversarial regions in different copies, making\nadversarial samples generated on one copy not replicable on others. In this\npaper, we focus on a scenario where multiple malicious buyers collude to\nattack. We first give two formulations and conduct empirical studies to analyze\neffectiveness of collusion attack under different assumptions on the attacker's\ncapabilities and properties of the attractors. We observe that existing\nattractor-based methods do not effectively mislead the colluders in the sense\nthat adversarial samples found are influenced more by the original model\ninstead of the attractors as number of colluders increases. Based on this\nobservation, we propose using adaptive attractors whose weight is guided by a\nU-shape curve to cover the shortfalls. Experimentation results show that when\nusing our approach, the attack success rate of a collusion attack converges to\naround 15% even when lots of copies are applied for collusion. In contrast,\nwhen using the existing attractor-based rewriter with fixed weight, the attack\nsuccess rate increases linearly with the number of copies used for collusion.",
        "translated": "在机器学习模型中，卖方根据原始模型生成不同的副本，并将其分发给不同的买方，因此在一个买方副本上生成的对抗性样本可能不适用于其他副本。一个已知的方法实现这一点使用基于吸引子的重写器注入不同的吸引子不同的副本。这会在不同的拷贝中产生不同的对抗性区域，使得在一个拷贝上产生的对抗性样本不能在其他拷贝上复制。在本文中，我们关注的是多个恶意买家串通攻击的场景。我们首先给出了两个公式并进行了实证研究，分析了在不同的攻击者能力和吸引子性质的假设下，合谋攻击的有效性。我们观察到现有的基于吸引子的方法并不能有效地误导合谋者，因为随着合谋者数量的增加，发现的对手样本受原始模型的影响更大，而不是吸引子。在此基础上，我们提出了利用自适应吸引子的权重指导下的 U 形曲线来弥补这一不足。实验结果表明，当使用该方法时，即使使用大量拷贝进行合谋攻击，合谋攻击的成功率也会收敛到15% 左右。相比之下，当使用现有的具有固定权重的基于吸引子的重写器时，攻击成功率随着用于合谋的拷贝数的增加而线性增加。"
    },
    {
        "title": "Towards Robust GAN-generated Image Detection: a Multi-view Completion\n  Representation",
        "url": "http://arxiv.org/abs/2306.01364v1",
        "pub_date": "2023-06-02",
        "summary": "GAN-generated image detection now becomes the first line of defense against\nthe malicious uses of machine-synthesized image manipulations such as\ndeepfakes. Although some existing detectors work well in detecting clean, known\nGAN samples, their success is largely attributable to overfitting unstable\nfeatures such as frequency artifacts, which will cause failures when facing\nunknown GANs or perturbation attacks. To overcome the issue, we propose a\nrobust detection framework based on a novel multi-view image completion\nrepresentation. The framework first learns various view-to-image tasks to model\nthe diverse distributions of genuine images. Frequency-irrelevant features can\nbe represented from the distributional discrepancies characterized by the\ncompletion models, which are stable, generalized, and robust for detecting\nunknown fake patterns. Then, a multi-view classification is devised with\nelaborated intra- and inter-view learning strategies to enhance view-specific\nfeature representation and cross-view feature aggregation, respectively. We\nevaluated the generalization ability of our framework across six popular GANs\nat different resolutions and its robustness against a broad range of\nperturbation attacks. The results confirm our method's improved effectiveness,\ngeneralization, and robustness over various baselines.",
        "translated": "GAN 生成的图像检测现在成为对抗恶意使用机器合成图像操作(如深度伪造)的第一道防线。虽然现有的一些探测器在检测干净的已知 GAN 样本方面表现良好，但是它们的成功主要归功于过度拟合不稳定特征，例如频率伪影，这些特征在面对未知 GAN 或扰动攻击时会导致故障。为了克服这一问题，我们提出了一种基于多视图图像完成表示的鲁棒检测框架。该框架首先学习各种视图到图像的任务，以建模真实图像的不同分布。频率无关的特征可以通过完成模型的分布差异来表示，完成模型具有稳定性、广义性和鲁棒性，能够检测未知的虚假拥有属性。在此基础上，设计了多视图分类方法，并详细阐述了视图内和视图间的学习策略，分别增强了视图特征表示和跨视图特征聚合。我们评估了我们的框架在六个不同分辨率的流行 GAN 上的泛化能力，以及它对大范围扰动攻击的鲁棒性。实验结果证实了该方法在不同基线条件下的有效性、泛化性和鲁棒性得到了提高。"
    },
    {
        "title": "FedCIP: Federated Client Intellectual Property Protection with Traitor\n  Tracking",
        "url": "http://arxiv.org/abs/2306.01356v1",
        "pub_date": "2023-06-02",
        "summary": "Federated learning is an emerging privacy-preserving distributed machine\nlearning that enables multiple parties to collaboratively learn a shared model\nwhile keeping each party's data private. However, federated learning faces two\nmain problems: semi-honest server privacy inference attacks and malicious\nclient-side model theft. To address privacy inference attacks, parameter-based\nencrypted federated learning secure aggregation can be used. To address model\ntheft, a watermark-based intellectual property protection scheme can verify\nmodel ownership. Although watermark-based intellectual property protection\nschemes can help verify model ownership, they are not sufficient to address the\nissue of continuous model theft by uncaught malicious clients in federated\nlearning. Existing IP protection schemes that have the ability to track\ntraitors are also not compatible with federated learning security aggregation.\nThus, in this paper, we propose a Federated Client-side Intellectual Property\nProtection (FedCIP), which is compatible with federated learning security\naggregation and has the ability to track traitors. To the best of our\nknowledge, this is the first IP protection scheme in federated learning that is\ncompatible with secure aggregation and tracking capabilities.",
        "translated": "联合学习是一种新兴的保护隐私的分布式机器学习，它使多方能够协作学习共享模型，同时保持各方数据的私有性。然而，联邦学习面临两个主要问题: 半诚实的服务器隐私推理攻击和恶意的客户端模型盗窃。为了解决隐私推理攻击，可以使用基于参数的加密联邦学习安全聚合。为了解决模型盗窃问题，一种基于水印的知识产权保护方案可以验证模型所有权。尽管基于水印的知识产权保护方案可以帮助验证模型所有权，但它们不足以解决联邦学习中未被抓获的恶意客户端持续盗窃模型的问题。具有跟踪叛徒能力的现有 IP 保护方案也不兼容联邦学习安全聚合。因此，本文提出了一种联邦客户端知识产权保护协议(FedCIP) ，该协议兼容联邦学习安全集成，具有追踪叛徒的能力。据我们所知，这是联邦学习中第一个与安全聚合和跟踪能力兼容的 IP 保护方案。"
    },
    {
        "title": "Discriminative Adversarial Privacy: Balancing Accuracy and Membership\n  Privacy in Neural Networks",
        "url": "http://arxiv.org/abs/2306.03054v1",
        "pub_date": "2023-06-05",
        "summary": "The remarkable proliferation of deep learning across various industries has\nunderscored the importance of data privacy and security in AI pipelines. As the\nevolution of sophisticated Membership Inference Attacks (MIAs) threatens the\nsecrecy of individual-specific information used for training deep learning\nmodels, Differential Privacy (DP) raises as one of the most utilized techniques\nto protect models against malicious attacks. However, despite its proven\ntheoretical properties, DP can significantly hamper model performance and\nincrease training time, turning its use impractical in real-world scenarios.\nTackling this issue, we present Discriminative Adversarial Privacy (DAP), a\nnovel learning technique designed to address the limitations of DP by achieving\na balance between model performance, speed, and privacy. DAP relies on\nadversarial training based on a novel loss function able to minimise the\nprediction error while maximising the MIA's error. In addition, we introduce a\nnovel metric named Accuracy Over Privacy (AOP) to capture the\nperformance-privacy trade-off. Finally, to validate our claims, we compare DAP\nwith diverse DP scenarios, providing an analysis of the results from\nperformance, time, and privacy preservation perspectives.",
        "translated": "深度学习在各个行业的显著扩散突出了人工智能管道中数据隐私和安全的重要性。随着复杂的成员推理攻击(MIAs)的发展，威胁到用于训练深度学习模型的个人特定信息的保密性，差分隐私(DP)成为保护模型免受恶意攻击的最常用技术之一。然而，尽管 DP 的理论性能得到了证明，但它会显著地阻碍模型的性能并增加训练时间，使其在现实世界中的使用变得不切实际。针对这一问题，我们提出了一种新的学习技术——歧视性对抗性隐私(DAP) ，旨在通过实现模型性能、速度和隐私之间的平衡来解决 DP 的局限性。DAP 依赖于基于一种新的损失函数的对抗性训练，能够最小化预测误差，同时最大化 MIA 的误差。此外，我们还引入了一个新的度量标准，称为隐私精确度(AOP) ，以捕获性能-隐私权衡。最后，为了验证我们的主张，我们将 DAP 与不同的 DP 场景进行了比较，从性能、时间和隐私保护的角度对结果进行了分析。"
    },
    {
        "title": "Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated\n  Learning",
        "url": "http://arxiv.org/abs/2306.03013v2",
        "pub_date": "2023-06-05",
        "summary": "Malicious server (MS) attacks have enabled the scaling of data stealing in\nfederated learning to large batch sizes and secure aggregation, settings\npreviously considered private. However, many concerns regarding client-side\ndetectability of MS attacks were raised, questioning their practicality once\nthey are publicly known. In this work, for the first time, we thoroughly study\nthe problem of client-side detectability.We demonstrate that most prior MS\nattacks, which fundamentally rely on one of two key principles, are detectable\nby principled client-side checks. Further, we formulate desiderata for\npractical MS attacks and propose SEER, a novel attack framework that satisfies\nall desiderata, while stealing user data from gradients of realistic networks,\neven for large batch sizes (up to 512 in our experiments) and under secure\naggregation. The key insight of SEER is the use of a secret decoder, which is\njointly trained with the shared model. Our work represents a promising first\nstep towards more principled treatment of MS attacks, paving the way for\nrealistic data stealing that can compromise user privacy in real-world\ndeployments.",
        "translated": "恶意服务器(MS)攻击使联邦学习中的数据窃取扩展到大批量和安全聚合，这些设置以前被认为是私有的。然而，许多关于 MS 攻击的客户端可检测性的担忧被提出，质疑它们的实用性，一旦它们被公开知道。在这项工作中，我们首次深入研究了客户端的可检测性问题。我们证明了大多数先前的 MS 攻击，基本上依赖于两个关键原则之一，是可以通过原则性的客户端检查来检测的。此外，我们为实际的 MS 攻击制定了急需数据，并提出了 SEER，一种满足所有急需数据的新型攻击框架，同时从现实网络的梯度中窃取用户数据，即使是在大批量(在我们的实验中高达512)和安全聚合的情况下。SEER 的关键见解是使用秘密解码器，该解码器与共享模型共同训练。我们的工作是朝着更有原则地处理 MS 攻击迈出的有希望的第一步，为在现实世界部署中可能损害用户隐私的现实数据窃取铺平了道路。"
    },
    {
        "title": "Evading Black-box Classifiers Without Breaking Eggs",
        "url": "http://arxiv.org/abs/2306.02895v1",
        "pub_date": "2023-06-05",
        "summary": "Decision-based evasion attacks repeatedly query a black-box classifier to\ngenerate adversarial examples. Prior work measures the cost of such attacks by\nthe total number of queries made to the classifier. We argue this metric is\nflawed. Most security-critical machine learning systems aim to weed out \"bad\"\ndata (e.g., malware, harmful content, etc). Queries to such systems carry a\nfundamentally asymmetric cost: queries detected as \"bad\" come at a higher cost\nbecause they trigger additional security filters, e.g., usage throttling or\naccount suspension. Yet, we find that existing decision-based attacks issue a\nlarge number of \"bad\" queries, which likely renders them ineffective against\nsecurity-critical systems. We then design new attacks that reduce the number of\nbad queries by $1.5$-$7.3\\times$, but often at a significant increase in total\n(non-bad) queries. We thus pose it as an open problem to build black-box\nattacks that are more effective under realistic cost metrics.",
        "translated": "基于决策的规避攻击通过重复查询黑盒分类器来生成对抗性例子。之前的工作通过对分类器的查询总数来度量这种攻击的成本。我们认为这个度量标准是有缺陷的。大多数安全性关键的机器学习系统旨在清除“坏”数据(例如，恶意软件、有害内容等)。对这种系统的查询有一个根本上不对称的成本: 被检测为“坏”的查询的成本更高，因为它们会触发额外的安全过滤器，例如，使用节流或帐户暂停。然而，我们发现现有的基于决策的攻击会发出大量“坏”查询，这可能使它们对安全关键系统无效。然后我们设计新的攻击，将坏查询的数量减少1.5美元-7.3美元乘以 $，但是总的(非坏的)查询数量通常会显著增加。因此，我们提出了一个开放的问题来构建在现实成本指标下更有效的黑盒攻击。"
    },
    {
        "title": "Modular zk-Rollup On-Demand",
        "url": "http://arxiv.org/abs/2306.02785v1",
        "pub_date": "2023-06-05",
        "summary": "The rapid expansion of the use of blockchain-based systems often leads to a\nchoice between customizable private blockchains and more secure, scalable and\ndecentralized but expensive public blockchains. This choice represents the\ntrade-off between privacy and customization at a low cost and security,\nscalability, and a large user base but at a high cost. In order to improve the\nscalability of secure public blockchains while enabling privacy and cost\nreduction, zk-rollups, a layer 2 solution, appear to be a promising avenue.\nThis paper explores the benefits of zk-rollups, including improved privacy, as\nwell as their potential to support transactions designed for specific\napplications. We propose an innovative design that allows multiple zk-rollups\nto co-exist on the same smart contracts, simplifying their creation and\ncustomization. We then evaluate the first implementation of our system\nhighlighting a low overhead on existing transaction types and on proof\ngeneration while strongly decreasing the cost of new transaction types and\ndrastically reducing zk-rollup creation costs.",
        "translated": "基于区块链系统使用的快速扩展通常导致在可定制的私人区块链和更安全、可扩展和分散但昂贵的公共区块链之间进行选择。这种选择代表了在低成本、安全性、可伸缩性和大用户基础(但成本较高)的隐私和定制之间的权衡。为了在保护隐私和降低成本的同时提高安全公共区块链的可伸缩性，第二层解决方案 zk-rollup 似乎是一个有前途的途径。本文探讨 zk-rollup 的好处，包括提高隐私性，以及它们支持为特定应用程序设计的事务的潜力。我们提出了一个创新的设计，允许多 zk-rollup 共存在相同的智能合同，简化他们的创建和定制。然后，我们评估了我们系统的第一个实现，突出了现有事务类型和证明生成的低开销，同时大大降低了新事务类型的成本，并大大降低了 zk-rolup 创建成本。"
    },
    {
        "title": "Federated Intrusion Detection System based on Deep Belief Networks",
        "url": "http://arxiv.org/abs/2306.02715v1",
        "pub_date": "2023-06-05",
        "summary": "The vast increase of IoT technologies and the ever-evolving attack vectors\nand threat actors have increased cyber-security risks dramatically. Novel\nattacks can compromise IoT devices to gain access to sensitive data or control\nthem to deploy further malicious activities. The detection of novel attacks\noften relies upon AI solutions. A common approach to implementing AI-based IDS\nin distributed IoT systems is in a centralised manner. However, this approach\nmay violate data privacy and secrecy. In addition, centralised data collection\nprohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT\necosystems need to move towards a decentralised direction. FL has attracted\nsignificant interest in recent years due to its ability to perform\ncollaborative learning while preserving data confidentiality and locality.\nNevertheless, most FL-based IDS for IoT systems are designed under unrealistic\ndata distribution conditions. To that end, we design an experiment\nrepresentative of the real world and evaluate the performance of two FL IDS\nimplementations, one based on DNNs and another on our previous work on DBNs.\nFor our experiments, we rely on TON-IoT, a realistic IoT network traffic\ndataset, associating each IP address with a single FL client. Additionally, we\nexplore pre-training and investigate various aggregation methods to mitigate\nthe impact of data heterogeneity. Lastly, we benchmark our approach against a\ncentralised solution. The comparison shows that the heterogeneous nature of the\ndata has a considerable negative impact on the model performance when trained\nin a distributed manner. However, in the case of a pre-trained initial global\nFL model, we demonstrate a performance improvement of over 20% (F1-score) when\ncompared against a randomly initiated global model.",
        "translated": "物联网技术的飞速发展以及不断演变的攻击媒介和威胁行为者已经极大地增加了网络安全风险。新型的攻击可以危害物联网设备，以获得敏感数据的访问或控制它们部署进一步的恶意活动。新型攻击的检测常常依赖于人工智能的解决方案。在分布式物联网系统中实现基于人工智能的入侵检测系统的一种常见方法是采用集中方式。然而，这种方法可能会侵犯数据的隐私性和保密性。此外，中央数据收集禁止扩大入侵检测系统的规模。因此，物联网生态系统中的入侵检测解决方案需要朝着分散化的方向发展。由于能够在保护数据机密性和本地性的同时执行合作学习操作，FL 近年来引起了人们的极大兴趣。然而，大多数基于 FL 的物联网入侵检测系统都是在不切实际的数据分发条件下设计的。为此，我们设计了一个真实世界的实验代表，并评估了两个 FL IDS 实现的性能，一个基于 DNN，另一个基于我们以前在 DBN 上的工作。对于我们的实验，我们依赖 TON-IoT，一个真实的物联网流量数据集，将每个 IP 地址与一个 FL 客户端关联起来。此外，我们探索预训练和调查各种聚合方法，以减轻数据异构性的影响。最后，我们以集中解决方案为基准来衡量我们的方法。比较表明，当以分布式方式训练时，数据的异构性质对模型性能有相当大的负面影响。然而，在预先训练的初始全局 FL 模型的情况下，与随机启动的全局模型相比，我们证明了超过20% 的性能提高(F1分数)。"
    },
    {
        "title": "A Privacy-Preserving Federated Learning Approach for Kernel methods",
        "url": "http://arxiv.org/abs/2306.02677v1",
        "pub_date": "2023-06-05",
        "summary": "It is challenging to implement Kernel methods, if the data sources are\ndistributed and cannot be joined at a trusted third party for privacy reasons.\nIt is even more challenging, if the use case rules out privacy-preserving\napproaches that introduce noise. An example for such a use case is machine\nlearning on clinical data. To realize exact privacy preserving computation of\nkernel methods, we propose FLAKE, a Federated Learning Approach for KErnel\nmethods on horizontally distributed data. With FLAKE, the data sources mask\ntheir data so that a centralized instance can compute a Gram matrix without\ncompromising privacy. The Gram matrix allows to calculate many kernel matrices,\nwhich can be used to train kernel-based machine learning algorithms such as\nSupport Vector Machines. We prove that FLAKE prevents an adversary from\nlearning the input data or the number of input features under a semi-honest\nthreat model. Experiments on clinical and synthetic data confirm that FLAKE is\noutperforming the accuracy and efficiency of comparable methods. The time\nneeded to mask the data and to compute the Gram matrix is several orders of\nmagnitude less than the time a Support Vector Machine needs to be trained.\nThus, FLAKE can be applied to many use cases.",
        "translated": "如果数据源是分布式的，并且由于隐私原因不能在可信的第三方连接，那么实现内核方法就很有挑战性。如果用例排除了引入噪音的保护隐私的方法，那么就更具挑战性了。这种用例的一个例子是基于临床数据的机器学习。为了实现核方法的精确隐私保护计算，我们提出了一种水平分布数据核方法的联邦学习方法 FLAKE。在 FLAKE，数据源掩盖了他们的数据，这样一个集中的实例就可以在不损害隐私的情况下计算出一个 Gram 矩阵。Gram 矩阵允许计算许多核矩阵，可用于训练基于核的机器学习算法，如支持向量机。证明了在半诚实威胁模型下，FLAKE 可以防止对手学习输入数据或输入特征的个数。临床和合成数据的实验证实，FLAKE 的准确性和效率优于可比较的方法。掩盖数据和计算格拉姆矩阵所需的时间比训练数量级支持向量机所需的时间少了好几倍。因此，FLAKE 可以应用于许多用例。"
    },
    {
        "title": "Efficient Algorithms for Modeling SBoxes Using MILP",
        "url": "http://arxiv.org/abs/2306.02642v1",
        "pub_date": "2023-06-05",
        "summary": "Mixed Integer Linear Programming (MILP) is a well-known approach for the\ncryptanalysis of a symmetric cipher. A number of MILP-based security analyses\nhave been reported for non-linear (SBoxes) and linear layers. Researchers\nproposed word- and bit-wise SBox modeling techniques using a set of\ninequalities which helps in searching differential trails for a cipher. In this\npaper, we propose two new techniques to reduce the number of inequalities to\nrepresent the valid differential transitions for SBoxes. Our first technique\nchooses the best greedy solution with a random tiebreaker and achieves improved\nresults for the 4-bit SBoxes of MIBS, LBlock, and Serpent over the existing\nresults of Sun et al. [25]. Subset addition, our second approach, is an\nimprovement over the algorithm proposed by Boura and Coggia. Subset addition\ntechnique is faster than Boura and Coggia [10] and also improves the count of\ninequalities. Our algorithm emulates the existing results for the 4-bit SBoxes\nof Minalpher, LBlock, Serpent, Prince, and Rectangle. The subset addition\nmethod also works for 5-bit and 6-bit SBoxes. We improve the boundary of\nminimum number inequalities from the existing results for 5-bit SBoxes of ASCON\nand SC2000. Application of subset addition technique for 6-bit SBoxes of APN,\nFIDES, and SC2000 enhances the existing results. By applying multithreading, we\nreduced the execution time needed to find the minimum inequality set over the\nexisting techniques.",
        "translated": "混合整数线性规划(mILP)是一种著名的对称密码密码分析方法。针对非线性(SBox)和线性层，已经报道了许多基于 MILP 的安全性分析。研究人员提出了使用一组不等式的字和位 SBox 建模技术，这些不等式有助于搜索密码的差分路径。在本文中，我们提出了两个新的技巧，以减少不等式的数目来表示有效的微分过渡。我们的第一个技术使用随机抢七选择最好的贪婪解决方案，并且比 Sun 等人的现有结果更好地实现了 MIBS、 LBlock 和 Snake 的4位 SBox 的结果[25]。子集加法是我们的第二种方法，是对 Boura 和 Coggia 提出的算法的改进。子集加法比 Boura 和 Coggia [10]更快，也提高了不等式的计数。我们的算法模拟了 Minalpher、 LBlock、 Snake、 Prince 和矩形的4位 SBoxes 的现有结果。子集添加方法也适用于5位和6位 SBox。从 ASCON 和 SC2000的5位 SBox 的已有结果出发，改进了最小数不等式的边界。对 APN、 FIDES 和 SC2000等6位 SBox 的子集加入技术的应用增强了已有的结果。通过应用多线程，我们减少了在现有技术上寻找最小不等式集所需的执行时间。"
    },
    {
        "title": "Building Resilient SMEs: Harnessing Large Language Models for Cyber\n  Security in Australia",
        "url": "http://arxiv.org/abs/2306.02612v1",
        "pub_date": "2023-06-05",
        "summary": "The escalating digitalisation of our lives and enterprises has led to a\nparallel growth in the complexity and frequency of cyber-attacks. Small and\nmedium-sized enterprises (SMEs), particularly in Australia, are experiencing\nincreased vulnerability to cyber threats, posing a significant challenge to the\nnation's cyber security landscape. Embracing transformative technologies such\nas Artificial Intelligence (AI), Machine Learning (ML) and Large Language\nModels (LLMs) can potentially strengthen cyber security policies for Australian\nSMEs. However, their practical application, advantages, and limitations remain\nunderexplored, with prior research mainly focusing on large corporations. This\nstudy aims to address this gap by providing a comprehensive understanding of\nthe potential role of LLMs in enhancing cyber security policies for Australian\nSMEs. Employing a mixed-methods study design, this research includes a\nliterature review, qualitative analysis of SME case studies, and a quantitative\nassessment of LLM performance metrics in cyber security applications. The\nfindings highlight the promising potential of LLMs across various performance\ncriteria, including relevance, accuracy, and applicability, though gaps remain\nin areas such as completeness and clarity. The study underlines the importance\nof integrating human expertise with LLM technology and refining model\ndevelopment to address these limitations. By proposing a robust conceptual\nframework guiding the effective adoption of LLMs, this research aims to\ncontribute to a safer and more resilient cyber environment for Australian SMEs,\nenabling sustainable growth and competitiveness in the digital era.",
        "translated": "我们的生活和企业日益数字化，导致网络攻击的复杂性和频率也随之增加。中小型企业，尤其是澳大利亚的中小型企业，面对网络威胁的脆弱性正在增加，这对澳大利亚的网络安全形势构成了重大挑战。拥抱人工智能(AI)、机器学习(ML)和大语言模型(LLM)等变革性技术，可能会加强澳大利亚中小企业的网络安全政策。然而，它们的实际应用、优势和局限性仍然没有得到充分的探索，以前的研究主要集中在大公司。本研究旨在通过全面了解澳大利亚中小企业在加强网络安全政策方面的潜在作用，弥补这一差距。本研究采用混合研究方法设计，包括文献回顾、中小企业个案研究的定性分析、网络安全应用中 LLM 绩效指标的定量评估。研究结果强调了 LLM 在各种绩效标准(包括相关性、准确性和适用性)方面的潜力，尽管在完整性和清晰度等方面仍然存在差距。该研究强调了将人类专业知识与 LLM 技术相结合并精炼模型开发以解决这些局限性的重要性。本研究旨在透过建议一套稳健的概念框架，指导澳洲中小企业有效采用 LLM 模式，为澳洲中小企业缔造一个更安全及更具弹性的网络环境，促进数码时代的持续增长及竞争力。"
    },
    {
        "title": "Jammer classification with Federated Learning",
        "url": "http://arxiv.org/abs/2306.02587v1",
        "pub_date": "2023-06-05",
        "summary": "Jamming signals can jeopardize the operation of GNSS receivers until denying\nits operation. Given their ubiquity, jamming mitigation and localization\ntechniques are of crucial importance, for which jammer classification is of\nhelp. Data-driven models have been proven useful in detecting these threats,\nwhile their training using crowdsourced data still poses challenges when it\ncomes to private data sharing. This article investigates the use of federated\nlearning to train jamming signal classifiers locally on each device, with model\nupdates aggregated and averaged at the central server. This allows for\nprivacy-preserving training procedures that do not require centralized data\nstorage or access to client local data. The used framework FedAvg is assessed\non a dataset consisting of spectrogram images of simulated interfered GNSS\nsignal. Six different jammer types are effectively classified with comparable\nresults to a fully centralized solution that requires vast amounts of data\ncommunication and involves privacy-preserving concerns.",
        "translated": "干扰信号可以危及 GNSS 接收机的运行，直到拒绝其运行。鉴于干扰的普遍性，干扰抑制和定位技术具有非常重要的意义，干扰分类对此有着重要的帮助。事实证明，数据驱动模型在检测这些威胁方面非常有用，而使用众包数据的培训在私人数据共享方面仍然构成挑战。本文研究了使用联邦学习在每个设备上本地训练干扰信号分类器，在中央服务器上汇总和平均模型更新。这使得保护隐私的培训过程不需要集中的数据存储或访问客户端本地数据。所使用的框架 FedAvg 是在一个由模拟干扰 GNSS 信号的光谱图像组成的数据集上进行评估的。六种不同的干扰机类型被有效地分类，其结果与需要大量数据通信并涉及隐私保护问题的完全集中的解决方案相当。"
    },
    {
        "title": "Large-Scale Distributed Learning via Private On-Device\n  Locality-Sensitive Hashing",
        "url": "http://arxiv.org/abs/2306.02563v1",
        "pub_date": "2023-06-05",
        "summary": "Locality-sensitive hashing (LSH) based frameworks have been used efficiently\nto select weight vectors in a dense hidden layer with high cosine similarity to\nan input, enabling dynamic pruning. While this type of scheme has been shown to\nimprove computational training efficiency, existing algorithms require repeated\nrandomized projection of the full layer weight, which is impractical for\ncomputational- and memory-constrained devices. In a distributed setting,\ndeferring LSH analysis to a centralized host is (i) slow if the device cluster\nis large and (ii) requires access to input data which is forbidden in a\nfederated context. Using a new family of hash functions, we develop one of the\nfirst private, personalized, and memory-efficient on-device LSH frameworks. Our\nframework enables privacy and personalization by allowing each device to\ngenerate hash tables, without the help of a central host, using device-specific\nhashing hyper-parameters (e.g. number of hash tables or hash length). Hash\ntables are generated with a compressed set of the full weights, and can be\nserially generated and discarded if the process is memory-intensive. This\nallows devices to avoid maintaining (i) the fully-sized model and (ii) large\namounts of hash tables in local memory for LSH analysis. We prove several\nstatistical and sensitivity properties of our hash functions, and\nexperimentally demonstrate that our framework is competitive in training\nlarge-scale recommender networks compared to other LSH frameworks which assume\nunrestricted on-device capacity.",
        "translated": "基于局部性敏感哈希(lSH)的框架已被有效地用于选择密集隐藏层中的权重向量，该层对输入具有较高的余弦距离，从而实现了动态修剪。虽然这种类型的方案已被证明可以提高计算训练效率，但现有的算法需要重复随机投影的全层权重，这是不切实际的计算和内存约束的设备。在分布式设置中，如果设备集群很大，将 LSH 分析延迟到集中式主机会很慢，并且(ii)需要访问联邦上下文中禁止的输入数据。使用一个新的散列函数家族，我们开发了第一个私有的、个性化的、内存高效的设备上 LSH 框架。我们的框架允许每个设备在没有中央主机的帮助下，使用特定设备的哈希超参数(例如哈希表的数量或哈希长度)生成哈希表，从而实现了隐私和个性化。哈希表是用一组压缩的全权值生成的，如果进程占用大量内存，则可以连续生成和丢弃哈希表。这允许设备避免维护(i)完全大小的模型和(ii)本地内存中用于 LSH 分析的大量哈希表。我们证明了我们的哈希函数的一些统计和灵敏度特性，并且实验证明了我们的框架在训练大规模的推荐网络相比，其他 LSH 框架假设无限制的在设备上的能力是有竞争力的。"
    },
    {
        "title": "Interest-disclosing Mechanisms for Advertising are Privacy-Exposing (not\n  Preserving)",
        "url": "http://arxiv.org/abs/2306.03825v1",
        "pub_date": "2023-06-06",
        "summary": "Today, targeted online advertising relies on unique identifiers assigned to\nusers through third-party cookies--a practice at odds with user privacy. While\nthe web and advertising communities have proposed interest-disclosing\nmechanisms, including Google's Topics API, as solutions, an independent\nanalysis of these proposals in realistic scenarios has yet to be performed. In\nthis paper, we attempt to validate the privacy (i.e., preventing unique\nidentification) and utility (i.e., enabling ad targeting) claims of Google's\nTopics proposal in the context of realistic user behavior. Through new\nstatistical models of the distribution of user behaviors and resulting\ntargeting topics, we analyze the capabilities of malicious advertisers\nobserving users over time and colluding with other third parties. Our analysis\nshows that even in the best case, individual users' identification across sites\nis possible, as 0.4% of the 250k users we simulate are re-identified. These\nguarantees weaken further over time and when advertisers collude: 57% of users\nare uniquely re-identified after 15 weeks of browsing, increasing to 75% after\n30 weeks. While measuring that the Topics API provides moderate utility, we\nalso find that advertisers and publishers can abuse the Topics API to\npotentially assign unique identifiers to users, defeating the desired privacy\nguarantees. As a result, the inherent diversity of users' interests on the web\nis directly at odds with the privacy objectives of interest-disclosing\nmechanisms; we discuss how any replacement of third-party cookies may have to\nseek other avenues to achieve privacy for the web.",
        "translated": "今天，有针对性的在线广告依赖于通过第三方 cookie 分配给用户的唯一标识符——这种做法与用户隐私不符。虽然网络和广告社区已经提出了利益披露机制，包括谷歌的主题 API，作为解决方案，这些建议在现实情况下的独立分析尚未执行。在本文中，我们试图验证的隐私(即，防止唯一的识别)和实用程序(即，启用广告定位)的声明，谷歌的主题的建议在现实的用户行为的背景下。通过新的用户行为分布统计模型和由此产生的目标话题，我们分析了恶意广告商随时间观察用户和与其他第三方合谋的能力。我们的分析表明，即使在最好的情况下，个人用户的识别跨网站是可能的，因为0.4% 的25万用户我们模拟重新识别。随着时间的推移和广告商的串通，这些保证会进一步削弱: 57% 的用户在浏览15周后被唯一地重新识别，30周后增加到75% 。虽然测量主题 API 提供适度的实用性，我们也发现广告商和发布者可以滥用主题 API 来潜在地为用户分配唯一的标识符，破坏所需的隐私保障。因此，用户在网络上兴趣的内在多样性与利益披露机制的隐私目标直接相悖; 我们讨论任何第三方 cookie 的替代品可能必须寻找其他途径来实现网络的隐私。"
    },
    {
        "title": "A Novel Approach To User Agent String Parsing For Vulnerability Analysis\n  Using Mutli-Headed Attention",
        "url": "http://arxiv.org/abs/2306.03733v1",
        "pub_date": "2023-06-06",
        "summary": "The increasing reliance on the internet has led to the proliferation of a\ndiverse set of web-browsers and operating systems (OSs) capable of browsing the\nweb. User agent strings (UASs) are a component of web browsing that are\ntransmitted with every Hypertext Transfer Protocol (HTTP) request. They contain\ninformation about the client device and software, which is used by web servers\nfor various purposes such as content negotiation and security. However, due to\nthe proliferation of various browsers and devices, parsing UASs is a\nnon-trivial task due to a lack of standardization of UAS formats. Current\nrules-based approaches are often brittle and can fail when encountering such\nnon-standard formats. In this work, a novel methodology for parsing UASs using\nMulti-Headed Attention Based transformers is proposed. The proposed methodology\nexhibits strong performance in parsing a variety of UASs with differing\nformats. Furthermore, a framework to utilize parsed UASs to estimate the\nvulnerability scores for large sections of publicly visible IT networks or\nregions is also discussed. The methodology present here can also be easily\nextended or deployed for real-time parsing of logs in enterprise settings.",
        "translated": "对互联网的日益依赖导致了一系列不同的网络浏览器和操作系统(OS)能够浏览网页的激增。用户代理字符串(User agent string，UAS)是网页浏览的一个组成部分，每个超文本传输协议(HTTP)请求都会传输这些字符串。它们包含有关客户端设备和软件的信息，这些信息被 Web 服务器用于各种目的，例如内容协商和安全性。然而，由于各种浏览器和设备的普及，由于 UAS 格式缺乏标准化，解析 UAS 是一项非常重要的任务。当前基于规则的方法往往是脆弱的，在遇到这种非标准格式时可能会失败。提出了一种基于多头注意变换的无人机分析方法。提议的方法在解析不同格式的各种无人机系统方面表现出很强的性能。此外，还讨论了一个框架，利用已解析的 UAS 来估计大部分公开可见的 IT 网络或区域的脆弱性分数。这里提供的方法也可以很容易地扩展或部署，以便在企业设置中实时解析日志。"
    },
    {
        "title": "Exploring Model Dynamics for Accumulative Poisoning Discovery",
        "url": "http://arxiv.org/abs/2306.03726v1",
        "pub_date": "2023-06-06",
        "summary": "Adversarial poisoning attacks pose huge threats to various machine learning\napplications. Especially, the recent accumulative poisoning attacks show that\nit is possible to achieve irreparable harm on models via a sequence of\nimperceptible attacks followed by a trigger batch. Due to the limited\ndata-level discrepancy in real-time data streaming, current defensive methods\nare indiscriminate in handling the poison and clean samples. In this paper, we\ndive into the perspective of model dynamics and propose a novel information\nmeasure, namely, Memorization Discrepancy, to explore the defense via the\nmodel-level information. By implicitly transferring the changes in the data\nmanipulation to that in the model outputs, Memorization Discrepancy can\ndiscover the imperceptible poison samples based on their distinct dynamics from\nthe clean samples. We thoroughly explore its properties and propose\nDiscrepancy-aware Sample Correction (DSC) to defend against accumulative\npoisoning attacks. Extensive experiments comprehensively characterized\nMemorization Discrepancy and verified its effectiveness. The code is publicly\navailable at: https://github.com/tmlr-group/Memorization-Discrepancy.",
        "translated": "对抗性中毒攻击对各种机器学习应用构成了巨大的威胁。特别是，最近的累积中毒攻击表明，有可能通过一系列不易察觉的攻击，然后是触发批次，对模型造成不可弥补的伤害。由于实时数据流中有限的数据级别差异，当前的防御方法在处理毒物和干净样本时是不加区分的。本文从模型动力学的角度出发，提出了一种新的信息度量方法——记忆差异，通过模型层次的信息来探索防御策略。通过隐式地将数据操作中的变化传递给模型输出中的变化，记忆差异可以基于其与干净样本不同的动态发现不可察觉的有毒样本。我们深入探讨了它的性质，并提出了差异感知样本修正(DSC)来防范累积中毒攻击。广泛的实验全面描述了记忆差异，并验证了其有效性。该守则可于以下 https://github.com/tmlr-group/memorization-discrepancy 公开索取:。"
    },
    {
        "title": "Effective Intrusion Detection in Highly Imbalanced IoT Networks with\n  Lightweight S2CGAN-IDS",
        "url": "http://arxiv.org/abs/2306.03707v1",
        "pub_date": "2023-06-06",
        "summary": "Since the advent of the Internet of Things (IoT), exchanging vast amounts of\ninformation has increased the number of security threats in networks. As a\nresult, intrusion detection based on deep learning (DL) has been developed to\nachieve high throughput and high precision. Unlike general deep learning-based\nscenarios, IoT networks contain benign traffic far more than abnormal traffic,\nwith some rare attacks. However, most existing studies have been focused on\nsacrificing the detection rate of the majority class in order to improve the\ndetection rate of the minority class in class-imbalanced IoT networks. Although\nthis way can reduce the false negative rate of minority classes, it both wastes\nresources and reduces the credibility of the intrusion detection systems. To\naddress this issue, we propose a lightweight framework named S2CGAN-IDS. The\nproposed framework leverages the distribution characteristics of network\ntraffic to expand the number of minority categories in both data space and\nfeature space, resulting in a substantial increase in the detection rate of\nminority categories while simultaneously ensuring the detection precision of\nmajority categories. To reduce the impact of sparsity on the experiments, the\nCICIDS2017 numeric dataset is utilized to demonstrate the effectiveness of the\nproposed method. The experimental results indicate that our proposed approach\noutperforms the superior method in both Precision and Recall, particularly with\na 10.2% improvement in the F1-score.",
        "translated": "自从物联网(IoT)出现以来，大量的信息交换增加了网络安全威胁的数量。因此，基于深度学习(DL)的入侵检测技术得到了发展，以实现高吞吐量和高精度的入侵检测。与一般的基于深度学习的场景不同，物联网包含的良性流量远远多于异常流量，还有一些罕见的攻击。然而，为了提高类不平衡物联网中少数类的检测率，现有的研究大多集中在牺牲多数类的检测率上。虽然这种方法可以降低少数类的假阴性率，但是它不仅浪费资源，而且降低了入侵检测系统的可信度。为了解决这个问题，我们提出了一个轻量级框架 S2CGAN-IDS。拟议框架利用网络流量的分布特点，扩大了数据空间和特征空间中少数群体类别的数量，从而大幅度提高了少数群体类别的检测率，同时确保了多数群体类别的检测精度。为了减少稀疏性对实验的影响，利用 CICIDS2017数值数据集验证了该方法的有效性。实验结果表明，我们提出的方法在两个准确率召回率都优于优秀的方法，特别是在 f1分数提高了10.2% 的情况下。"
    },
    {
        "title": "Human-imperceptible, Machine-recognizable Images",
        "url": "http://arxiv.org/abs/2306.03679v1",
        "pub_date": "2023-06-06",
        "summary": "Massive human-related data is collected to train neural networks for computer\nvision tasks. A major conflict is exposed relating to software engineers\nbetween better developing AI systems and distancing from the sensitive training\ndata. To reconcile this conflict, this paper proposes an efficient\nprivacy-preserving learning paradigm, where images are first encrypted to\nbecome ``human-imperceptible, machine-recognizable'' via one of the two\nencryption strategies: (1) random shuffling to a set of equally-sized patches\nand (2) mixing-up sub-patches of the images. Then, minimal adaptations are made\nto vision transformer to enable it to learn on the encrypted images for vision\ntasks, including image classification and object detection. Extensive\nexperiments on ImageNet and COCO show that the proposed paradigm achieves\ncomparable accuracy with the competitive methods. Decrypting the encrypted\nimages requires solving an NP-hard jigsaw puzzle or an ill-posed inverse\nproblem, which is empirically shown intractable to be recovered by various\nattackers, including the powerful vision transformer-based attacker. We thus\nshow that the proposed paradigm can ensure the encrypted images have become\nhuman-imperceptible while preserving machine-recognizable information. The code\nis available at \\url{https://github.com/FushengHao/PrivacyPreservingML.}",
        "translated": "大量的人类相关数据被收集来训练计算机视觉任务的神经网络。软件工程师在更好地开发人工智能系统和远离敏感的培训数据之间暴露出一个重大的冲突。为了调和这种冲突，本文提出了一种有效的保护隐私的学习范式，首先通过两种加密策略中的一种将图像加密成“人类感知不到的，机器可识别的”: (1)随机移动到一组大小相等的补丁和(2)混合图像的子补丁。然后，对视觉转换器进行最小限度的适应，使其能够在加密图像上学习视觉任务，包括图像分类和目标检测。在 ImageNet 和 COCO 上的大量实验表明，本文提出的方法与竞争方法具有可比的精度。加密图像的解密需要解决一个 NP 难题或一个病态逆问题，经验表明，这是难以恢复的各种攻击者，包括强大的视觉变压器为基础的攻击者。结果表明，该算法能够在保留机器可识别信息的同时，保证加密后的图像不被人类察觉。该代码可在 url { https://github.com/fushenghao/privacypreservingml 获得。}"
    },
    {
        "title": "TALUS: Reinforcing TEE Confidentiality with Cryptographic Coprocessors\n  (Technical Report)",
        "url": "http://arxiv.org/abs/2306.03643v1",
        "pub_date": "2023-06-06",
        "summary": "Platforms are nowadays typically equipped with tristed execution environments\n(TEES), such as Intel SGX and ARM TrustZone. However, recent microarchitectural\nattacks on TEEs repeatedly broke their confidentiality guarantees, including\nthe leakage of long-term cryptographic secrets. These systems are typically\nalso equipped with a cryptographic coprocessor, such as a TPM or Google Titan.\nThese coprocessors offer a unique set of security features focused on\nsafeguarding cryptographic secrets. Still, despite their simultaneous\navailability, the integration between these technologies is practically\nnonexistent, which prevents them from benefitting from each other's strengths.\nIn this paper, we propose TALUS, a general design and a set of three main\nrequirements for a secure symbiosis between TEEs and cryptographic\ncoprocessors. We implement a proof-of-concept of TALUS based on Intel SGX and a\nhardware TPM. We show that with TALUS, the long-term secrets used in the SGX\nlife cycle can be moved to the TPM. We demonstrate that our design is robust\neven in the presence of transient execution attacks, preventing an entire class\nof attacks due to the reduced attack surface on the shared hardware.",
        "translated": "现在的平台通常都配备了三级执行环境(TEES) ，比如 Intel SGX 和 ARM TrustZone。然而，最近对 TEE 的微架构攻击屡次打破了它们的保密保障，包括泄露长期的加密机密。这些系统通常还配备了加密协处理器，如 TPM 或 Google Titan。这些协处理器提供了一组独特的安全特性，专注于保护加密秘密。然而，尽管它们同时可用，但这些技术之间的集成实际上是不存在的，这使它们无法从彼此的优势中受益。在本文中，我们提出 TALUS，一个通用的设计和一组三个主要要求的安全共生之间的 TEE 和密码协处理器。我们实现了一个基于 Intel SGX 和硬件 TPM 的 TALUS 概念验证。我们展示了使用 TALUS，在新交所生命周期中使用的长期秘密可以移动到 TPM。我们证明了我们的设计即使在存在瞬态执行攻击的情况下也是健壮的，可以防止由于共享硬件上的攻击面减少而导致的整个类别的攻击。"
    },
    {
        "title": "mdTLS: How to Make middlebox-aware TLS more efficient?",
        "url": "http://arxiv.org/abs/2306.03573v1",
        "pub_date": "2023-06-06",
        "summary": "The more data transmission over TLS protocol becomes increasingly common in\nIT Systems, the more middleboxes are deployed in networks. These middleboxes\nhave several advantages, however, they become the target of cyber-attacks. Many\nresearchers proposed revised versions of TLS protocols to make them secure,\nhowever, their approaches had some limitations. In this paper, we propose a\nmiddlebox-delegated TLS (mdTLS) protocol to improve performance based on the\nmiddlebox-aware TLS (maTLS), one of the most secure TLS protocols. We found out\nthat the computational complexity of mdTLS is about twice as low as that of\nmaTLS. Furthermore, we formally verified that our proposal meets newly defined\nsecurity goals as well as those verified by maTLS. All of the formal models and\nlemmas are open to the public through following url\nhttps://github.com/HackProof/mdTLS.",
        "translated": "在 IT 系统中，TLS 协议的数据传输越多，网络中部署的中间盒就越多。这些中间盒有几个优点，然而，他们成为网络攻击的目标。许多研究人员提出了 TLS 协议的修订版本，以使它们更加安全，然而，他们的方法有一些局限性。本文基于最安全的 TLS 协议之一——中间盒感知 TLS (maTLS) ，提出了一种中间盒委托 TLS (mdTLS)协议来提高性能。我们发现 mdTLS 的计算复杂度大约是 maTLS 的两倍。此外，我们正式验证了我们的提案满足新定义的安全目标以及那些由 maTLS 验证的目标。所有的正式模型和引理都是通过下面的 url  https://github.com/hackproof/mdtls 向公众开放的。"
    },
    {
        "title": "Machine Unlearning: A Survey",
        "url": "http://arxiv.org/abs/2306.03558v1",
        "pub_date": "2023-06-06",
        "summary": "Machine learning has attracted widespread attention and evolved into an\nenabling technology for a wide range of highly successful applications, such as\nintelligent computer vision, speech recognition, medical diagnosis, and more.\nYet a special need has arisen where, due to privacy, usability, and/or the\nright to be forgotten, information about some specific samples needs to be\nremoved from a model, called machine unlearning. This emerging technology has\ndrawn significant interest from both academics and industry due to its\ninnovation and practicality. At the same time, this ambitious problem has led\nto numerous research efforts aimed at confronting its challenges. To the best\nof our knowledge, no study has analyzed this complex topic or compared the\nfeasibility of existing unlearning solutions in different kinds of scenarios.\nAccordingly, with this survey, we aim to capture the key concepts of unlearning\ntechniques. The existing solutions are classified and summarized based on their\ncharacteristics within an up-to-date and comprehensive review of each\ncategory's advantages and limitations. The survey concludes by highlighting\nsome of the outstanding issues with unlearning techniques, along with some\nfeasible directions for new research opportunities.",
        "translated": "机器学习已经引起了人们的广泛关注，并逐渐发展成为一种能够应用于各种非常成功的应用领域的技术，例如智能计算机视觉、语音识别、医疗诊断等等。然而，由于隐私、可用性和/或被遗忘的权利，一种特殊的需求已经出现，关于某些特定样本的信息需要从一个模型中删除，这种模型称为机器去学习。这种新兴技术因其创新性和实用性而引起了学术界和工业界的极大兴趣。与此同时，这个雄心勃勃的问题已经导致了许多旨在应对其挑战的研究工作。据我们所知，还没有研究分析过这个复杂的主题，也没有比较过现有的不学习解决方案在不同情景下的可行性。因此，通过这个调查，我们的目标是捕捉忘记技术的关键概念。现有的解决方案根据其特点进行了分类和总结，并对每个类别的优点和局限性进行了最新和全面的审查。该调查最后强调了一些突出的问题与忘却技术，以及一些新的研究机会的可行方向。"
    },
    {
        "title": "A Practical Framework for Storing and Searching Encrypted Data on Cloud\n  Storage",
        "url": "http://arxiv.org/abs/2306.03547v1",
        "pub_date": "2023-06-06",
        "summary": "Security has become a significant concern with the increased popularity of\ncloud storage services. It comes with the vulnerability of being accessed by\nthird parties. Security is one of the major hurdles in the cloud server for the\nuser when the user data that reside in local storage is outsourced to the\ncloud. It has given rise to security concerns involved in data confidentiality\neven after the deletion of data from cloud storage. Though, it raises a serious\nproblem when the encrypted data needs to be shared with more people than the\ndata owner initially designated. However, searching on encrypted data is a\nfundamental issue in cloud storage. The method of searching over encrypted data\nrepresents a significant challenge in the cloud.\n  Searchable encryption allows a cloud server to conduct a search over\nencrypted data on behalf of the data users without learning the underlying\nplaintexts. While many academic SE schemes show provable security, they usually\nexpose some query information, making them less practical, weak in usability,\nand challenging to deploy. Also, sharing encrypted data with other authorized\nusers must provide each document's secret key. However, this way has many\nlimitations due to the difficulty of key management and distribution.\n  We have designed the system using the existing cryptographic approaches,\nensuring the search on encrypted data over the cloud. The primary focus of our\nproposed model is to ensure user privacy and security through a less\ncomputationally intensive, user-friendly system with a trusted third party\nentity. To demonstrate our proposed model, we have implemented a web\napplication called CryptoSearch as an overlay system on top of a well-known\ncloud storage domain. It exhibits secure search on encrypted data with no\ncompromise to the user-friendliness and the scheme's functional performance in\nreal-world applications.",
        "translated": "随着云存储服务的日益普及，安全性已经成为一个重要的问题。它伴随着被第三方访问的脆弱性。当驻留在本地存储中的用户数据被外包到云服务器时，安全性是用户在云服务器中面临的主要障碍之一。即使在从云存储中删除数据之后，这也引起了与数据保密有关的安全问题。尽管如此，当需要与比数据所有者最初指定的更多的人共享加密数据时，它会引起一个严重的问题。然而，对加密数据的搜索是云存储中的一个基本问题。搜索加密数据的方法是云中的一个重大挑战。可搜索加密允许云服务器代表数据用户对加密数据进行搜索，而无需了解底层明文。虽然许多学术 SE 方案表现出可证明的安全性，但是它们通常会暴露一些查询信息，使得它们不太实用、易用性差、部署困难。此外，与其他授权用户共享加密数据必须提供每个文档的密钥。然而，由于密钥管理和分配的困难，这种方法有很多局限性。我们使用现有的加密方法设计了系统，确保在云上搜索加密数据。我们提出的模型的主要重点是通过一个计算密集度较低、用户友好的系统和一个可信的第三方实体来确保用户的隐私和安全。为了演示我们提出的模型，我们在一个著名的云存储域上实现了一个名为 CryptoSearch 的 Web 应用程序作为覆盖系统。该方案对加密数据进行安全搜索，不影响用户友好性和实际应用中的性能。"
    },
    {
        "title": "Greedy-Mine: A Profitable Mining Attack Strategy in Bitcoin-NG",
        "url": "http://arxiv.org/abs/2306.03540v1",
        "pub_date": "2023-06-06",
        "summary": "Bitcoin-NG is an extensible blockchain protocol based on the same trust model\nas Bitcoin. It divides each epoch into one Key-Block and multiple Micro-Blocks,\neffectively improving transaction processing capacity. Bitcoin-NG adopts a\nspecial incentive mechanism (i.e., the transaction fees in each epoch are split\nto the current and next leader) to maintain its security. However, there are\nsome limitations to the existing incentive analysis of Bitcoin-NG in recent\nworks. First, the incentive division method of Bitcoin-NG only includes some\nspecific mining attack strategies of adversary, while ignoring more stubborn\nattack strategies. Second, once adversaries find a whale transaction, they will\ndeviate from honest mining strategy to obtain extra reward. In this paper, we\nare committed to solving these two limitations. First, we propose a novel\nmining strategy named Greedy-Mine attack. Then, we formulate a Markov Decision\nProcess (MDP) model to analyze the competition of honest miners and\nadversaries. Furthermore, we analysis the extra reward of adversaries and\nsummarize the mining power proportion range required for malicious adversaries\nto launch Greedy-Mine to obtain extra returns. Finally, we make a\nbackward-compatibility progressive modification to Bitcoin-NG protocol that\nwould raise the threshold of propagation factor from 0 to 1. Meanwhile, we get\nthe winning condition of adversaries when adopting Greedy-Mine, compared with\nhonest mining. Simulation and experimental results indicate that Bitcoin-NG is\nnot incentive compatible, which is vulnerable to Greedy-Mine attack.",
        "translated": "比特币 -NG 是一个可扩展的区块链协议，它基于与比特币相同的信任模型。它将每个时代划分为一个关键块和多个微块，有效地提高了事务处理能力。比特币 -NG 采用了一种特殊的激励机制(即每个时代的交易费用分摊给当前和下一个领导者)来维持其安全性。然而，现有的比特币 -NG 激励分析在近期的研究中存在一定的局限性。首先，比特币 -NG 的激励划分方法只包括一些特定的挖掘攻击策略，而忽略了较为顽固的攻击策略。其次，一旦对手发现了鲸鱼的交易，他们就会偏离诚实的采矿策略来获得额外的报酬。在本文中，我们致力于解决这两个局限性。首先，本文提出了一种新的挖掘策略——贪婪-地雷攻击。然后，我们制定了一个马可夫决策过程模型来分析诚实的矿工和对手之间的竞争。此外，本文还分析了对手的额外报酬，总结了恶意对手为获得额外报酬而发射贪婪矿井所需的采矿权比例范围。最后，对比特币 -NG 协议进行了向后兼容的渐进修改，将传播因子的阈值从0提高到1。同时，通过与诚实采矿法的比较，得出了采用贪婪采矿法时对手的获胜条件。仿真和实验结果表明，比特币-NG 不具备激励兼容性，容易受到 Greedy-Mine 攻击。"
    },
    {
        "title": "On the Reliability of Watermarks for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04634v1",
        "pub_date": "2023-06-07",
        "summary": "Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.",
        "translated": "大型语言模型(LLM)现在被部署到日常使用中，并定位于在未来十年生成大量文本。机器生成的文本可能取代互联网上人写的文本，并有可能被用于恶意目的，如鱼叉式钓鱼攻击和社交媒体机器人。水印是一种简单而有效的策略，通过检测和记录 LLM 生成的文本来减轻这种危害。然而，一个关键的问题仍然存在: 在野外的现实环境中，水印的可靠性如何？在那里，水印文本可能与其他文本来源混合，由人类作家或其他语言模型转述，并用于广泛的领域中的应用，包括社会和技术。在本文中，我们探讨了不同的检测方案，量化它们在检测水印方面的能力，并确定在每个场景中需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调我们的人类研究，我们调查的可靠性水印时，面对人类释义。我们比较了基于水印的检测和其他检测策略，发现水印是一个可靠的解决方案，特别是因为它的样本复杂性-对于所有的攻击，我们考虑，水印证据复合越多的例子，并最终检测水印。"
    },
    {
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations",
        "url": "http://arxiv.org/abs/2306.04618v1",
        "pub_date": "2023-06-07",
        "summary": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
        "translated": "本文重新审视了自然语言处理领域中分布外(OOD)鲁棒性的研究。我们发现在以往的研究中，分布移位设置通常缺乏足够的挑战，阻碍了面向对象的鲁棒性的准确评估。为了解决这些问题，我们提出了一个基准建设协议，以确保明确的差异和挑战性的分配转移。然后我们介绍了 BOSS，一个用于分布外鲁棒性评估的基准套件，包括5个任务和20个数据集。基于 BOSS 系统，我们对预训练语言模型进行了一系列的实验，用于分析和评估面向对象的鲁棒性。首先，对于普通的微调，我们研究分发内(ID)和 OOD 性能之间的关系。我们确定了三种典型的类型，揭示了内部学习机制，这可能有助于面向对象的鲁棒性预测，与 ID 数据集的进步相关。然后，我们对 BOSS 上的5种经典方法进行了评估，发现尽管它们在特定情况下显示出一些有效性，但与普通的微调相比，它们并没有提供显著的改进。此外，我们评估了5个具有不同适应范例的 LLM，发现当有足够的 ID 数据可用时，针对特定领域的微调模型在 ID 示例上的表现明显优于 LLM。但是，在面向对象的实例中，使用上下文内学习对 LLM 进行优先排序会产生更好的结果。我们发现，微调小型模型和 LLM 在有效处理下游任务方面都面临挑战。该代码在 url { https://github.com/lifan-yuan/ood_nlp }是公共的。"
    },
    {
        "title": "Prefix Siphoning: Exploiting LSM-Tree Range Filters For Information\n  Disclosure (Full Version)",
        "url": "http://arxiv.org/abs/2306.04602v1",
        "pub_date": "2023-06-07",
        "summary": "Key-value stores typically leave access control to the systems for which they\nact as storage engines. Unfortunately, attackers may circumvent such read\naccess controls via timing attacks on the key-value store, which use\ndifferences in query response times to glean information about stored data.\n  To date, key-value store timing attacks have aimed to disclose stored values\nand have exploited external mechanisms that can be disabled for protection. In\nthis paper, we point out that key disclosure is also a security threat -- and\ndemonstrate key disclosure timing attacks that exploit mechanisms of the\nkey-value store itself.\n  We target LSM-tree based key-value stores utilizing range filters, which have\nbeen recently proposed to optimize LSM-tree range queries. We analyze the\nimpact of the range filters SuRF and prefix Bloom filter on LSM-trees through a\nsecurity lens, and show that they enable a key disclosure timing attack, which\nwe call prefix siphoning. Prefix siphoning successfully leverages benign\nqueries for non-present keys to identify prefixes of actual keys -- and in some\ncases, full keys -- in scenarios where brute force searching for keys (via\nexhaustive enumeration or random guesses) is infeasible.",
        "translated": "键值存储通常将访问控制留给它们作为存储引擎的系统。不幸的是，攻击者可能通过对键值存储的定时攻击来规避这种读访问控制，这种攻击使用查询响应时间的差异来收集有关存储数据的信息。到目前为止，键值存储定时攻击的目的是披露存储值，并利用可以禁用的外部机制进行保护。在本文中，我们指出密钥公开也是一种安全威胁——并论证了利用密钥价值存储本身机制的密钥公开时间攻击。我们利用最近提出的用于优化 LSM 树范围查询的范围过滤器来实现基于 LSM 树的键值存储。我们通过安全透镜分析了距离滤波器 SuRF 和前缀 Bloom 滤波器对 LSM 树的影响，并指出它们能够实现一种密钥泄露定时攻击，我们称之为前缀虹吸。前缀虹吸成功地利用对非存在键的良性查询来识别实际键的前缀——在某些情况下，识别全键——在强制搜索键(通过穷举或随机猜测)是不可行的情况下。"
    },
    {
        "title": "The Effect of Length on Key Fingerprint Verification Security and\n  Usability",
        "url": "http://arxiv.org/abs/2306.04574v1",
        "pub_date": "2023-06-07",
        "summary": "In applications such as end-to-end encrypted instant messaging, secure email,\nand device pairing, users need to compare key fingerprints to detect\nimpersonation and adversary-in-the-middle attacks. Key fingerprints are usually\ncomputed as truncated hashes of each party's view of the channel keys, encoded\nas an alphanumeric or numeric string, and compared out-of-band, e.g. manually,\nto detect any inconsistencies. Previous work has extensively studied the\nusability of various verification strategies and encoding formats, however, the\nexact effect of key fingerprint length on the security and usability of key\nfingerprint verification has not been rigorously investigated. We present a\n162-participant study on the effect of numeric key fingerprint length on\ncomparison time and error rate. While the results confirm some widely-held\nintuitions such as general comparison times and errors increasing significantly\nwith length, a closer look reveals interesting nuances. The significant rise in\ncomparison time only occurs when highly similar fingerprints are compared, and\ncomparison time remains relatively constant otherwise. On errors, our results\nclearly distinguish between security non-critical errors that remain low\nirrespective of length and security critical errors that significantly rise,\nespecially at higher fingerprint lengths. A noteworthy implication of this\nlatter result is that Signal/WhatsApp key fingerprints provide a considerably\nlower level of security than usually assumed.",
        "translated": "在端到端加密即时通讯、安全电子邮件和设备配对等应用程序中，用户需要比较密钥指纹来检测模仿和中间对手攻击。密钥指纹通常计算为各方频道密钥视图的截断哈希，编码为字母数字或数字字符串，并进行带外比较，例如手动比较，以检测任何不一致之处。以往的工作已经广泛地研究了各种验证策略和编码格式的可用性，但是，密钥指纹长度对密钥指纹验证的安全性和可用性的确切影响还没有得到严格的研究。我们提出了一个162人参与的研究数字键指纹长度对比较时间和错误率的影响。虽然研究结果证实了一些普遍接受的直觉，比如一般的比较时间和误差随着长度的增加而显著增加，但仔细观察就会发现有趣的细微差别。只有当高度相似的指纹进行比较时，比较时间才会显著增加，否则比较时间保持相对恒定。在错误方面，我们的结果清楚地区分了无论长度如何都保持较低的安全性非关键性错误和显著上升的安全性关键性错误，特别是在指纹长度较高的情况下。后一种结果的一个值得注意的含义是，Signal/WhatsApp 密钥指纹提供了比通常假设的低得多的安全级别。"
    },
    {
        "title": "Differentially Private Selection from Secure Distributed Computing",
        "url": "http://arxiv.org/abs/2306.04564v2",
        "pub_date": "2023-06-07",
        "summary": "Given a collection of vectors $x^{(1)},\\dots,x^{(n)} \\in \\{0,1\\}^d$, the\nselection problem asks to report the index of an \"approximately largest\" entry\nin $x=\\sum_{j=1}^n x^{(j)}$. Selection abstracts a host of problems--in machine\nlearning it can be used for hyperparameter tuning, feature selection, or to\nmodel empirical risk minimization. We study selection under differential\nprivacy, where a released index guarantees privacy for each vectors. Though\nselection can be solved with an excellent utility guarantee in the central\nmodel of differential privacy, the distributed setting lacks solutions.\nSpecifically, strong privacy guarantees with high utility are offered in high\ntrust settings, but not in low trust settings. For example, in the popular\nshuffle model of distributed differential privacy, there are strong lower\nbounds suggesting that the utility of the central model cannot be obtained. In\nthis paper we design a protocol for differentially private selection in a trust\nsetting similar to the shuffle model--with the crucial difference that our\nprotocol tolerates corrupted servers while maintaining privacy. Our protocol\nuses techniques from secure multi-party computation (MPC) to implement a\nprotocol that: (i) has utility on par with the best mechanisms in the central\nmodel, (ii) scales to large, distributed collections of high-dimensional\nvectors, and (iii) uses $k\\geq 3$ servers that collaborate to compute the\nresult, where the differential privacy holds assuming an honest majority. Since\ngeneral-purpose MPC techniques are not sufficiently scalable, we propose a\nnovel application of integer secret sharing, and evaluate the utility and\nefficiency of our protocol theoretically and empirically. Our protocol is the\nfirst to demonstrate that large-scale differentially private selection is\npossible in a distributed setting.",
        "translated": "给定{0,1} ^ d $中的向量 $x ^ {(1)} ，点，x ^ {(n)}的集合，选择问题要求报告 $x = sum _ { j = 1} ^ n x ^ {(j)} $中“近似最大”条目的索引。选择抽象出许多问题——在机器学习中，它可以用于超参数调整、特征选择或经验风险最小化建模。我们研究差分隐私下的选择，其中发布的索引保证每个向量的隐私。尽管在中心差分隐私模型中，选择可以通过极好的效用保证得到解决，但分布式设置缺乏解决方案。具体来说，在高信任设置中提供具有高效用的强隐私保护，但在低信任设置中不提供这种保护。例如，在流行的分布式差分隐私的洗牌模型中，有很强的下限，表明不能获得中央模型的效用。在本文中，我们设计了一个类似于 shuffle 模型的信任设置中的差异私有选择协议，其关键区别在于我们的协议能够容忍被破坏的服务器，同时保持私有性。我们的协议使用来自安全多方计算(mPC)的技术来实现一个协议: (i)与中央模型中最好的机制具有同等效用，(ii)扩展到高维向量的大型分布式集合，以及(iii)使用合作计算结果的 $k geq 3 $服务器，其中差分隐私持有假定的诚实多数。由于通用的 MPC 技术不具有足够的可扩展性，本文提出了一种新的整数秘密共享应用，并从理论和经验上对该协议的效用和效率进行了评估。我们的协议首次证明了在分布式环境中可以进行大规模的差异私有选择。"
    },
    {
        "title": "Vulnerable Smart Contract Function Locating Based on Multi-Relational\n  Nested Graph Convolutional Network",
        "url": "http://arxiv.org/abs/2306.04479v1",
        "pub_date": "2023-06-07",
        "summary": "The immutable and trustable characteristics of blockchain enable smart\ncontracts to be applied in various fields. Unfortunately, smart contracts are\nsubject to various vulnerabilities, which are frequently exploited by\nattackers, causing financial damage to users.In this paper, we study the\nproblem of vulnerable smart contract function locating. We construct a novel\nMulti-Relational Nested contract Graph (MRNG) to better characterize the rich\nsyntactic and semantic information in the smart contract code, including the\nrelationships between data and instructions. An MRNG represents a smart\ncontract, where each node represents a function in the smart contract and each\nedge describes the calling relationship between the functions. In addition, we\ncreate a Multi-Relational Function Graph (MRFG) for each function, which\ncharacterizes the corresponding function code. That is, each function is\ncharacterized as an MRFG, which corresponds to a node in the MRNG. Each MRFG\nuses different types of edges to represent the different control and data\nrelationships between nodes within a function. We also propose a\nMulti-Relational Nested Graph Convolutional Network (MRN-GCN) to process the\nMRNG. MRN-GCN first extracts and aggregates features from each MRFG, using the\nedge-enhanced graph convolution network and self-attention mechanism. The\nextracted feature vector is then assigned to the corresponding node in the MRNG\nto obtain a new Featured Contract Graph (FCG) for the smart contract. Graph\nconvolution is used to further extract features from the FCG. Finally, a feed\nforward network with a Sigmoid function is used to locate the vulnerable\nfunctions. Experimental results on the real-world smart contract datasets show\nthat model MRN-GCN can effectively improve the accuracy, precision, recall and\nF1-score performance of vulnerable smart contract function locating.",
        "translated": "区块链的不可变性和可信性使得智能契约能够应用于各个领域。不幸的是，智能合同容易受到各种漏洞的攻击，这些漏洞经常被攻击者利用，给用户造成经济损失。为了更好地描述智能契约代码中丰富的语法和语义信息，包括数据和指令之间的关系，我们构建了一个新颖的多关系嵌套契约图(Multi-Relational Nested ContractGraph，MRNG)。MRNG 表示智能契约，其中每个节点表示智能契约中的一个函数，每个边描述函数之间的调用关系。此外，我们为每个函数创建一个多关系函数图(MRFG) ，它描述了相应的函数代码。也就是说，每个函数都被描述为一个 MRFG，它对应于 MRNG 中的一个节点。每个 MRFG 使用不同类型的边来表示函数中节点之间不同的控制和数据关系。我们还提出了一个多关系嵌套图卷积网络(MRN-GCN)来处理 MRNG。GCN 首先利用边增强的图卷积网络和自注意机制从每个 MRFG 中提取和聚集特征。然后将提取的特征向量分配给 MRNG 中的相应节点，得到新的特征契约图(FCG)。图卷积用于进一步从 FCG 中提取特征。最后，使用一个带有 S形函数的前馈网络来定位易受攻击的功能。实验结果表明，MRN-GCN 模型能够有效地提高脆弱智能契约功能定位的准确性、精度、召回率和 F1分数性能。"
    },
    {
        "title": "Hardening and Speeding Up Zero-interaction Pairing and Authentication",
        "url": "http://arxiv.org/abs/2306.04458v1",
        "pub_date": "2023-06-07",
        "summary": "Establishing and maintaining secure communications in the Internet of Things\n(IoT) is vital to protect smart devices. Zero-interaction pairing (ZIP) and\nzero-interaction authentication (ZIA) enable IoT devices to establish and\nmaintain secure communications without user interaction by utilizing devices'\nambient context, e.g., audio. For autonomous operation, ZIP and ZIA require the\ncontext to have enough entropy to resist attacks and complete in a timely\nmanner. Despite the low-entropy context being the norm, like inside an\nunoccupied room, the research community has yet to come up with ZIP and ZIA\nschemes operating under such conditions. We propose HARDZIPA, a novel approach\nthat turns commodity IoT actuators into injecting devices, generating\nhigh-entropy context. Here, we combine the capability of IoT actuators to\nimpact the environment, e.g., emitting a sound, with a pseudorandom number\ngenerator (PRNG) featured by many actuators to craft hard-to-predict context\nstimuli. To demonstrate the feasibility of HARDZIPA, we implement it on\noff-the-shelf IoT actuators, i.e., smart speakers, lights, and humidifiers. We\ncomprehensively evaluate HARDZIPA, collecting over 80 hours of various context\ndata in real-world scenarios. Our results show that HARDZIPA is able to thwart\nadvanced active attacks on ZIP and ZIA schemes, while doubling the amount of\ncontext entropy in many cases, which allows two times faster pairing and\nauthentication.",
        "translated": "在物联网(IoT)中建立和维护安全通信对于保护智能设备至关重要。零交互配对(ZIP)和零交互认证(ZIA)使物联网设备能够在没有用户交互的情况下，通过利用设备的环境上下文(如音频)建立和维护安全通信。对于自主操作，ZIP 和 ZIA 需要上下文具有足够的熵来抵抗攻击并及时完成。尽管低熵环境是常态，就像在一个空房间里一样，研究团体还没有提出 ZIP 和 ZIA 方案在这样的条件下运作。我们提出了 HARDZIPA，一种新的方法，将商品物联网执行器注入设备，产生高熵上下文。在这里，我们结合了物联网执行器的能力，以影响环境，例如，发出声音，一个伪随机数生成器(PRNG)的特点，许多执行器制造难以预测的背景刺激。为了证明 HARDZIPA 的可行性，我们在现成的物联网执行器上实现了它，例如，智能扬声器、灯和加湿器。我们全面评估 HARDZIPA，收集超过80个小时的各种上下文数据在现实世界的情景。我们的研究结果表明，HARDZIPA 能够阻止针对 ZIP 和 ZIA 方案的高级主动攻击，同时在许多情况下使上下文熵增加一倍，这使得配对和认证速度提高了两倍。"
    },
    {
        "title": "Fast Optimal Locally Private Mean Estimation via Random Projections",
        "url": "http://arxiv.org/abs/2306.04444v1",
        "pub_date": "2023-06-07",
        "summary": "We study the problem of locally private mean estimation of high-dimensional\nvectors in the Euclidean ball. Existing algorithms for this problem either\nincur sub-optimal error or have high communication and/or run-time complexity.\nWe propose a new algorithmic framework, ProjUnit, for private mean estimation\nthat yields algorithms that are computationally efficient, have low\ncommunication complexity, and incur optimal error up to a $1+o(1)$-factor. Our\nframework is deceptively simple: each randomizer projects its input to a random\nlow-dimensional subspace, normalizes the result, and then runs an optimal\nalgorithm such as PrivUnitG in the lower-dimensional space. In addition, we\nshow that, by appropriately correlating the random projection matrices across\ndevices, we can achieve fast server run-time. We mathematically analyze the\nerror of the algorithm in terms of properties of the random projections, and\nstudy two instantiations. Lastly, our experiments for private mean estimation\nand private federated learning demonstrate that our algorithms empirically\nobtain nearly the same utility as optimal ones while having significantly lower\ncommunication and computational cost.",
        "translated": "研究了欧氏球中高维向量的局部私有均值估计问题。针对这个问题的现有算法要么会产生次优误差，要么具有较高的通信和/或运行时复杂度。我们提出了一个新的算法框架，ProjUnit，用于私有均值估计，它产生的算法计算效率高，通信复杂度低，并产生最优误差高达 $1 + o (1) $因子。我们的框架看似简单: 每个随机发生器将其输入投射到一个随机的低维子空间，规范化结果，然后在低维空间运行一个最优算法，如 PrivUnitG。此外，我们表明，通过适当关联跨设备的随机投影矩阵，我们可以实现快速的服务器运行时。我们利用随机投影的性质对算法的误差进行了数学分析，并研究了两个实例。最后，我们对私有均值估计和私有联邦学习的实验表明，我们的算法在经验上获得了与最优算法几乎相同的效用，同时具有明显较低的通信和计算成本。"
    },
    {
        "title": "Security Analysis of WG-7 Lightweight Stream Cipher against Cube Attack",
        "url": "http://arxiv.org/abs/2306.04352v1",
        "pub_date": "2023-06-07",
        "summary": "Welch--Gong (WG) is a hardware-oriented LFSR-based stream cipher. WG-7 is a\nversion of the eStream submission Welch--Gong, used for RFID encryption and\nauthentication purposes. It offers 80-bit cryptographic security. In modern\ndays, almost all ciphers achieve the security by exploiting the nonlinear\nfeedback structure. In this paper, we investigate the security of the nonlinear\nfeedback-based initialization phase of the WG-7 stream cipher using the\nconventional bit-based division property of cube attack, by considering the\ncipher in a non-blackbox polynomial setting. In our work, we mount the cube\nattack using mixed-integer-linear-programming(MILP) models. The results of our\nattack enable us to recover the secret key of WG-7 after 20 rounds of\ninitialization utilizing $2^{10}$ keystream bits in $2^{73}$ time. We show that\nour proposed attack takes significantly lower data complexity. To the best of\nour knowledge, our attack is the first one that investigates the security of\nthe nonlinear feedback-based initialization phase of WG-7 cipher.",
        "translated": "WG 是一种面向硬件的基于 LFSR 的流密码。WG-7是 eStream 提交的韦尔奇——龚的一个版本，用于 RFID 加密和认证目的。它提供80位加密安全性。在现代，几乎所有的密码都是通过利用非线性反馈结构来实现安全的。本文利用立方体攻击的传统比特基除法性质，考虑非黑盒多项式背景下的非线性反馈初始化阶段的安全性，研究了 WG-7流密码的初始化阶段的安全性。在我们的工作中，我们使用混合整数线性规划(MILP)模型来安装立方体攻击。我们的攻击结果使我们能够在20轮初始化之后恢复 WG-7的密钥，在 $2 ^ {73} $时间内使用 $2 ^ {10} $keystream 位。我们表明，我们提出的攻击采取显着降低数据复杂性。据我们所知，我们的攻击是第一个研究 WG-7密码基于非线性反馈初始化阶段的安全性的攻击。"
    },
    {
        "title": "Development of a Multi-purpose Fuzzer to Perform Assessment as Input to\n  a Cybersecurity Risk Assessment and Analysis System",
        "url": "http://arxiv.org/abs/2306.04284v1",
        "pub_date": "2023-06-07",
        "summary": "Fuzzing is utilized for testing software and systems for cybersecurity risk\nvia the automated adaptation of inputs. It facilitates the identification of\nsoftware bugs and misconfigurations that may create vulnerabilities, cause\nabnormal operations or result in systems' failure. While many fuzzers have been\npurpose-developed for testing specific systems, this paper proposes a\ngeneralized fuzzer that provides a specific capability for testing software and\ncyber-physical systems which utilize configuration files. While this fuzzer\nfacilitates the detection of system and software defects and vulnerabilities,\nit also facilitates the determination of the impact of settings on device\noperations. This later capability facilitates the modeling of the devices in a\ncybersecurity risk assessment and analysis system. This paper describes and\nassesses the performance of the proposed fuzzer technology. It also details how\nthe fuzzer operates as part of the broader cybersecurity risk assessment and\nanalysis system.",
        "translated": "Fuzzing 通过自动调整输入，用于测试软件和系统的网络安全风险。它有助于识别可能导致漏洞、导致异常操作或导致系统故障的软件错误和错误配置。针对测试特定系统的需要，本文提出了一种通用的模糊检测器，该模糊检测器为测试软件和利用配置文件的网络物理系统提供了特定的功能。虽然这个模糊检测器有助于检测系统和软件缺陷和漏洞，但它也有助于确定设置对设备操作的影响。此后的功能有助于在网络安全风险评估和分析系统中对设备进行建模。本文描述并评估了所提出的模糊控制技术的性能。报告还详细介绍了作为更广泛的网络安全风险评估和分析系统的一部分，模糊控制器是如何运作的。"
    },
    {
        "title": "Fully Robust Federated Submodel Learning in a Distributed Storage System",
        "url": "http://arxiv.org/abs/2306.05402v1",
        "pub_date": "2023-06-08",
        "summary": "We consider the federated submodel learning (FSL) problem in a distributed\nstorage system. In the FSL framework, the full learning model at the server\nside is divided into multiple submodels such that each selected client needs to\ndownload only the required submodel(s) and upload the corresponding update(s)\nin accordance with its local training data. The server comprises multiple\nindependent databases and the full model is stored across these databases. An\neavesdropper passively observes all the storage and listens to all the\ncommunicated data, of its controlled databases, to gain knowledge about the\nremote client data and the submodel information. In addition, a subset of\ndatabases may fail, negatively affecting the FSL process, as FSL process may\ntake a non-negligible amount of time for large models. To resolve these two\nissues together (i.e., security and database repair), we propose a novel coding\nmechanism coined ramp secure regenerating coding (RSRC), to store the full\nmodel in a distributed manner. Using our new RSRC method, the eavesdropper is\npermitted to learn a controllable amount of submodel information for the sake\nof reducing the communication and storage costs. Further, during the database\nrepair process, in the construction of the replacement database, the submodels\nto be updated are stored in the form of their latest version from updating\nclients, while the remaining submodels are obtained from the previous version\nin other databases through routing clients. Our new RSRC-based distributed FSL\napproach is constructed on top of our earlier two-database FSL scheme which\nuses private set union (PSU). A complete one-round FSL process consists of\nFSL-PSU phase, FSL-write phase and additional auxiliary phases. Our proposed\nFSL scheme is also robust against database drop-outs, client drop-outs, client\nlate-arrivals and an active adversary controlling databases.",
        "translated": "研究了分布式存储系统中的联邦子模型学习(FSL)问题。在 FSL 框架中，服务器端的完整学习模型被划分为多个子模型，每个选定的客户端只需要下载所需的子模型，并根据其本地训练数据上传相应的更新。服务器由多个独立的数据库组成，完整的模型存储在这些数据库中。窃听者被动地观察所有的存储器，监听所有被控数据库的通信数据，以获取远程客户端数据和子模型信息的相关知识。此外，数据库的一个子集可能会失败，从而对 FSL 过程产生负面影响，因为对于大型模型，FSL 过程可能需要花费不可忽视的时间。为了同时解决这两个问题(即安全性和数据库修复) ，我们提出了一种新的编码机制——斜坡安全再生编码(RSRC) ，以分布式方式存储完整的模型。使用我们新的 RSRC 方法，窃听者可以学习可控量的子模型信息，从而降低通信和存储成本。此外，在数据库修复过程中，在建立替换数据库时，需要更新的子模型以更新客户端的最新版本的形式存储，而其余子模型则通过路由客户端从其他数据库的上一版本获得。我们的新的基于 RSRC 的分布式 FSL 方法是在我们早期的两数据库 FSL 方案的基础上构建的，该方案使用私有集合联合(PSU)。一个完整的一轮 FSL 工艺包括 FSL-PSU 阶段、 FSL 写入阶段和附加辅助阶段。我们提出的 FSL 方案对于数据库丢失、客户端丢失、客户端延迟到达以及活跃的对手控制数据库也具有很强的鲁棒性。"
    },
    {
        "title": "Detecting Neural Trojans Through Merkle Trees",
        "url": "http://arxiv.org/abs/2306.05368v1",
        "pub_date": "2023-06-08",
        "summary": "Deep neural networks are utilized in a growing number of industries. Much of\nthe current literature focuses on the applications of deep neural networks\nwithout discussing the security of the network itself. One security issue\nfacing deep neural networks is neural trojans. Through a neural trojan, a\nmalicious actor may force the deep neural network to act in unintended ways.\nSeveral potential defenses have been proposed, but they are computationally\nexpensive, complex, or unusable in commercial applications. We propose Merkle\ntrees as a novel way to detect and isolate neural trojans.",
        "translated": "深层神经网络在越来越多的行业中得到了应用。目前的大部分文献都集中在深层神经网络的应用上，而没有讨论网络本身的安全性。深度神经网络面临的一个安全问题是神经木马。通过神经木马，恶意行为者可能会强迫深层神经网络以意想不到的方式行动。已经提出了几种潜在的防御措施，但它们在计算上代价高昂、复杂，或者在商业应用中无法使用。我们提出默克尔树作为一种新的方法来检测和分离神经木马。"
    },
    {
        "title": "Federated Linear Contextual Bandits with User-level Differential Privacy",
        "url": "http://arxiv.org/abs/2306.05275v1",
        "pub_date": "2023-06-08",
        "summary": "This paper studies federated linear contextual bandits under the notion of\nuser-level differential privacy (DP). We first introduce a unified federated\nbandits framework that can accommodate various definitions of DP in the\nsequential decision-making setting. We then formally introduce user-level\ncentral DP (CDP) and local DP (LDP) in the federated bandits framework, and\ninvestigate the fundamental trade-offs between the learning regrets and the\ncorresponding DP guarantees in a federated linear contextual bandits model. For\nCDP, we propose a federated algorithm termed as \\robin and show that it is\nnear-optimal in terms of the number of clients $M$ and the privacy budget\n$\\varepsilon$ by deriving nearly-matching upper and lower regret bounds when\nuser-level DP is satisfied. For LDP, we obtain several lower bounds, indicating\nthat learning under user-level $(\\varepsilon,\\delta)$-LDP must suffer a regret\nblow-up factor at least {$\\min\\{1/\\varepsilon,M\\}$ or\n$\\min\\{1/\\sqrt{\\varepsilon},\\sqrt{M}\\}$} under different conditions.",
        "translated": "本文在用户级差分隐私(DP)的概念下研究了联邦线性上下文盗贼。我们首先介绍了一个统一的联邦土匪框架，该框架可以在序贯决策环境中容纳 DP 的各种定义。然后在联邦土匪模型中正式引入了用户级中央 DP (CDP)和本地 DP (LDP) ，研究了在联邦线性关联土匪模型中，学习遗憾与相应 DP 保证之间的基本权衡关系。对于 CDP，我们提出了一种称为 Robin 的联邦算法，当用户级 DP 满足时，通过导出接近匹配的上下后悔界限，证明了该算法在客户数 $M $和隐私预算 $varepsilon $方面接近最优。对于 LDP，我们得到了几个下界，表明在用户级 $(varepsilon，delta) $- LDP 下的学习必须在不同的条件下至少经历一个后悔爆破因子{ $min {1/varepsilon，M } $或 $min {1/sqrt { varepsilon } ，sqrt { M } $}。"
    },
    {
        "title": "Ownership Protection of Generative Adversarial Networks",
        "url": "http://arxiv.org/abs/2306.05233v1",
        "pub_date": "2023-06-08",
        "summary": "Generative adversarial networks (GANs) have shown remarkable success in image\nsynthesis, making GAN models themselves commercially valuable to legitimate\nmodel owners. Therefore, it is critical to technically protect the intellectual\nproperty of GANs. Prior works need to tamper with the training set or training\nprocess, and they are not robust to emerging model extraction attacks. In this\npaper, we propose a new ownership protection method based on the common\ncharacteristics of a target model and its stolen models. Our method can be\ndirectly applicable to all well-trained GANs as it does not require retraining\ntarget models. Extensive experimental results show that our new method can\nachieve the best protection performance, compared to the state-of-the-art\nmethods. Finally, we demonstrate the effectiveness of our method with respect\nto the number of generations of model extraction attacks, the number of\ngenerated samples, different datasets, as well as adaptive attacks.",
        "translated": "生成对抗网络(GAN)在图像合成方面取得了显著的成功，使得 GAN 模型本身对于合法的模型所有者来说具有商业价值。因此，从技术上保护 GAN 的知识产权至关重要。以前的工作需要篡改训练集或训练过程，它们对新出现的模型提取攻击不具有鲁棒性。本文基于目标模型及其窃取模型的共同特点，提出了一种新的所有权保护方法。我们的方法可以直接适用于所有训练有素的 GAN，因为它不需要再训练目标模型。大量的实验结果表明，与目前最先进的保护方法相比，我们的新方法可以获得最佳的保护性能。最后，从模型提取攻击的代数、生成的样本数、不同的数据集以及自适应攻击等方面证明了该方法的有效性。"
    },
    {
        "title": "Boosting Adversarial Transferability by Achieving Flat Local Maxima",
        "url": "http://arxiv.org/abs/2306.05225v1",
        "pub_date": "2023-06-08",
        "summary": "Transfer-based attack adopts the adversarial examples generated on the\nsurrogate model to attack various models, making it applicable in the physical\nworld and attracting increasing interest. Recently, various adversarial attacks\nhave emerged to boost adversarial transferability from different perspectives.\nIn this work, inspired by the fact that flat local minima are correlated with\ngood generalization, we assume and empirically validate that adversarial\nexamples at a flat local region tend to have good transferability by\nintroducing a penalized gradient norm to the original loss function. Since\ndirectly optimizing the gradient regularization norm is computationally\nexpensive and intractable for generating adversarial examples, we propose an\napproximation optimization method to simplify the gradient update of the\nobjective function. Specifically, we randomly sample an example and adopt the\nfirst-order gradient to approximate the second-order Hessian matrix, which\nmakes computing more efficient by interpolating two Jacobian matrices.\nMeanwhile, in order to obtain a more stable gradient direction, we randomly\nsample multiple examples and average the gradients of these examples to reduce\nthe variance due to random sampling during the iterative process. Extensive\nexperimental results on the ImageNet-compatible dataset show that the proposed\nmethod can generate adversarial examples at flat local regions, and\nsignificantly improve the adversarial transferability on either normally\ntrained models or adversarially trained models than the state-of-the-art\nattacks.",
        "translated": "基于转移的攻击采用在代理模型上生成的敌对实例对各种模型进行攻击，使其适用于物理世界，引起了人们越来越多的兴趣。最近，各种各样的对抗性攻击已经出现，从不同的角度提高了对抗性的可转移性。在本文中，受平坦局部极小与良好推广相关的启发，我们假设并实验验证了在平坦局部区域上的对立例子通过引入惩罚梯度范数对原始损失函数具有良好的可迁移性。由于直接优化梯度正则化范数的计算量很大，而且难以生成对立的例子，因此提出了一种近似优化方法来简化目标函数的梯度更新。具体地说，我们随机抽样一个例子，采用一阶梯度来逼近二阶 Hessian 矩阵，通过插值两个 Jacobian 矩阵来提高计算效率。同时，为了得到一个更稳定的梯度方向，在迭代过程中，我们随机抽样多个样本，并对这些样本的梯度进行平均，以减少随机抽样造成的方差。在与 ImageNet 兼容的数据集上的大量实验结果表明，该方法可以在平坦的局部区域生成对抗性示例，并且比最先进的攻击方法显著地提高了对抗性转移在正常训练模型或对抗性训练模型上的可转移性。"
    },
    {
        "title": "PriSampler: Mitigating Property Inference of Diffusion Models",
        "url": "http://arxiv.org/abs/2306.05208v1",
        "pub_date": "2023-06-08",
        "summary": "Diffusion models have been remarkably successful in data synthesis. Such\nsuccesses have also driven diffusion models to apply to sensitive data, such as\nhuman face data, but this might bring about severe privacy concerns. In this\nwork, we systematically present the first privacy study about property\ninference attacks against diffusion models, in which adversaries aim to extract\nsensitive global properties of the training set from a diffusion model, such as\nthe proportion of the training data for certain sensitive properties.\nSpecifically, we consider the most practical attack scenario: adversaries are\nonly allowed to obtain synthetic data. Under this realistic scenario, we\nevaluate the property inference attacks on different types of samplers and\ndiffusion models. A broad range of evaluations shows that various diffusion\nmodels and their samplers are all vulnerable to property inference attacks.\nFurthermore, one case study on off-the-shelf pre-trained diffusion models also\ndemonstrates the effectiveness of the attack in practice. Finally, we propose a\nnew model-agnostic plug-in method PriSampler to mitigate the property inference\nof diffusion models. PriSampler can be directly applied to well-trained\ndiffusion models and support both stochastic and deterministic sampling.\nExtensive experiments illustrate the effectiveness of our defense and it makes\nadversaries infer the proportion of properties as close as random guesses.\nPriSampler also shows its significantly superior performance to diffusion\nmodels trained with differential privacy on both model utility and defense\nperformance.",
        "translated": "扩散模型在数据综合方面取得了显著的成功。这些成功也促使扩散模型应用于敏感数据，如人脸数据，但这可能会带来严重的隐私问题。在这项工作中，我们系统地提出了第一个针对扩散模型的属性推理攻击的隐私研究，其中对手的目标是从扩散模型中提取训练集的敏感的全局属性，例如某些敏感属性的训练数据的比例。具体来说，我们考虑最实际的攻击场景: 只允许对手获取合成数据。在这种现实情况下，我们评估了属性推断攻击的不同类型的采样器和扩散模型。大量的评估表明，各种扩散模型及其采样器都容易受到属性推断攻击。此外，一个现成的预训练扩散模型的案例研究也证明了攻击在实践中的有效性。最后，我们提出了一种新的模型无关插件方法 PriSampler 来缓解扩散模型的性质推断。PriSampler 可以直接应用于训练有素的扩散模型，并支持随机和确定性采样。大量的实验证明了我们防御的有效性，它使对手推断出的属性比例就像随机猜测一样接近。PriSampler 还显示了其明显优于扩散模型的性能，扩散模型在模型实用性和防御性能方面都经过了差分隐私的训练。"
    },
    {
        "title": "Formalizing, Verifying and Applying ISA Security Guarantees as Universal\n  Contracts",
        "url": "http://arxiv.org/abs/2306.05128v1",
        "pub_date": "2023-06-08",
        "summary": "Progress has recently been made on specifying instruction set architectures\n(ISAs) in executable formalisms rather than through prose. However, to date,\nthose formal specifications are limited to the functional aspects of the ISA\nand do not cover its security guarantees. We present a novel, general method\nfor formally specifying an ISAs security guarantees to (1) balance the needs of\nISA implementations (hardware) and clients (software), (2) can be\nsemi-automatically verified to hold for the ISA operational semantics,\nproducing a high-assurance mechanically-verifiable proof, and (3) support\ninformal and formal reasoning about security-critical software in the presence\nof adversarial code. Our method leverages universal contracts: software\ncontracts that express bounds on the authority of arbitrary untrusted code.\nUniversal contracts can be kept agnostic of software abstractions, and strike\nthe right balance between requiring sufficient detail for reasoning about\nsoftware and preserving implementation freedom of ISA designers and CPU\nimplementers. We semi-automatically verify universal contracts against Sail\nimplementations of ISA semantics using our Katamaran tool; a semi-automatic\nseparation logic verifier for Sail which produces machine-checked proofs for\nsuccessfully verified contracts. We demonstrate the generality of our method by\napplying it to two ISAs that offer very different security primitives: (1)\nMinimalCaps: a custom-built capability machine ISA and (2) a (somewhat\nsimplified) version of RISC-V with PMP. We verify a femtokernel using the\nsecurity guarantee we have formalized for RISC-V with PMP.",
        "translated": "最近在指定可执行形式的指令集体系结构(ISA)方面取得了进展，而不是通过散文。然而，到目前为止，这些正式规范仅限于 ISA 的功能方面，并不包括其安全保障。我们提出了一个新颖的，通用的方法来正式指定一个 ISA 安全保证: (1)平衡 ISA 实施(硬件)和客户(软件)的需求; (2)可以半自动验证以支持 ISA 操作语义学，产生一个高保证的机械验证证据; (3)支持在对手代码存在的情况下关于安全关键软件的非正式和正式的推理。我们的方法利用了通用契约: 软件契约表达了任意不可信代码的权限。通用契约可以保持软件抽象的不可知性，并在需要足够详细的软件推理和保持 ISA 设计者和 CPU 实现者的实现自由之间取得适当的平衡。我们使用我们的 Katamaran 工具半自动验证通用合同和 Sail 实现的 ISA 语义，这是一个半自动的 Sail 分离逻辑验证器，它为成功验证的合同生成机器检查证明。我们通过将其应用于提供非常不同的安全原语的两个 ISA 来展示我们的方法的通用性: (1) MinimalCaps: 一个定制构建的能力机 ISA 和(2)一个(稍微简化的)带有 PMP 的 RISC-V 版本。我们使用我们已经形式化的 RISC-V 和 PMP 的安全保证来验证飞机内核。"
    },
    {
        "title": "FheFL: Fully Homomorphic Encryption Friendly Privacy-Preserving\n  Federated Learning with Byzantine Users",
        "url": "http://arxiv.org/abs/2306.05112v1",
        "pub_date": "2023-06-08",
        "summary": "The federated learning (FL) technique was initially developed to mitigate\ndata privacy issues that can arise in the traditional machine learning\nparadigm. While FL ensures that a user's data always remain with the user, the\ngradients of the locally trained models must be communicated with the\ncentralized server to build the global model. This results in privacy leakage,\nwhere the server can infer private information of the users' data from the\nshared gradients. To mitigate this flaw, the next-generation FL architectures\nproposed encryption and anonymization techniques to protect the model updates\nfrom the server. However, this approach creates other challenges, such as a\nmalicious user might sabotage the global model by sharing false gradients.\nSince the gradients are encrypted, the server is unable to identify and\neliminate rogue users which would protect the global model. Therefore, to\nmitigate both attacks, this paper proposes a novel fully homomorphic encryption\n(FHE) based scheme suitable for FL. We modify the one-to-one single-key\nCheon-Kim-Kim-Song (CKKS)-based FHE scheme into a distributed multi-key\nadditive homomorphic encryption scheme that supports model aggregation in FL.\nWe employ a novel aggregation scheme within the encrypted domain, utilizing\nusers' non-poisoning rates, to effectively address data poisoning attacks while\nensuring privacy is preserved by the proposed encryption scheme. Rigorous\nsecurity, privacy, convergence, and experimental analyses have been provided to\nshow that FheFL is novel, secure, and private, and achieves comparable accuracy\nat reasonable computational cost.",
        "translated": "联邦学习(FL)技术最初是为了缓解传统机器学习范式中可能出现的数据隐私问题而开发的。虽然 FL 确保用户的数据始终与用户保持一致，但是本地训练模型的梯度必须与集中式服务器通信，以构建全局模型。这会导致隐私泄露，服务器可以从共享梯度推断用户数据的隐私信息。为了减轻这一缺陷，下一代 FL 架构提出了加密和匿名技术来保护模型更新不受服务器的影响。但是，这种方法会带来其他挑战，比如恶意用户可能会通过共享虚假渐变破坏全局模型。由于梯度是加密的，服务器无法识别和消除流氓用户，这将保护全局模型。因此，为了减轻这两种攻击，本文提出了一种新的基于全同态加密(fHE)的适合于 FL 的方案。我们修改了基于一对一单密钥 Cheon-Kim-Kim-Song (CKKS)的 FHE 方案为一个分布式多密钥加法同态加密方案，该方案支持 FL 中的模型聚合。我们在加密域内采用一种新的聚合方案，利用用户的非中毒率，有效地解决数据中毒攻击，同时确保所提出的加密方案能够保护隐私。严格的安全性、隐私性、收敛性和实验分析表明，FheFL 是新颖的、安全的和私有的，并且在合理的计算成本下达到可比较的精度。"
    },
    {
        "title": "On the Robustness of Topics API to a Re-Identification Attack",
        "url": "http://arxiv.org/abs/2306.05094v1",
        "pub_date": "2023-06-08",
        "summary": "Web tracking through third-party cookies is considered a threat to users'\nprivacy and is supposed to be abandoned in the near future. Recently, Google\nproposed the Topics API framework as a privacy-friendly alternative for\nbehavioural advertising. Using this approach, the browser builds a user profile\nbased on navigation history, which advertisers can access. The Topics API has\nthe possibility of becoming the new standard for behavioural advertising, thus\nit is necessary to fully understand its operation and find possible\nlimitations.\n  This paper evaluates the robustness of the Topics API to a re-identification\nattack where an attacker reconstructs the user profile by accumulating user's\nexposed topics over time to later re-identify the same user on a different\nwebsite. Using real traffic traces and realistic population models, we find\nthat the Topics API mitigates but cannot prevent re-identification to take\nplace, as there is a sizeable chance that a user's profile is unique within a\nwebsite's audience. Consequently, the probability of correct re-identification\ncan reach 15-17%, considering a pool of 1,000 users. We offer the code and data\nwe use in this work to stimulate further studies and the tuning of the Topic\nAPI parameters.",
        "translated": "通过第三方 cookie 进行的网络跟踪被认为是对用户隐私的威胁，应该会在不久的将来被废弃。最近，Google 提出将 Topics API 框架作为行为广告的一个隐私友好的替代方案。使用这种方法，浏览器建立一个基于导航历史的用户配置文件，广告商可以访问。主题 API 有可能成为行为广告的新标准，因此有必要充分了解其运作并找出可能的局限性。本文评估了 Topics API 对重新识别攻击的健壮性，攻击者通过累积用户暴露的主题来重建用户配置文件，然后在不同的网站上重新识别相同的用户。通过使用真实的流量跟踪和真实的人口模型，我们发现 Topics API 可以缓解但不能阻止重新识别的发生，因为一个用户的个人资料在一个网站的受众中有很大的可能性是独一无二的。因此，考虑到有1,000个用户，正确重新识别的可能性可以达到15-17% 。我们提供了在这项工作中使用的代码和数据，以促进进一步的研究和 Topic API 参数的调优。"
    },
    {
        "title": "Re-aligning Shadow Models can Improve White-box Membership Inference\n  Attacks",
        "url": "http://arxiv.org/abs/2306.05093v1",
        "pub_date": "2023-06-08",
        "summary": "Machine learning models have been shown to leak sensitive information about\ntheir training datasets. As models are being increasingly used, on devices, to\nautomate tasks and power new applications, there have been concerns that such\nwhite-box access to its parameters, as opposed to the black-box setting which\nonly provides query access to the model, increases the attack surface. Directly\nextending the shadow modelling technique from the black-box to the white-box\nsetting has been shown, in general, not to perform better than black-box only\nattacks. A key reason is misalignment, a known characteristic of deep neural\nnetworks. We here present the first systematic analysis of the causes of\nmisalignment in shadow models and show the use of a different weight\ninitialisation to be the main cause of shadow model misalignment. Second, we\nextend several re-alignment techniques, previously developed in the model\nfusion literature, to the shadow modelling context, where the goal is to\nre-align the layers of a shadow model to those of the target model.We show\nre-alignment techniques to significantly reduce the measured misalignment\nbetween the target and shadow models. Finally, we perform a comprehensive\nevaluation of white-box membership inference attacks (MIA). Our analysis\nreveals that (1) MIAs suffer from misalignment between shadow models, but that\n(2) re-aligning the shadow models improves, sometimes significantly, MIA\nperformance. On the CIFAR10 dataset with a false positive rate of 1\\%,\nwhite-box MIA using re-aligned shadow models improves the true positive rate by\n4.5\\%.Taken together, our results highlight that on-device deployment increase\nthe attack surface and that the newly available information can be used by an\nattacker.",
        "translated": "机器学习模型已被证明会泄漏关于其训练数据集的敏感信息。随着模型在设备上越来越多地被用于自动化任务和驱动新的应用程序，有人担心，这种白盒访问其参数，而不是黑盒设置，只提供对模型的查询访问，增加了攻击面。直接将阴影建模技术从黑盒扩展到白盒设置已经被证明，一般来说，不会比黑盒单独的攻击表现得更好。一个关键原因是错位，这是深度神经网络的一个已知特征。本文首次系统地分析了影子模型失调的原因，并指出使用不同的权重初始化是影子模型失调的主要原因。其次，我们将以前在模型融合文献中开发的几种重新对齐技术扩展到阴影建模背景，其中目标是将阴影模型的层重新对齐到目标模型的层。我们显示重新对齐技术以显着减少目标和阴影模型之间测量的不对齐。最后，我们对白盒成员推理攻击(MIA)进行了综合评估。我们的分析表明: (1)阴影模型之间存在失调，但是(2)重新调整阴影模型可以显著提高 MIA 性能。在 CIFAR10数据集中，假阳性率为1% ，使用重新对齐的阴影模型的白盒 MIA 使真阳性率提高了4.5% 。综上所述，我们的结果强调了设备上的部署增加了攻击面，并且新获得的信息可以被攻击者使用。"
    },
    {
        "title": "\"My sex-related data is more sensitive than my financial data and I want\n  the same level of security and privacy\": User Risk Perceptions and Protective\n  Actions in Female-oriented Technologies",
        "url": "http://arxiv.org/abs/2306.05956v1",
        "pub_date": "2023-06-09",
        "summary": "The digitalization of the reproductive body has engaged myriads of\ncutting-edge technologies in supporting people to know and tackle their\nintimate health. Generally understood as female technologies (aka\nfemale-oriented technologies or 'FemTech'), these products and systems collect\na wide range of intimate data which are processed, transferred, saved and\nshared with other parties. In this paper, we explore how the \"data-hungry\"\nnature of this industry and the lack of proper safeguarding mechanisms,\nstandards, and regulations for vulnerable data can lead to complex harms or\nfaint agentic potential. We adopted mixed methods in exploring users'\nunderstanding of the security and privacy (SP) of these technologies. Our\nfindings show that while users can speculate the range of harms and risks\nassociated with these technologies, they are not equipped and provided with the\ntechnological skills to protect themselves against such risks. We discuss a\nnumber of approaches, including participatory threat modelling and SP by\ndesign, in the context of this work and conclude that such approaches are\ncritical to protect users in these sensitive systems.",
        "translated": "生殖机构的数字化使用了无数尖端技术，支持人们了解和处理自己的亲密健康。这些产品和系统通常被理解为女性技术(又名面向女性的技术或“ FemTech”) ，它们收集各种各样的私密数据，这些数据被处理、传输、保存并与其他各方共享。在本文中，我们探讨了这个行业的“数据饥渴”性质和缺乏适当的保护机制，标准和法规的脆弱数据可能导致复杂的危害或微弱的代理潜力。我们采用混合的方法来探索用户对这些技术的安全性和隐私性(SP)的理解。我们的研究结果表明，虽然用户可以推测与这些技术相关的危害和风险的范围，但他们没有装备和提供技术技能来保护自己免受这些风险。在这项工作的背景下，我们讨论了一些方法，包括参与式威胁建模和按设计的 SP，并得出结论认为，这些方法对于保护这些敏感系统中的用户至关重要。"
    },
    {
        "title": "GAN-CAN: A Novel Attack to Behavior-Based Driver Authentication Systems",
        "url": "http://arxiv.org/abs/2306.05923v2",
        "pub_date": "2023-06-09",
        "summary": "For many years, car keys have been the sole mean of authentication in\nvehicles. Whether the access control process is physical or wireless,\nentrusting the ownership of a vehicle to a single token is prone to stealing\nattempts. For this reason, many researchers started developing behavior-based\nauthentication systems. By collecting data in a moving vehicle, Deep Learning\n(DL) models can recognize patterns in the data and identify drivers based on\ntheir driving behavior. This can be used as an anti-theft system, as a thief\nwould exhibit a different driving style compared to the vehicle owner's.\nHowever, the assumption that an attacker cannot replicate the legitimate driver\nbehavior falls under certain conditions.\n  In this paper, we propose GAN-CAN, the first attack capable of fooling\nstate-of-the-art behavior-based driver authentication systems in a vehicle.\nBased on the adversary's knowledge, we propose different GAN-CAN\nimplementations. Our attack leverages the lack of security in the Controller\nArea Network (CAN) to inject suitably designed time-series data to mimic the\nlegitimate driver. Our design of the malicious time series results from the\ncombination of different Generative Adversarial Networks (GANs) and our study\non the safety importance of the injected values during the attack. We tested\nGAN-CAN in an improved version of the most efficient driver behavior-based\nauthentication model in the literature. We prove that our attack can fool it\nwith an attack success rate of up to 0.99. We show how an attacker, without\nprior knowledge of the authentication system, can steal a car by deploying\nGAN-CAN in an off-the-shelf system in under 22 minutes.",
        "translated": "多年来，车钥匙一直是车辆认证的唯一手段。无论访问控制过程是物理的还是无线的，将车辆的所有权委托给单个令牌都容易导致窃取尝试。出于这个原因，许多研究人员开始开发基于行为的认证系统。深度学习(DL)模型通过在行驶中的车辆中收集数据，可以识别数据中的模式，并根据驾驶员的驾驶行为识别驾驶员。这可以作为一个防盗系统，因为小偷会表现出不同的驾驶风格相比，车主的。但是，攻击者不能复制合法的驱动程序行为的假设在某些情况下是不成立的。在本文中，我们提出的 GAN-CAN，第一次攻击能够欺骗国家的最先进的行为为基础的驾驶员认证系统在车辆。基于对手的知识，我们提出了不同的 GAN-CAN 实现方案。我们的攻击利用控制器局域网路(CAN)缺乏安全性的特点，注入适当设计的时间序列数据来模拟合法的驱动程序。我们对恶意时间序列的设计结合了不同的生成对抗网络(GAN)和我们对注入值在攻击过程中的安全重要性的研究。我们在文献中最有效的基于驾驶员行为的认证模型的改进版本中测试了 GAN-CAN。我们证明我们的攻击可以愚弄它，攻击成功率高达0.99。我们展示了攻击者如何在没有事先了解认证系统的情况下，通过在不到22分钟的时间内在现成的系统中部署 GAN-CAN 来窃取汽车。"
    },
    {
        "title": "Differentially Private All-Pairs Shortest Distances for Low Tree-Width\n  Graphs",
        "url": "http://arxiv.org/abs/2306.05916v1",
        "pub_date": "2023-06-09",
        "summary": "In this paper, we present a polynomial time algorithm for the problem of\ndifferentially private all pair shortest distances over the class of low\ntree-width graphs. Our result generalizes the result of Sealfon 2016 for the\ncase of trees to a much larger family of graphs. Furthermore, if we restrict to\nthe class of low tree-width graphs, the additive error of our algorithm is\nsignificantly smaller than that of the best known algorithm for this problem,\nproposed by Chen et. al. 2023.",
        "translated": "本文提出了一种求解低树宽图类上的全对最短距离的差分私有化问题的多项式时间算法。我们的结果将 Sealfon 2016的结果推广到一个更大的图族。此外，如果我们限制在低树宽度图的类别，我们的算法的加性误差明显小于最好的已知算法对这个问题，提出了陈等人。Al 2023."
    },
    {
        "title": "You Can Tell a Cybercriminal by the Company they Keep: A Framework to\n  Infer the Relevance of Underground Communities to the Threat Landscape",
        "url": "http://arxiv.org/abs/2306.05898v1",
        "pub_date": "2023-06-09",
        "summary": "The criminal underground is populated with forum marketplaces where,\nallegedly, cybercriminals share and trade knowledge, skills, and cybercrime\nproducts. However, it is still unclear whether all marketplaces matter the same\nin the overall threat landscape. To effectively support trade and avoid\ndegenerating into scams-for-scammers places, underground markets must address\nfundamental economic problems (such as moral hazard, adverse selection) that\nenable the exchange of actual technology and cybercrime products (as opposed to\nrepackaged malware or years-old password databases). From the relevant\nliterature and manual investigation, we identify several mechanisms that\nmarketplaces implement to mitigate these problems, and we condense them into a\nmarket evaluation framework based on the Business Model Canvas. We use this\nframework to evaluate which mechanisms `successful' marketplaces have in place,\nand whether these differ from those employed by `unsuccessful' marketplaces. We\ntest the framework on 23 underground forum markets by searching 836 aliases of\nindicted cybercriminals to identify `successful' marketplaces. We find evidence\nthat marketplaces whose administrators are impartial in trade, verify their\nsellers, and have the right economic incentives to keep the market functional\nare more likely to be credible sources of threat.",
        "translated": "地下犯罪集团充斥着论坛市场，据称，网络犯罪分子在那里分享和交易知识、技能和网络犯罪产品。然而，目前还不清楚是否所有的市场在整体的威胁情况下都是一样的。为了有效地支持贸易，避免沦为骗子的地盘，地下市场必须解决根本性的经济问题(如道德风险、逆向选择) ，以便能够交换实际的技术和网络犯罪产品(而不是重新包装的恶意软件或存在多年的密码数据库)。从相关文献和手工调查中，我们确定了市场实施的几种机制来缓解这些问题，并将它们浓缩成一个基于商业模式图的市场评估框架。我们使用这个框架来评估哪些机制“成功的”市场已经到位，以及这些机制是否不同于“不成功的”市场所使用的机制。我们在23个地下论坛市场上通过搜索836个被起诉的网络犯罪分子的化名来确定“成功的”市场来测试这个框架。我们发现有证据表明，那些管理者在贸易方面不偏不倚、核实卖家、并具有保持市场正常运转的正确经济激励的市场，更有可能成为可信的威胁来源。"
    },
    {
        "title": "Detecting Adversarial Directions in Deep Reinforcement Learning to Make\n  Robust Decisions",
        "url": "http://arxiv.org/abs/2306.05873v1",
        "pub_date": "2023-06-09",
        "summary": "Learning in MDPs with highly complex state representations is currently\npossible due to multiple advancements in reinforcement learning algorithm\ndesign. However, this incline in complexity, and furthermore the increase in\nthe dimensions of the observation came at the cost of volatility that can be\ntaken advantage of via adversarial attacks (i.e. moving along worst-case\ndirections in the observation space). To solve this policy instability problem\nwe propose a novel method to detect the presence of these non-robust directions\nvia local quadratic approximation of the deep neural policy loss. Our method\nprovides a theoretical basis for the fundamental cut-off between safe\nobservations and adversarial observations. Furthermore, our technique is\ncomputationally efficient, and does not depend on the methods used to produce\nthe worst-case directions. We conduct extensive experiments in the Arcade\nLearning Environment with several different adversarial attack techniques. Most\nsignificantly, we demonstrate the effectiveness of our approach even in the\nsetting where non-robust directions are explicitly optimized to circumvent our\nproposed method.",
        "translated": "由于强化学习算法设计的多项进步，目前可以在具有高度复杂状态表示的 MDP 中进行学习。然而，这种复杂性的增加以及观察维度的增加是以可以通过对抗性攻击(即沿着观察空间中的最坏情况方向移动)利用的波动性为代价的。为了解决这个策略不稳定性问题，我们提出了一种新的方法来检测这些非鲁棒方向的存在，通过局部二次逼近的深度神经策略损失。我们的方法为安全观察和对抗观察之间的基本分界提供了理论基础。此外，我们的技术是计算效率，并不依赖于方法用于产生最坏的情况下的方向。我们在拱廊学习环境中使用几种不同的对抗性攻击技术进行广泛的实验。最重要的是，我们证明了我们的方法的有效性，即使在非鲁棒的方向是明确优化的设置，以规避我们提出的方法。"
    },
    {
        "title": "Detecting Phishing Sites Using ChatGPT",
        "url": "http://arxiv.org/abs/2306.05816v1",
        "pub_date": "2023-06-09",
        "summary": "The rise of large language models (LLMs) has had a significant impact on\nvarious domains, including natural language processing and artificial\nintelligence. While LLMs such as ChatGPT have been extensively researched for\ntasks such as code generation and text synthesis, their application in\ndetecting malicious web content, particularly phishing sites, has been largely\nunexplored. To combat the rising tide of automated cyber attacks facilitated by\nLLMs, it is imperative to automate the detection of malicious web content,\nwhich requires approaches that leverage the power of LLMs to analyze and\nclassify phishing sites. In this paper, we propose a novel method that utilizes\nChatGPT to detect phishing sites. Our approach involves leveraging a web\ncrawler to gather information from websites and generate prompts based on this\ncollected data. This approach enables us to detect various phishing sites\nwithout the need for fine-tuning machine learning models and identify social\nengineering techniques from the context of entire websites and URLs. To\nevaluate the performance of our proposed method, we conducted experiments using\na dataset. The experimental results using GPT-4 demonstrated promising\nperformance, with a precision of 98.3% and a recall of 98.4%. Comparative\nanalysis between GPT-3.5 and GPT-4 revealed an enhancement in the latter's\ncapability to reduce false negatives. These findings not only highlight the\npotential of LLMs in efficiently identifying phishing sites but also have\nsignificant implications for enhancing cybersecurity measures and protecting\nusers from the dangers of online fraudulent activities.",
        "translated": "大语言模型(LLM)的兴起对自然语言处理和人工智能等领域产生了重大影响。虽然像 ChatGPT 这样的 LLM 已经被广泛研究用于代码生成和文本合成等任务，但它们在检测恶意网络内容(尤其是网络钓鱼网站)方面的应用在很大程度上还没有被探索。为了应对 LLM 推动的自动化网络攻击浪潮，必须自动检测恶意网络内容，这需要利用 LLM 的能力来分析和分类钓鱼网站。本文提出了一种利用 ChatGPT 检测网络钓鱼网站的新方法。我们的方法包括利用网络爬虫从网站收集信息，并根据收集到的数据生成提示。这种方法使我们能够检测各种钓鱼网站，而不需要对机器学习模型进行微调，并从整个网站和 URL 的上下文中识别社会工程技术。为了评估我们提出的方法的性能，我们使用一个数据集进行了实验。实验结果表明 GPT-4具有良好的性能，准确率为98.3% ，召回率为98.4% 。GPT-3.5和 GPT-4的比较分析显示后者减少假阴性的能力有所提高。这些调查结果不仅突出了 LLM 在有效识别钓鱼网站方面的潜力，而且对加强网络安全措施和保护用户免遭网上欺诈活动的危险具有重大影响。"
    },
    {
        "title": "DETECTA: Investigación de metodologías no intrusivas apoyadas en\n  tecnologías habilitadoras 4.0 para abordar un mantenimiento predictivo y\n  ciberseguro en pymes industriales",
        "url": "http://arxiv.org/abs/2306.05799v1",
        "pub_date": "2023-06-09",
        "summary": "This work presents the results of the DETECTA project, which addresses\nindustrial research activities for the generation of predictive knowledge aimed\nat detecting anomalies in machining-based manufacturing systems. It addresses\ndifferent technological challenges to simultaneously improve the availability\nof machinery and the protection against cyberthreats of industrial systems,\nwith the collaboration of knowledge centers and experts in industrial\nprocesses. Through the use of innovative technologies such as the digital twin\nand artificial intelligence, it implements process characterization\nmethodologies and anomaly detection in a non-intrusive way without limiting the\nproductivity of the industrial plant according to the maintenance and remote\naccess needs. The research has been supported by a general evaluation of\nconnected environments in small and medium-sized enterprises to identify if the\nbenefits of digitization outweigh the risks that cannot be eliminated. The\nresults obtained, through a process of supervision by process experts and\nmachine learning, have made it possible to discriminate anomalies between\npurely technical events and events related to cyber incidents or cyber attacks.",
        "translated": "这项工作介绍了 DETECTA 项目的结果，该项目涉及产生预测性知识的工业研究活动，这些预测性知识旨在检测基于机械加工的制造系统中的异常。它通过知识中心和工业过程专家的合作，应对不同的技术挑战，同时改善机械的可用性和防范工业系统的网络威胁。通过使用创新技术，例如数码双胞胎和人工智能，它以非侵入性的方式实施过程角色塑造方法和异常检测，而不会根据维修和远程访问的需要限制工业厂房的生产力。这项研究得到了对中小型企业联网环境的一般评价的支持，以确定数字化的好处是否大于无法消除的风险。通过过程专家和机器学习的监督过程所获得的结果，使我们能够区分纯技术事件和与网络事件或网络攻击有关的事件之间的异常。"
    },
    {
        "title": "Cross-Consensus Measurement of Individual-level Decentralization in\n  Blockchains",
        "url": "http://arxiv.org/abs/2306.05788v1",
        "pub_date": "2023-06-09",
        "summary": "Decentralization is widely recognized as a crucial characteristic of\nblockchains that enables them to resist malicious attacks such as the 51%\nattack and the takeover attack. Prior research has primarily examined\ndecentralization in blockchains employing the same consensus protocol or at the\nlevel of block producers. This paper presents the first individual-level\nmeasurement study comparing the decentralization of blockchains employing\ndifferent consensus protocols. To facilitate cross-consensus evaluation, we\npresent a two-level comparison framework and a new metric. We apply the\nproposed methods to Ethereum and Steem, two representative blockchains for\nwhich decentralization has garnered considerable interest. Our findings dive\ndeeper into the level of decentralization, suggest the existence of\ncentralization risk at the individual level in Steem, and provide novel\ninsights into the cross-consensus comparison of decentralization in\nblockchains.",
        "translated": "地方分权被广泛认为是区块链的一个关键特征，它使区块链能够抵御恶意攻击，如51% 攻击和接管攻击。先前的研究主要是在区块链中使用相同的协商一致方案或在区块生产者的水平上研究地方分权。本文介绍了第一个个体水平的测量研究，比较采用不同共识方案的区块链的地方分权。为了便于交叉共识评价，我们提出了一个两级比较框架和一个新的度量。我们将提议的方法应用于 Ethereum 和 Steem，这两个具有代表性的区块链地方分权已经引起了相当大的兴趣。我们的研究结果更深入地探讨了地方分权的水平，提出了在 Steem 个人层面存在的集中风险，并为区块链中地方分权的交叉共识比较提供了新颖的见解。"
    },
    {
        "title": "DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework",
        "url": "http://arxiv.org/abs/2306.05734v1",
        "pub_date": "2023-06-09",
        "summary": "Hyperparameter optimization, also known as hyperparameter tuning, is a widely\nrecognized technique for improving model performance. Regrettably, when\ntraining private ML models, many practitioners often overlook the privacy risks\nassociated with hyperparameter optimization, which could potentially expose\nsensitive information about the underlying dataset. Currently, the sole\nexisting approach to allow privacy-preserving hyperparameter optimization is to\nuniformly and randomly select hyperparameters for a number of runs,\nsubsequently reporting the best-performing hyperparameter. In contrast, in\nnon-private settings, practitioners commonly utilize \"adaptive\" hyperparameter\noptimization methods such as Gaussian process-based optimization, which select\nthe next candidate based on information gathered from previous outputs. This\nsubstantial contrast between private and non-private hyperparameter\noptimization underscores a critical concern. In our paper, we introduce\nDP-HyPO, a pioneering framework for \"adaptive\" private hyperparameter\noptimization, aiming to bridge the gap between private and non-private\nhyperparameter optimization. To accomplish this, we provide a comprehensive\ndifferential privacy analysis of our framework. Furthermore, we empirically\ndemonstrate the effectiveness of DP-HyPO on a diverse set of real-world and\nsynthetic datasets.",
        "translated": "超参数优化，也称为超参数调整，是一种被广泛认可的改善模型性能的技术。遗憾的是，在训练私有机器学习模型时，许多从业者往往忽视了与超参数优化相关的隐私风险，这可能会暴露关于底层数据集的敏感信息。目前，允许保护隐私的超参数优化的唯一现有方法是为多次运行统一和随机选择超参数，随后报告性能最好的超参数。相比之下，在非私有设置，从业人员通常利用“自适应”超参数优化方法，如高斯过程为基础的优化，选择下一个候选人的基础上收集的信息从以前的输出。私有和非私有超参数优化之间的实质性对比强调了一个关键问题。在本文中，我们介绍了 DP-HyPO，一个“自适应”私有超参数优化的开创性框架，旨在弥补私有和非私有超参数优化之间的差距。为了达到这个目的，我们对我们的架构进行了全面的差分隐私分析。此外，我们实证证明了 DP-HyPO 在一组不同的真实世界和合成数据集上的有效性。"
    },
    {
        "title": "JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its\n  Application to Malicious Website Detection",
        "url": "http://arxiv.org/abs/2306.05698v1",
        "pub_date": "2023-06-09",
        "summary": "Machine learning is often used for malicious website detection, but an\napproach incorporating WebAssembly as a feature has not been explored due to a\nlimited number of samples, to the best of our knowledge. In this paper, we\npropose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization\npaCKer), a tool to generate WebAssembly datasets in a pseudo fashion via\nJavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code\nin the real world, convert them into WebAssembly, and then outputs vectors of\nthe WebAssembly as samples for malicious website detection. We also conduct\nexperimental evaluations of JABBERWOCK in terms of the processing time for\ndataset generation, comparison of the generated samples with actual WebAssembly\nsamples gathered from the Internet, and an application for malicious website\ndetection. Regarding the processing time, we show that JABBERWOCK can construct\na dataset in 4.5 seconds per sample for any number of samples. Next, comparing\n10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we\nbelieve that the generated samples by JABBERWOCK are similar to those in the\nreal world. We then show that JABBERWOCK can provide malicious website\ndetection with 99\\% F1-score because JABBERWOCK makes a gap between benign and\nmalicious samples as the reason for the above high score. We also confirm that\nJABBERWOCK can be combined with an existing malicious website detection tool to\nimprove F1-scores. JABBERWOCK is publicly available via GitHub\n(https://github.com/c-chocolate/Jabberwock).",
        "translated": "机器学习通常用于恶意网站检测，但是据我们所知，由于样本数量有限，还没有探索将 WebAssembly 作为一个特性的方法。在本文中，我们提出了 JABBERWOCK (通过 WebAssembly 优化包工具基于 JavaScript 的二进制编码器) ，一个通过 JavaScript 以伪方式生成 WebAssembly 数据集的工具。粗略地说，JABBERWOCK 自动收集现实世界中的 JavaScript 代码，将它们转换为 WebAssembly，然后将 WebAssembly 的向量输出为用于恶意网站检测的示例。我们还对 JABBERWOCK 进行了实验性的评估，包括数据集生成的处理时间、生成的样本与从互联网收集的实际 WebAssembly 样本的比较，以及恶意网站检测应用程序。关于处理时间，我们展示了 JABBERWOCK 可以在4.5秒内为任意数量的样本构造一个数据集。接下来，将 JABBERWOCK 输出的10,000个样本与收集的168个 WebAssembly 样本进行比较，我们认为 JABBERWOCK 生成的样本与现实世界中的样本相似。然后我们证明了 JABBERWOCK 可以提供99% 的 F1分数的恶意网站检测，因为 JABBERWOCK 使良性和恶意样本之间的差距作为上述高分的原因。我们还证实，JABBERWOCK 可以结合现有的恶意网站检测工具，以提高 F1分数。JABBERWOCK 可以通过 gitHub ( https://GitHub.com/c-chocolate/JABBERWOCK )公开获得。"
    },
    {
        "title": "Gaussian Membership Inference Privacy",
        "url": "http://arxiv.org/abs/2306.07273v1",
        "pub_date": "2023-06-12",
        "summary": "We propose a new privacy notion called $f$-Membership Inference Privacy\n($f$-MIP), which explicitly considers the capabilities of realistic adversaries\nunder the membership inference attack threat model. By doing so $f$-MIP offers\ninterpretable privacy guarantees and improved utility (e.g., better\nclassification accuracy). Our novel theoretical analysis of likelihood\nratio-based membership inference attacks on noisy stochastic gradient descent\n(SGD) results in a parametric family of $f$-MIP guarantees that we refer to as\n$\\mu$-Gaussian Membership Inference Privacy ($\\mu$-GMIP). Our analysis\nadditionally yields an analytical membership inference attack that offers\ndistinct advantages over previous approaches. First, unlike existing methods,\nour attack does not require training hundreds of shadow models to approximate\nthe likelihood ratio. Second, our analytical attack enables straightforward\nauditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the\nimportance of various factors, such as hyperparameters (e.g., batch size,\nnumber of model parameters) and data specific characteristics in controlling an\nattacker's success in reliably inferring a given point's membership to the\ntraining set. We demonstrate the effectiveness of our method on models trained\nacross vision and tabular datasets.",
        "translated": "我们提出了一种新的隐私概念，称为 $f $- 成员推理隐私($f $- MIP) ，它明确考虑了成员推理攻击威胁模型下现实对手的能力。通过这样做 $f $- MIP 提供了可解释的隐私保障和改进的实用性(例如，更好的分类准确性)。我们对噪声随机梯度下降(SGD)的基于似然比的成员推理攻击的新颖理论分析导致了 $f $- MIP 保证的参数族，我们称之为 $mu $- Gaussian 成员推理隐私($mu $- gmIP)。我们的分析还产生了一种分析性成员推断攻击，它比以前的方法具有明显的优势。首先，与现有的方法不同，我们的攻击不需要训练数百个阴影模型来近似似然比。其次，我们的分析攻击可以直接审计我们的隐私概念 $f $- MIP。最后，我们的分析强调了各种因素的重要性，例如超参数(例如，批量大小，模型参数的数量)和数据特定特征在控制攻击者成功可靠地推断给定点的训练集成员。我们证明了我们的方法的有效性模型训练跨视觉和表格数据集。"
    },
    {
        "title": "Generic Attacks against Cryptographic Hardware through Long-Range Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.07249v1",
        "pub_date": "2023-06-12",
        "summary": "Hardware-based cryptographic implementations utilize countermeasures to\nresist side-channel attacks. In this paper, we propose a novel deep-learning\narchitecture for side-channel analysis called SCANET that generalizes across\nmultiple implementations and algorithms without manual tuning or trace\npre-processing. We achieve this by combining a novel input processing technique\nwith several advanced deep learning techniques including transformer blocks and\nmulti-task learning. We demonstrate the generality of our approach by\nsuccessfully attacking four hardware-accelerated countermeasures for elliptic\ncurve digital signatures in an end-to-end manner without human tuning.\nAdditionally, we showcase SCANET's ability to generalize across multiple\nalgorithms by successfully replicating state-of-the-art attacks against\nprotected AES without the need for trace preprocessing, hand-tuning, or model\narchitectural changes. These results offer promising prospects for generic and\nautomated side-channel leakage evaluation without manual effort.",
        "translated": "基于硬件的加密实现利用对策来抵抗侧信道攻击。在本文中，我们提出了一种新的边通道分析的深度学习体系结构，称为 SCANET，它可以在不需要手动调优或跟踪预处理的情况下跨多个实现和算法进行泛化。我们通过将一种新的输入处理技术与包括变压器块和多任务学习在内的几种先进的深度学习技术相结合来实现这一目标。我们证明了我们的方法的一般性，成功地攻击四个硬件加速的椭圆曲线数字签名在一个端到端的方式没有人工调整的对策。此外，我们还展示了 SCANET 通过成功复制针对受保护的 AES 的最先进的攻击而不需要跟踪预处理、手工调优或模型架构更改的多种算法进行泛化的能力。这些结果提供了通用和自动化的前景，侧渠泄漏评价无需人工努力。"
    },
    {
        "title": "Cybersecurity Training for Users of Remote Computing",
        "url": "http://arxiv.org/abs/2306.07192v1",
        "pub_date": "2023-06-12",
        "summary": "End users of remote computing systems are frequently not aware of basic ways\nin which they could enhance protection against cyber-threats and attacks. In\nthis paper, we discuss specific techniques to help and train users to improve\ncybersecurity when using such systems. To explain the rationale behind these\ntechniques, we go into some depth explaining possible threats in the context of\nusing remote, shared computing resources. Although some of the details of these\nprescriptions and recommendations apply to specific use cases when connecting\nto remote servers, such as a supercomputer, cluster, or Linux workstation, the\nmain concepts and ideas can be applied to a wider spectrum of cases.",
        "translated": "远程计算系统的最终用户常常不知道他们可以通过哪些基本方法加强对网络威胁和攻击的保护。在本文中，我们讨论了在使用这些系统时帮助和培训用户提高网络安全的具体技术。为了解释这些技术背后的基本原理，我们深入解释了在使用远程共享计算资源的上下文中可能存在的威胁。尽管这些规定和建议的一些细节适用于连接到远程服务器(如超级计算机、集群或 Linux 工作站)时的特定用例，但主要概念和思想可以应用于更广泛的用例。"
    },
    {
        "title": "Twitter Bots Influence on the Russo-Ukrainian War During the 2022\n  Italian General Elections",
        "url": "http://arxiv.org/abs/2306.07183v1",
        "pub_date": "2023-06-12",
        "summary": "In February 2022, Russia launched a full-scale invasion of Ukraine. This\nevent had global repercussions, especially on the political decisions of\nEuropean countries. As expected, the role of Italy in the conflict became a\nmajor campaign issue for the Italian General Election held on 25 September\n2022. Politicians frequently use Twitter to communicate during political\ncampaigns, but bots often interfere and attempt to manipulate elections. Hence,\nunderstanding whether bots influenced public opinion regarding the conflict\nand, therefore, the elections is essential.\n  In this work, we investigate how Italian politics responded to the\nRusso-Ukrainian conflict on Twitter and whether bots manipulated public opinion\nbefore the 2022 general election. We first analyze 39,611 tweets of six major\npolitical Italian parties to understand how they discussed the war during the\nperiod February-December 2022. Then, we focus on the 360,823 comments under the\nlast month's posts before the elections, discovering around 12% of the\ncommenters are bots. By examining their activities, it becomes clear they both\ndistorted how war topics were treated and influenced real users during the last\nmonth before the elections.",
        "translated": "2022年2月，俄罗斯对乌克兰发动了全面入侵。这一事件对全球产生了影响，尤其是对欧洲国家的政治决策产生了影响。正如所料，意大利在冲突中的作用成为2022年9月25日举行的意大利大选的一个主要竞选议题。政客们经常在政治竞选期间使用 Twitter 进行交流，但是机器人经常干扰并试图操纵选举。因此，了解机器人是否影响了关于冲突的公众舆论，因此，选举是至关重要的。在这项研究中，我们调查了意大利政界是如何在 Twitter 上回应俄罗斯与乌克兰的冲突，以及机器人是否在2022年大选前操纵了公众舆论。我们首先分析了意大利六个主要政党的39611条推文，以了解他们在2022年2月至12月期间是如何讨论这场战争的。然后，我们关注选举前一个月帖子下的360,823条评论，发现大约12% 的评论者是机器人。通过检查他们的活动，可以清楚地看到，在选举前的最后一个月，他们都歪曲了战争话题的处理方式，并对真正的用户产生了影响。"
    },
    {
        "title": "Frequency-Based Vulnerability Analysis of Deep Learning Models against\n  Image Corruptions",
        "url": "http://arxiv.org/abs/2306.07178v1",
        "pub_date": "2023-06-12",
        "summary": "Deep learning models often face challenges when handling real-world image\ncorruptions. In response, researchers have developed image corruption datasets\nto evaluate the performance of deep neural networks in handling such\ncorruptions. However, these datasets have a significant limitation: they do not\naccount for all corruptions encountered in real-life scenarios. To address this\ngap, we present MUFIA (Multiplicative Filter Attack), an algorithm designed to\nidentify the specific types of corruptions that can cause models to fail. Our\nalgorithm identifies the combination of image frequency components that render\na model susceptible to misclassification while preserving the semantic\nsimilarity to the original image. We find that even state-of-the-art models\ntrained to be robust against known common corruptions struggle against the low\nvisibility-based corruptions crafted by MUFIA. This highlights the need for\nmore comprehensive approaches to enhance model robustness against a wider range\nof real-world image corruptions.",
        "translated": "深度学习模型在处理真实世界的图像损坏时经常面临挑战。作为回应，研究人员已经开发了图像腐败数据集，以评估深层神经网络在处理此类腐败方面的性能。但是，这些数据集有一个显著的局限性: 它们不能解释在实际场景中遇到的所有损坏。为了弥补这一差距，我们提出了 MUFIA (乘法过滤攻击) ，一种用于识别可能导致模型失败的特定类型的损坏的算法。该算法在保持原始图像语义相似性的同时，识别出使模型容易错误分类的图像频率分量的组合。我们发现，即使是最先进的模型，训练有素的强大反对已知的普通腐败斗争低可见度为基础的腐败由 MUFIA 精心设计。这突出表明，需要采取更加全面的办法，提高模型对更广泛的现实世界图像损坏的稳健性。"
    },
    {
        "title": "On building machine learning pipelines for Android malware detection: a\n  procedural survey of practices, challenges and opportunities",
        "url": "http://arxiv.org/abs/2306.07118v1",
        "pub_date": "2023-06-12",
        "summary": "As the smartphone market leader, Android has been a prominent target for\nmalware attacks. The number of malicious applications (apps) identified for it\nhas increased continually over the past decade, creating an immense challenge\nfor all parties involved. For market holders and researchers, in particular,\nthe large number of samples has made manual malware detection unfeasible,\nleading to an influx of research that investigate Machine Learning (ML)\napproaches to automate this process. However, while some of the proposed\napproaches achieve high performance, rapidly evolving Android malware has made\nthem unable to maintain their accuracy over time. This has created a need in\nthe community to conduct further research, and build more flexible ML\npipelines. Doing so, however, is currently hindered by a lack of systematic\noverview of the existing literature, to learn from and improve upon the\nexisting solutions. Existing survey papers often focus only on parts of the ML\nprocess (e.g., data collection or model deployment), while omitting other\nimportant stages, such as model evaluation and explanation. In this paper, we\naddress this problem with a review of 42 highly-cited papers, spanning a decade\nof research (from 2011 to 2021). We introduce a novel procedural taxonomy of\nthe published literature, covering how they have used ML algorithms, what\nfeatures they have engineered, which dimensionality reduction techniques they\nhave employed, what datasets they have employed for training, and what their\nevaluation and explanation strategies are. Drawing from this taxonomy, we also\nidentify gaps in knowledge and provide ideas for improvement and future work.",
        "translated": "作为智能手机市场的领导者，Android 一直是恶意软件攻击的主要目标。在过去的十年中，恶意应用程序的数量不断增加，给相关各方带来了巨大的挑战。特别是对于市场持有者和研究人员来说，大量的样本使得人工检测恶意软件变得不可行，导致了大量研究的涌入，这些研究调查机器学习(ML)方法来自动化这一过程。然而，虽然一些提议的方法取得了很高的性能，快速发展的安卓恶意软件已经使他们无法随着时间的推移保持他们的准确性。这就需要社区进行进一步的研究，建立更加灵活的机器学习管道。然而，由于缺乏对现有文献的系统性概述，以便从现有解决方案中学习和改进，目前这样做受到了阻碍。现有的调查论文往往只关注机器学习过程的一部分(如数据收集或模型部署) ，而忽略了其他重要阶段，如模型评估和解释。在这篇论文中，我们回顾了42篇被高度引用的论文，跨越了十年的研究(从2011年到2021年)来解决这个问题。我们介绍了一个新的已发表文献的程序分类，包括他们如何使用机器学习算法，他们设计了哪些特性，他们使用了哪些降维技术，他们使用了哪些数据集进行培训，以及他们的评估和解释策略是什么。从这个分类法中，我们还确定了知识中的差距，并提供了改进和未来工作的想法。"
    },
    {
        "title": "Residual-Based Detection of Attacks in Cyber-Physical Inverter-Based\n  Microgrids",
        "url": "http://arxiv.org/abs/2306.07082v1",
        "pub_date": "2023-06-12",
        "summary": "This paper discusses the challenges faced by cyber-physical microgrids (MGs)\ndue to the inclusion of information and communication technologies in their\nalready complex, multi-layered systems. The work identifies a research gap in\nmodeling and analyzing stealthy intermittent integrity attacks in MGs, which\nare designed to maximize damage and cancel secondary control objectives. To\naddress this, the paper proposes a nonlinear residual-based observer approach\nto detect and mitigate such attacks. In order to ensure a stable operation of\nthe MG, the formulation then incorporates stability constraints along with the\ndetection observer. The proposed design is validated through case studies on a\nMG benchmark with four distributed generators, demonstrating its effectiveness\nin detecting attacks while satisfying network and stability constraints.",
        "translated": "本文讨论了网络物理微网(MG)所面临的挑战，这些挑战是由于将信息和通信技术纳入其已经复杂的多层次系统。这项工作确定了在建模和分析隐形间歇完整性攻击的研究差距，这是设计最大限度地损害和取消二次控制目标。为了解决这个问题，本文提出了一种基于非线性残差的观测器方法来检测和减轻这种攻击。为了确保 MG 的稳定运行，该公式随后将稳定性约束与检测观测器结合在一起。通过对一个具有四个分布式发生器的 MG 基准的实例研究，验证了该设计在满足网络和稳定性约束的情况下，在检测攻击方面的有效性。"
    },
    {
        "title": "When Vision Fails: Text Attacks Against ViT and OCR",
        "url": "http://arxiv.org/abs/2306.07033v1",
        "pub_date": "2023-06-12",
        "summary": "While text-based machine learning models that operate on visual inputs of\nrendered text have become robust against a wide range of existing attacks, we\nshow that they are still vulnerable to visual adversarial examples encoded as\ntext. We use the Unicode functionality of combining diacritical marks to\nmanipulate encoded text so that small visual perturbations appear when the text\nis rendered. We show how a genetic algorithm can be used to generate visual\nadversarial examples in a black-box setting, and conduct a user study to\nestablish that the model-fooling adversarial examples do not affect human\ncomprehension. We demonstrate the effectiveness of these attacks in the real\nworld by creating adversarial examples against production models published by\nFacebook, Microsoft, IBM, and Google.",
        "translated": "虽然基于文本的机器学习模型对渲染文本的视觉输入进行操作，已经变得对现有的广泛的攻击具有鲁棒性，但是我们表明，它们仍然容易受到编码为文本的视觉对手示例的攻击。我们使用 Unicode 功能组合发音标记来操作编码文本，以便在呈现文本时出现小的视觉扰动。我们展示了如何使用遗传算法在黑盒设置中生成可视化对手例子，并进行了用户研究，以确定欺骗模型的对手例子不影响人类的理解。我们通过创建针对 Facebook、微软、 IBM 和谷歌发布的生产模型的对抗性示例，来展示这些攻击在现实世界中的有效性。"
    },
    {
        "title": "AI-Generated Image Detection using a Cross-Attention Enhanced\n  Dual-Stream Network",
        "url": "http://arxiv.org/abs/2306.07005v1",
        "pub_date": "2023-06-12",
        "summary": "With the rapid evolution of AI Generated Content (AIGC), forged images\nproduced through this technology are inherently more deceptive and require less\nhuman intervention compared to traditional Computer-generated Graphics (CG).\nHowever, owing to the disparities between CG and AIGC, conventional CG\ndetection methods tend to be inadequate in identifying AIGC-produced images. To\naddress this issue, our research concentrates on the text-to-image generation\nprocess in AIGC. Initially, we first assemble two text-to-image databases\nutilizing two distinct AI systems, DALLE2 and DreamStudio. Aiming to\nholistically capture the inherent anomalies produced by AIGC, we develope a\nrobust dual-stream network comprised of a residual stream and a content stream.\nThe former employs the Spatial Rich Model (SRM) to meticulously extract various\ntexture information from images, while the latter seeks to capture additional\nforged traces in low frequency, thereby extracting complementary information\nthat the residual stream may overlook. To enhance the information exchange\nbetween these two streams, we incorporate a cross multi-head attention\nmechanism. Numerous comparative experiments are performed on both databases,\nand the results show that our detection method consistently outperforms\ntraditional CG detection techniques across a range of image resolutions.\nMoreover, our method exhibits superior performance through a series of\nrobustness tests and cross-database experiments. When applied to widely\nrecognized traditional CG benchmarks such as SPL2018 and DsTok, our approach\nsignificantly exceeds the capabilities of other existing methods in the field\nof CG detection.",
        "translated": "随着人工智能生成内容(AIGC)的快速发展，与传统的计算机生成图形(CG)相比，通过这种技术生成的伪造图像本质上更具有欺骗性，需要的人工干预也更少。然而，由于 CG 和 AIGC 之间的差异，传统的 CG 检测方法往往不足以识别 AIGC 产生的图像。为了解决这个问题，我们的研究集中在 AIGC 中的文本到图像的生成过程。最初，我们首先利用两个不同的 AI 系统 DALLE2和 DreamStudio 组装两个文本到图像的数据库。为了全面地捕获 AIGC 产生的固有异常，我们开发了一个由剩余流和内容流组成的鲁棒双流网络。前者采用空间富集模型(SRM)精细地从图像中提取各种纹理信息，后者则寻求在低频下捕获额外的伪迹，从而提取残留流可能忽略的互补信息。为了加强这两个流之间的信息交换，我们引入了一个交叉的多头注意机制。在这两个数据库上进行了大量的对比实验，结果表明我们的检测方法在一定的图像分辨率范围内始终优于传统的 CG 检测技术。此外，通过一系列的鲁棒性测试和跨数据库实验，我们的方法表现出了优越的性能。当应用于广泛公认的传统 CG 基准，如 SPL2018和 DsTok，我们的方法显着超过了其他现有的方法在 CG 检测领域的能力。"
    },
    {
        "title": "SecOComp: A Fast and Secure Simultaneous Compression and Encryption\n  Scheme",
        "url": "http://arxiv.org/abs/2306.06949v1",
        "pub_date": "2023-06-12",
        "summary": "We live in a data-driven era that involves the generation, collection and\nprocessing of a massive amount of data. This data often contains valuable\nintellectual property and sensitive user information that must be safeguarded.\nThere is a need to both encrypt and compress the data at line speed and\nsometimes with added power constraints. The majority of the currently available\nsimultaneous compression and encryption (SCE) schemes are tailored for a\nspecific type of data such as images for instance. This reduces their generic\napplicability. In this paper, we tackle this issue and propose a generic,\nefficient, and secure simultaneous compression and encryption scheme where the\ndata is simultaneously encrypted using chaotic maps and compressed using a fast\nlossless compression algorithm. We claim that employing multiple chaotic maps\nand a lossless compression method can help us create not only an efficient\nencryption scheme but also compress the data efficiently in a hardware-friendly\nmanner. We avoid all the known pitfalls of chaos theory based encryption that\nhave prevented its widespread usage. Our algorithm passes all the NIST tests\nfor nine different types of popular datasets. The proposed implementation uses\n1.51x less storage as compared to the nearest computing work.",
        "translated": "我们生活在一个数据驱动的时代，其中涉及到大量数据的生成、收集和处理。这些数据通常包含有价值的知识产权和必须加以保护的敏感用户信息。需要以线速对数据进行加密和压缩，有时还需要附加功耗约束。当前可用的大多数同时压缩和加密(SCE)方案都是为特定类型的数据(例如图像)量身定制的。这降低了它们的通用适用性。在本文中，我们解决了这个问题，并提出了一个通用的，高效的，安全的同时压缩和加密方案，其中数据同时加密使用混沌映射和压缩使用快速无损数据压缩算法。我们声称，使用多个混沌映射和一个无损数据压缩方法，不仅可以帮助我们创建一个有效的加密方案，而且还可以有效地压缩数据，以一种硬件友好的方式。我们避免了所有已知的基于混沌理论的加密陷阱，这些陷阱阻碍了它的广泛应用。我们的算法通过了九种不同类型的流行数据集的所有 NIST 测试。与最接近的计算工作相比，建议的实现使用的存储空间少了1.51倍。"
    },
    {
        "title": "Continual Release of Differentially Private Synthetic Data",
        "url": "http://arxiv.org/abs/2306.07884v1",
        "pub_date": "2023-06-13",
        "summary": "Motivated by privacy concerns in long-term longitudinal studies in medical\nand social science research, we study the problem of continually releasing\ndifferentially private synthetic data. We introduce a model where, in every\ntime step, each individual reports a new data element, and the goal of the\nsynthesizer is to incrementally update a synthetic dataset to capture a rich\nclass of statistical properties. We give continual synthetic data generation\nalgorithms that preserve two basic types of queries: fixed time window queries\nand cumulative time queries. We show nearly tight upper bounds on the error\nrates of these algorithms and demonstrate their empirical performance on\nrealistically sized datasets from the U.S. Census Bureau's Survey of Income and\nProgram Participation.",
        "translated": "基于医学和社会科学研究中长期纵向研究中对隐私的关注，我们研究了不断发布差异化私人合成数据的问题。我们引入一个模型，在每个时间步骤中，每个个体报告一个新的数据元素，合成器的目标是增量更新合成数据集以捕获丰富的统计特性类。我们给出了连续的合成数据生成算法，它保留了两种基本类型的查询: 固定时间窗口查询和累积时间查询。我们在这些算法的错误率上显示了近乎严格的上限，并且在美国人口普查局的收入和项目参与调查的实际大小的数据集上展示了它们的经验性能。"
    },
    {
        "title": "Temporal Gradient Inversion Attacks with Robust Optimization",
        "url": "http://arxiv.org/abs/2306.07883v1",
        "pub_date": "2023-06-13",
        "summary": "Federated Learning (FL) has emerged as a promising approach for collaborative\nmodel training without sharing private data. However, privacy concerns\nregarding information exchanged during FL have received significant research\nattention. Gradient Inversion Attacks (GIAs) have been proposed to reconstruct\nthe private data retained by local clients from the exchanged gradients. While\nrecovering private data, the data dimensions and the model complexity increase,\nwhich thwart data reconstruction by GIAs. Existing methods adopt prior\nknowledge about private data to overcome those challenges. In this paper, we\nfirst observe that GIAs with gradients from a single iteration fail to\nreconstruct private data due to insufficient dimensions of leaked gradients,\ncomplex model architectures, and invalid gradient information. We investigate a\nTemporal Gradient Inversion Attack with a Robust Optimization framework, called\nTGIAs-RO, which recovers private data without any prior knowledge by leveraging\nmultiple temporal gradients. To eliminate the negative impacts of outliers,\ne.g., invalid gradients for collaborative optimization, robust statistics are\nproposed. Theoretical guarantees on the recovery performance and robustness of\nTGIAs-RO against invalid gradients are also provided. Extensive empirical\nresults on MNIST, CIFAR10, ImageNet and Reuters 21578 datasets show that the\nproposed TGIAs-RO with 10 temporal gradients improves reconstruction\nperformance compared to state-of-the-art methods, even for large batch sizes\n(up to 128), complex models like ResNet18, and large datasets like ImageNet\n(224*224 pixels). Furthermore, the proposed attack method inspires further\nexploration of privacy-preserving methods in the context of FL.",
        "translated": "联邦学习(FL)已经成为一种不需要共享私有数据的协同模型训练的有前途的方法。然而，关于外语学习期间信息交流的隐私问题已经引起了研究者的重视。梯度反转攻击(GIA)已被提出用于重构本地客户端从交换的梯度中保留的私有数据。在恢复私有数据时，数据维数和模型复杂度增加，阻碍了 GIA 的数据重构。现有方法采用对私有数据的事先了解来克服这些挑战。在本文中，我们首先观察到，由于泄漏的梯度维数不足，模型结构复杂，梯度信息无效，单次迭代的梯度 GIA 无法重建私有数据。我们研究了一种具有鲁棒优化框架的时间梯度反演攻击，称为 TGIA-RO，它通过利用多个时间梯度在没有任何先验知识的情况下恢复私有数据。为了消除离群值的负面影响，例如协作优化的无效梯度，提出了稳健统计。理论上保证了 TGIA-RO 对无效梯度的恢复性能和鲁棒性。对 MNIST，CIFAR10，ImageNet 和 Reuters 21578数据集的广泛实证结果表明，与最先进的方法相比，提出的具有10个时间梯度的 TGIA-RO 改善了重建性能，即使对于大批量(高达128) ，复杂模型如 ResNet18和大数据集如 ImageNet (224 * 224像素)。此外，本文提出的攻击方法对 FL 环境下的隐私保护方法的进一步研究具有启发意义。"
    },
    {
        "title": "Finite Gaussian Neurons: Defending against adversarial attacks by making\n  neural networks say \"I don't know\"",
        "url": "http://arxiv.org/abs/2306.07796v1",
        "pub_date": "2023-06-13",
        "summary": "Since 2014, artificial neural networks have been known to be vulnerable to\nadversarial attacks, which can fool the network into producing wrong or\nnonsensical outputs by making humanly imperceptible alterations to inputs.\nWhile defenses against adversarial attacks have been proposed, they usually\ninvolve retraining a new neural network from scratch, a costly task. In this\nwork, I introduce the Finite Gaussian Neuron (FGN), a novel neuron architecture\nfor artificial neural networks. My works aims to: - easily convert existing\nmodels to Finite Gaussian Neuron architecture, - while preserving the existing\nmodel's behavior on real data, - and offering resistance against adversarial\nattacks. I show that converted and retrained Finite Gaussian Neural Networks\n(FGNN) always have lower confidence (i.e., are not overconfident) in their\npredictions over randomized and Fast Gradient Sign Method adversarial images\nwhen compared to classical neural networks, while maintaining high accuracy and\nconfidence over real MNIST images. To further validate the capacity of Finite\nGaussian Neurons to protect from adversarial attacks, I compare the behavior of\nFGNs to that of Bayesian Neural Networks against both randomized and\nadversarial images, and show how the behavior of the two architectures differs.\nFinally I show some limitations of the FGN models by testing them on the more\ncomplex SPEECHCOMMANDS task, against the stronger Carlini-Wagner and Projected\nGradient Descent adversarial attacks.",
        "translated": "自2014年以来，人工神经网络已经被认为容易受到对抗性攻击，这种攻击可以通过对输入进行人类无法察觉的改变，欺骗网络产生错误或无意义的输出。虽然已经提出了对抗敌对攻击的防御措施，但它们通常涉及从零开始重新训练一个新的神经网络，这是一项代价高昂的任务。在这项工作中，我介绍了有限高斯神经元(FGN) ，一种新的神经元架构的人工神经网络。我的工作目标是:-轻松地将现有模型转换为有限高斯神经元结构,-同时保留现有模型在真实数据上的行为,-并提供对抗敌对攻击的能力。我指出，转换和再训练的有限高斯神经网络(FGNN)总是对随机和快速梯度符号方法对抗性图像的预测有较低的置信度(即，不过度自信) ，与经典的神经网络相比，同时保持高精度和置信度的真实 MNIST 图像。为了进一步验证有限高斯神经元抵御敌对攻击的能力，我比较了 FGNs 和贝叶斯神经网络对随机和敌对图像的行为，并展示了这两种结构的行为是如何不同的。最后，我通过在更复杂的 SPEECHCOMMANDS 任务上测试 FGN 模型，以对抗更强大的卡里尼-瓦格纳(Carlini-Wagner)和投影式梯度下降法对抗攻击，展示了它们的一些局限性。"
    },
    {
        "title": "SafeBet: Secure, Simple, and Fast Speculative Execution",
        "url": "http://arxiv.org/abs/2306.07785v1",
        "pub_date": "2023-06-13",
        "summary": "Spectre attacks exploit microprocessor speculative execution to read and\ntransmit forbidden data outside the attacker's trust domain and sandbox. Recent\nhardware schemes allow potentially-unsafe speculative accesses but prevent the\nsecret's transmission by delaying most access-dependent instructions even in\nthe predominantly-common, no-attack case, which incurs performance loss and\nhardware complexity. Instead, we propose SafeBet which allows only, and does\nnot delay most, safe accesses, achieving both security and high performance.\nSafeBet is based on the key observation that speculatively accessing a\ndestination location is safe if the location's access by the same static trust\ndomain has been committed previously; and potentially unsafe, otherwise. We\nextend this observation to handle inter trust-domain code and data\ninteractions. SafeBet employs the Speculative Memory Access Control Table\n(SMACT) to track non-speculative trust domain code region-destination pairs.\nDisallowed accesses wait until reaching commit to trigger well-known replay,\nwith virtually no change to the pipeline. Software simulations using SpecCPU\nbenchmarks show that SafeBet uses an 8.3-KB SMACT per core to perform within 6%\non average (63% at worst) of the unsafe baseline behind which NDA-restrictive,\na previous scheme of security and hardware complexity comparable to SafeBet's,\nlags by 83% on average.",
        "translated": "Spectre 攻击利用微处理器 Speculative_execution 在攻击者的信任域和沙盒之外读取和传输被禁止的数据。最近的硬件方案允许潜在的不安全的推测性访问，但是通过延迟大多数访问依赖的指令来阻止秘密的传输，即使在主要通用的、无攻击的情况下，这会导致性能损失和硬件复杂性。相反，我们建议安全打赌，只允许，而不延迟大多数，安全访问，实现安全和高性能。SafeBett 基于以下关键观察: 如果目标位置的访问以前已经通过相同的静态信任域提交，那么以投机方式访问该位置是安全的; 否则可能是不安全的。我们将这种观察扩展到处理信任域之间的代码和数据交互。SafeBet 使用推测内存访问控制表(SMACT)跟踪非推测信任域代码区域-目标对。不允许的访问要等到达到提交时才触发众所周知的重播，实际上不需要对管道进行任何更改。使用 SpecCPU 基准测试的软件模拟显示，SafeBet 每个核心使用8.3 KB 的 SMACT，平均在不安全基准的6% (最差为63%)之内执行。在这个基准之后，以前的安全和硬件复杂度与 SafeBet 相当的 NDA 限制方案平均落后83% 。"
    },
    {
        "title": "Area is all you need: repeatable elements make stronger adversarial\n  attacks",
        "url": "http://arxiv.org/abs/2306.07768v1",
        "pub_date": "2023-06-13",
        "summary": "Over the last decade, deep neural networks have achieved state of the art in\ncomputer vision tasks. These models, however, are susceptible to unusual\ninputs, known as adversarial examples, that cause them to misclassify or\notherwise fail to detect objects. Here, we provide evidence that the increasing\nsuccess of adversarial attacks is primarily due to increasing their size. We\nthen demonstrate a method for generating the largest possible adversarial patch\nby building a adversarial pattern out of repeatable elements. This approach\nachieves a new state of the art in evading detection by YOLOv2 and YOLOv3.\nFinally, we present an experiment that fails to replicate the prior success of\nseveral attacks published in this field, and end with some comments on testing\nand reproducibility.",
        "translated": "在过去的十年中，深度神经网络在计算机视觉任务中取得了最先进的技术。然而，这些模型容易受到不寻常的输入(称为对抗性示例)的影响，这些输入会导致模型错误分类或无法检测到对象。在这里，我们提供的证据表明，越来越成功的对抗性攻击主要是由于增加了他们的规模。然后，我们演示了一种方法，通过用可重复的元素构建一个对抗模式来生成尽可能大的对抗补丁。这种方法在躲避 YOLOv2和 YOLOv3的检测方面达到了一种新的技术水平。最后，我们提出了一个实验，未能复制在这个领域发表的几个攻击的先前的成功，并以一些测试和重现性的意见结束。"
    },
    {
        "title": "Generated Graph Detection",
        "url": "http://arxiv.org/abs/2306.07758v1",
        "pub_date": "2023-06-13",
        "summary": "Graph generative models become increasingly effective for data distribution\napproximation and data augmentation. While they have aroused public concerns\nabout their malicious misuses or misinformation broadcasts, just as what\nDeepfake visual and auditory media has been delivering to society. Hence it is\nessential to regulate the prevalence of generated graphs. To tackle this\nproblem, we pioneer the formulation of the generated graph detection problem to\ndistinguish generated graphs from real ones. We propose the first framework to\nsystematically investigate a set of sophisticated models and their performance\nin four classification scenarios. Each scenario switches between seen and\nunseen datasets/generators during testing to get closer to real-world settings\nand progressively challenge the classifiers. Extensive experiments evidence\nthat all the models are qualified for generated graph detection, with specific\nmodels having advantages in specific scenarios. Resulting from the validated\ngenerality and oblivion of the classifiers to unseen datasets/generators, we\ndraw a safe conclusion that our solution can sustain for a decent while to curb\ngenerated graph misuses.",
        "translated": "图生成模型在数据分布逼近和数据增强方面的应用越来越广泛。尽管它们引起了公众对其恶意滥用或错误信息广播的担忧，正如 Deepfalse 视听媒体向社会传递的信息一样。因此，规范生成图的流行是非常必要的。为了解决这个问题，我们首先提出了生成图检测问题的公式，以区分生成的图和真实的图。我们提出了第一个框架，系统地研究了一组复杂的模型及其在四种分类情景下的性能。每个场景在测试期间在可见和不可见的数据集/生成器之间切换，以更接近真实世界的设置并逐步挑战分类器。广泛的实验证明，所有的模型都有资格生成的图检测，具体的模型有优势，在特定的情况下。通过验证分类器对未知数据集/生成器的通用性和遗忘性，我们得出了一个安全的结论，即我们的解决方案可以维持一段时间，以遏制生成的图的误用。"
    },
    {
        "title": "Generative Watermarking Against Unauthorized Subject-Driven Image\n  Synthesis",
        "url": "http://arxiv.org/abs/2306.07754v1",
        "pub_date": "2023-06-13",
        "summary": "Large text-to-image models have shown remarkable performance in synthesizing\nhigh-quality images. In particular, the subject-driven model makes it possible\nto personalize the image synthesis for a specific subject, e.g., a human face\nor an artistic style, by fine-tuning the generic text-to-image model with a few\nimages from that subject. Nevertheless, misuse of subject-driven image\nsynthesis may violate the authority of subject owners. For example, malicious\nusers may use subject-driven synthesis to mimic specific artistic styles or to\ncreate fake facial images without authorization. To protect subject owners\nagainst such misuse, recent attempts have commonly relied on adversarial\nexamples to indiscriminately disrupt subject-driven image synthesis. However,\nthis essentially prevents any benign use of subject-driven synthesis based on\nprotected images.\n  In this paper, we take a different angle and aim at protection without\nsacrificing the utility of protected images for general synthesis purposes.\nSpecifically, we propose GenWatermark, a novel watermark system based on\njointly learning a watermark generator and a detector. In particular, to help\nthe watermark survive the subject-driven synthesis, we incorporate the\nsynthesis process in learning GenWatermark by fine-tuning the detector with\nsynthesized images for a specific subject. This operation is shown to largely\nimprove the watermark detection accuracy and also ensure the uniqueness of the\nwatermark for each individual subject. Extensive experiments validate the\neffectiveness of GenWatermark, especially in practical scenarios with unknown\nmodels and text prompts (74% Acc.), as well as partial data watermarking (80%\nAcc. for 1/4 watermarking). We also demonstrate the robustness of GenWatermark\nto two potential countermeasures that substantially degrade the synthesis\nquality.",
        "translated": "大型文本-图像模型在合成高质量图像方面表现出显著的性能。具体来说，主题驱动模型可以通过微调一般的文本到图像模型和一些来自该主题的图像，为特定主题(如人脸或艺术风格)进行个性化的图像合成。然而，误用主题驱动的图像合成可能会违反主题所有者的权威。例如，恶意用户可能使用主题驱动的合成来模仿特定的艺术风格或未经授权创建假面部图像。为了保护主题所有者免受这种滥用，最近的尝试通常依赖于对抗性的例子来不加区分地破坏主题驱动的图像合成。然而，这基本上阻止了任何良性使用主题驱动的合成基于受保护的图像。本文从不同的角度出发，在不牺牲图像保护效用的前提下，对图像进行综合保护。具体地说，我们提出了一种基于水印生成器和检测器联合学习的新型水印系统——基因水印。特别地，为了使水印在主题驱动的合成中存活下来，我们将合成过程融入到学习基因水印的过程中，通过对特定主题的合成图像的检测器进行微调来实现水印的学习。实验结果表明，该方法不仅大大提高了水印检测的准确性，而且保证了每个水印对象的唯一性。广泛的实验验证了基因水印的有效性，特别是在未知模型和文本提示的实际场景中(74% Acc。)，以及部分数据水印(80% 。1/4水印)。我们还证明了基因水印对两种潜在的对策的鲁棒性，这两种对策大大降低了合成质量。"
    },
    {
        "title": "An Inverse Approach to Windows' Resource-Based Permission Mechanism for\n  Access Permission Vulnerability Detection",
        "url": "http://arxiv.org/abs/2306.07734v1",
        "pub_date": "2023-06-13",
        "summary": "In organizations, employees work with information stored in files according\nto their duties and responsibilities. Windows uses resource-based access\npermissions that any permission for any user has to be set separately per\nresource. This approach gets complicated as the number of resources and users\nincrease, and causes oversights in assigning permissions. Therefore, a special\nmechanism is required to scrutinize what permissions any employee has on any\nset of resources. This requirement is circumvented by reversing the Windows\napproach in terms of user-accessible resources. This approach is implemented by\na program allowing quick and easy examination of any type of permissions\ngranted or denied to active directory users on any folder. In this way,\nadministrators can make sure there is no any missing or overlooked setting that\ncould cause a security vulnerability. This approach can easily be extended to\nscrutinize other resources, and for other local or active directory objects.",
        "translated": "在组织中，员工根据他们的职责和责任使用存储在文件中的信息工作。Windows 使用基于资源的访问权限，任何用户的任何权限都必须在每个资源中单独设置。随着资源和用户数量的增加，这种方法会变得复杂，并导致在分配权限时出现疏忽。因此，需要一种特殊的机制来仔细检查任何员工对任何资源集拥有什么权限。通过在用户可访问资源方面逆转 Windows 方法，规避了这一要求。这种方法是通过一个程序实现的，该程序允许快速、方便地检查授予或拒绝给任何文件夹上的活动目录用户的任何类型的权限。通过这种方式，管理员可以确保不会遗漏或忽略任何可能导致安全漏洞的设置。可以很容易地扩展这种方法来检查其他资源以及其他本地或活动目录对象。"
    },
    {
        "title": "Theoretical Foundations of Adversarially Robust Learning",
        "url": "http://arxiv.org/abs/2306.07723v1",
        "pub_date": "2023-06-13",
        "summary": "Despite extraordinary progress, current machine learning systems have been\nshown to be brittle against adversarial examples: seemingly innocuous but\ncarefully crafted perturbations of test examples that cause machine learning\npredictors to misclassify. Can we learn predictors robust to adversarial\nexamples? and how? There has been much empirical interest in this contemporary\nchallenge in machine learning, and in this thesis, we address it from a\ntheoretical perspective.\n  In this thesis, we explore what robustness properties can we hope to\nguarantee against adversarial examples and develop an understanding of how to\nalgorithmically guarantee them. We illustrate the need to go beyond traditional\napproaches and principles such as empirical risk minimization and uniform\nconvergence, and make contributions that can be categorized as follows: (1)\nintroducing problem formulations capturing aspects of emerging practical\nchallenges in robust learning, (2) designing new learning algorithms with\nprovable robustness guarantees, and (3) characterizing the complexity of robust\nlearning and fundamental limitations on the performance of any algorithm.",
        "translated": "尽管取得了非凡的进步，但是目前的机器学习系统已经被证明对于敌对的例子是脆弱的: 看似无害但是精心设计的测试例子扰动，导致机器学习预测错误分类。我们可以学习预测健壮的对抗性的例子？怎么做到的？当代机器学习面临的挑战已经引起了很多实证研究者的兴趣，在本文中，我们将从理论的角度来探讨这个问题。在这篇论文中，我们探讨了哪些鲁棒性特性可以在对抗性例子中得到保证，并且发展了如何通过算法来保证它们的理解。我们说明需要超越传统的方法和原则，如经验风险最小化和一致收敛，并作出贡献，可以分类如下: (1)引入问题公式捕捉方面的新兴实际挑战的鲁棒性学习，(2)设计新的学习算法与可证明的鲁棒性保证，(3)表征鲁棒性学习的复杂性和任何算法的性能的基本限制。"
    },
    {
        "title": "Public-Key Encryption with Quantum Keys",
        "url": "http://arxiv.org/abs/2306.07698v1",
        "pub_date": "2023-06-13",
        "summary": "In the framework of Impagliazzo's five worlds, a distinction is often made\nbetween two worlds, one where public-key encryption exists (Cryptomania), and\none in which only one-way functions exist (MiniCrypt). However, the boundaries\nbetween these worlds can change when quantum information is taken into account.\nRecent work has shown that quantum variants of oblivious transfer and\nmulti-party computation, both primitives that are classically in Cryptomania,\ncan be constructed from one-way functions, placing them in the realm of quantum\nMiniCrypt (the so-called MiniQCrypt). This naturally raises the following\nquestion: Is it possible to construct a quantum variant of public-key\nencryption, which is at the heart of Cryptomania, from one-way functions or\npotentially weaker assumptions?\n  In this work, we initiate the formal study of the notion of quantum\npublic-key encryption (qPKE), i.e., public-key encryption where keys are\nallowed to be quantum states. We propose new definitions of security and\nseveral constructions of qPKE based on the existence of one-way functions\n(OWF), or even weaker assumptions, such as pseudorandom function-like states\n(PRFS) and pseudorandom function-like states with proof of destruction\n(PRFSPD). Finally, to give a tight characterization of this primitive, we show\nthat computational assumptions are necessary to build quantum public-key\nencryption. That is, we give a self-contained proof that no quantum public-key\nencryption scheme can provide information-theoretic security.",
        "translated": "在 Impagliazzo 的五个世界的框架中，经常有两个世界之间的区别，一个是存在公钥加密的世界(Cryptomania) ，另一个是只存在单向函数的世界(MiniCrypt)。然而，当量子信息被考虑在内时，这些世界之间的界限会发生变化。最近的研究表明，无意识传输和多方计算的量子变体(这两种原语在 Cryptomania 都是经典的)可以由单向函数构造出来，将它们置于量子 MiniCrypt (即所谓的 MiniqCrypt)领域。这自然引发了以下问题: 有没有可能根据单向函数或潜在较弱的假设，构建一种处于 Cryptomania 核心的公钥加密的量子变体？在这项工作中，我们开始了量子公钥加密(qPKE)概念的正式研究，即公钥加密，其中允许密钥是量子态。基于单向函数(OWF)的存在性，或者更弱的假设，如伪随机类函数状态(PRFS)和伪随机类函数状态(PRFSPD) ，我们提出了安全性的新定义和 qPKE 的几种构造。最后，为了给这个原语一个严密的角色塑造，我们展示了构建量子公钥加密所需的计算假设。也就是说，我们给出了一个独立的证据，证明没有任何量子公钥加密方案能够提供资讯理论安全性。"
    },
    {
        "title": "Inroads into Autonomous Network Defence using Explained Reinforcement\n  Learning",
        "url": "http://arxiv.org/abs/2306.09318v1",
        "pub_date": "2023-06-15",
        "summary": "Computer network defence is a complicated task that has necessitated a high\ndegree of human involvement. However, with recent advancements in machine\nlearning, fully autonomous network defence is becoming increasingly plausible.\nThis paper introduces an end-to-end methodology for studying attack strategies,\ndesigning defence agents and explaining their operation. First, using state\ndiagrams, we visualise adversarial behaviour to gain insight about potential\npoints of intervention and inform the design of our defensive models. We opt to\nuse a set of deep reinforcement learning agents trained on different parts of\nthe task and organised in a shallow hierarchy. Our evaluation shows that the\nresulting design achieves a substantial performance improvement compared to\nprior work. Finally, to better investigate the decision-making process of our\nagents, we complete our analysis with a feature ablation and importance study.",
        "translated": "计算机网络防御是一项复杂的任务，需要人的高度参与。然而，随着机器学习的最新进展，完全自主的网络防御正变得越来越合理。本文介绍了一种端到端的攻击策略研究方法，设计了防御代理，并对它们的操作进行了说明。首先，利用状态图，我们可视化的对抗行为，以获得洞察潜在的干预点，并通知我们的防御模型的设计。我们选择使用一组深度强化学习的代理人，这些代理人接受过不同任务部分的培训，并按照肤浅的等级制度组织起来。我们的评估表明，与以前的工作相比，最终的设计实现了实质性的性能改进。最后，为了更好地研究我们的智能体的决策过程，我们用特征消融和重要性研究来完成我们的分析。"
    },
    {
        "title": "Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.09308v1",
        "pub_date": "2023-06-15",
        "summary": "The wide applicability and adaptability of generative large language models\n(LLMs) has enabled their rapid adoption. While the pre-trained models can\nperform many tasks, such models are often fine-tuned to improve their\nperformance on various downstream applications. However, this leads to issues\nover violation of model licenses, model theft, and copyright infringement.\nMoreover, recent advances show that generative technology is capable of\nproducing harmful content which exacerbates the problems of accountability\nwithin model supply chains. Thus, we need a method to investigate how a model\nwas trained or a piece of text was generated and what their pre-trained base\nmodel was. In this paper we take the first step to address this open problem by\ntracing back the origin of a given fine-tuned LLM to its corresponding\npre-trained base model. We consider different knowledge levels and attribution\nstrategies, and find that we can correctly trace back 8 out of the 10 fine\ntuned models with our best method.",
        "translated": "生成式大型语言模型(LLM)的广泛适用性和适应性使它们得以迅速采用。虽然预先训练的模型可以执行许多任务，但这些模型通常经过微调，以提高它们在各种下游应用程序中的性能。然而，这导致了违反模型许可证、模型盗窃和盗版的问题。此外，最近的进展表明，生成技术能够产生有害的内容，这加剧了示范供应链中的问责问题。因此，我们需要一种方法来研究如何训练一个模型或一段文本生成，以及他们的预先训练的基础模型是什么。在本文中，我们采取的第一步，以解决这个开放的问题，追溯起源的一个给定的微调 LLM 相应的预训练的基础模型。我们考虑了不同的知识水平和归因策略，发现我们可以用我们最好的方法正确地追溯10个微调模型中的8个。"
    },
    {
        "title": "Your Room is not Private: Gradient Inversion Attack for Deep Q-Learning",
        "url": "http://arxiv.org/abs/2306.09273v1",
        "pub_date": "2023-06-15",
        "summary": "The prominence of embodied Artificial Intelligence (AI), which empowers\nrobots to navigate, perceive, and engage within virtual environments, has\nattracted significant attention, owing to the remarkable advancements in\ncomputer vision and large language models. Privacy emerges as a pivotal concern\nwithin the realm of embodied AI, as the robot access substantial personal\ninformation. However, the issue of privacy leakage in embodied AI tasks,\nparticularly in relation to decision-making algorithms, has not received\nadequate consideration in research. This paper aims to address this gap by\nproposing an attack on the Deep Q-Learning algorithm, utilizing gradient\ninversion to reconstruct states, actions, and Q-values. The choice of using\ngradients for the attack is motivated by the fact that commonly employed\nfederated learning techniques solely utilize gradients computed based on\nprivate user data to optimize models, without storing or transmitting the data\nto public servers. Nevertheless, these gradients contain sufficient information\nto potentially expose private data. To validate our approach, we conduct\nexperiments on the AI2THOR simulator and evaluate our algorithm on active\nperception, a prevalent task in embodied AI. The experimental results\nconvincingly demonstrate the effectiveness of our method in successfully\nrecovering all information from the data across all 120 room layouts.",
        "translated": "由于计算机视觉和大型语言模型的显著进步，具体化人工智能(AI)的突出地位，使机器人能够在虚拟环境中导航、感知和参与，引起了人们的广泛关注。隐私作为一个关键问题出现在具体的人工智能领域，因为机器人访问大量的个人信息。然而，具体人工智能任务中的隐私泄露问题，特别是决策算法方面的问题，在研究中还没有得到足够的重视。本文旨在通过对深度 Q 学习算法的攻击，利用梯度反演重建状态、动作和 Q 值来弥补这一缺陷。选择使用梯度进行攻击的动机是，通常采用的联邦学习技术只利用基于私有用户数据计算的梯度来优化模型，而不将数据存储或传输到公共服务器。不过，这些渐变包含足够的信息，可能会暴露私有数据。为了验证我们的方法，我们在 AI2THOR 模拟器上进行了实验，并且评估了我们的算法在主动感知上的效果。实验结果令人信服地证明了我们的方法在成功恢复所有120个房间布局数据的有效性。"
    },
    {
        "title": "Concealing CAN Message Sequences to Prevent Schedule-based Bus-off\n  Attacks",
        "url": "http://arxiv.org/abs/2306.09206v1",
        "pub_date": "2023-06-15",
        "summary": "This work focuses on eliminating timing-side channels in real-time\nsafety-critical cyber-physical network protocols like Controller Area Networks\n(CAN). Automotive Electronic Control Units (ECUs) implement predictable\nscheduling decisions based on task level response time estimation. Such levels\nof determinism exposes timing information about task executions and therefore\ncorresponding message transmissions via the network buses (that connect the\nECUs and actuators). With proper analysis, such timing side channels can be\nutilized to launch several schedule-based attacks that can lead to eventual\ndenial-of-service or man-in-the-middle-type attacks. To eliminate this\ndeterminism, we propose a novel schedule obfuscation strategy by skipping\ncertain control task executions and related data transmissions along with\nrandom shifting of the victim task instance. While doing this, our strategy\ncontemplates the performance of the control task as well by bounding the number\nof control execution skips. We analytically demonstrate how the attack success\nprobability (ASP) is reduced under this proposed attack-aware skipping and\nrandomization. We also demonstrate the efficacy and real-time applicability of\nour attack-aware schedule obfuscation strategy Hide-n-Seek by applying it to\nsynthesized automotive task sets in a real-time Hardware-in-loop (HIL) setup.",
        "translated": "这项工作的重点是消除实时安全性关键的网络物理协议，如控制器区域网络(CAN)的时间端通道。汽车电子控制单元(ECU)实现基于任务级响应时间估计的可预测调度决策。这种级别的确定性公开了关于任务执行的时间信息，因此通过网络总线(连接 ECU 和执行器)传输相应的消息。通过适当的分析，可以利用这种时间侧信道发动多种基于调度的攻击，最终导致拒绝服务或中间人攻击。为了消除这种确定性，我们提出了一种新的调度模糊策略，通过跳过某些控制任务的执行和相关的数据传输以及受害任务实例的随机移动。在这样做的同时，我们的策略还通过限制控制执行跳过的次数来考虑控制任务的性能。我们分析了攻击成功概率(ASP)是如何降低这种攻击感知跳跃和随机。通过将攻击感知调度模糊策略 Hide-n-Seek 应用于实时硬件在环(HIL)环境下的综合汽车任务集，验证了该策略的有效性和实时适用性。"
    },
    {
        "title": "High-Resolution Convolutional Neural Networks on Homomorphically\n  Encrypted Data via Sharding Ciphertexts",
        "url": "http://arxiv.org/abs/2306.09189v1",
        "pub_date": "2023-06-15",
        "summary": "Recently, Deep Convolutional Neural Networks (DCNNs) including the ResNet-20\narchitecture have been privately evaluated on encrypted, low-resolution data\nwith the Residue-Number-System Cheon-Kim-Kim-Song (RNS-CKKS) homomorphic\nencryption scheme. We extend methods for evaluating DCNNs on images with larger\ndimensions and many channels, beyond what can be stored in single ciphertexts.\nAdditionally, we simplify and improve the efficiency of the recently introduced\nmultiplexed image format, demonstrating that homomorphic evaluation can work\nwith standard, row-major matrix packing and results in encrypted inference time\nspeedups by $4.6-6.5\\times$. We also show how existing DCNN models can be\nregularized during the training process to further improve efficiency and\naccuracy. These techniques are applied to homomorphically evaluate a DCNN with\nhigh accuracy on the high-resolution ImageNet dataset for the first time,\nachieving $80.2\\%$ top-1 accuracy. We also achieve the highest reported\naccuracy of homomorphically evaluated CNNs on the CIFAR-10 dataset of $98.3\\%$.",
        "translated": "最近，包括 ResNet-20架构在内的深层卷积神经网络已经通过剩余数字系统 Cheon-Kim-Kim-Song (RNS-CKKS)同态加密方案在加密的低分辨率数据上进行了私人评估。我们扩展了评估大尺寸和多通道图像上的 DCNN 的方法，超出了能够存储在单个密文中的范围。此外，我们简化和提高了最近引入的多路复用图像格式的效率，证明了同态计算可以与标准的行主矩阵打包一起工作，并导致加密推理时间加速4.6 -6.5倍。我们还展示了如何在训练过程中规范现有的 DCNN 模型，以进一步提高效率和准确性。首次将这些技术应用于高分辨率 ImageNet 数据集上的 DCNN 同态评估，获得了80.2% 的最高精度。我们还在 CIFAR-10数据集上实现了同态评估的 CNN 的最高报告准确度为98.3% 。"
    },
    {
        "title": "DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks in\n  the Physical World",
        "url": "http://arxiv.org/abs/2306.09124v1",
        "pub_date": "2023-06-15",
        "summary": "Adversarial attacks in the physical world, particularly patch attacks, pose\nsignificant threats to the robustness and reliability of deep learning models.\nDeveloping reliable defenses against patch attacks is crucial for real-world\napplications, yet current research in this area is severely lacking. In this\npaper, we propose DIFFender, a novel defense method that leverages the\npre-trained diffusion model to perform both localization and defense against\npotential adversarial patch attacks. DIFFender is designed as a pipeline\nconsisting of two main stages: patch localization and restoration. In the\nlocalization stage, we exploit the intriguing properties of a diffusion model\nto effectively identify the locations of adversarial patches. In the\nrestoration stage, we employ a text-guided diffusion model to eliminate\nadversarial regions in the image while preserving the integrity of the visual\ncontent. Additionally, we design a few-shot prompt-tuning algorithm to\nfacilitate simple and efficient tuning, enabling the learned representations to\neasily transfer to downstream tasks, which optimize two stages jointly. We\nconduct extensive experiments on image classification and face recognition to\ndemonstrate that DIFFender exhibits superior robustness under strong adaptive\nattacks and generalizes well across various scenarios, diverse classifiers, and\nmultiple attack methods.",
        "translated": "物理世界中的对抗性攻击，特别是补丁攻击，对深度学习模型的健壮性和可靠性构成了严重威胁。开发针对补丁攻击的可靠防御对于真实世界的应用程序是至关重要的，然而目前在这个领域的研究严重缺乏。在本文中，我们提出了 DIFFender，一种新的防御方法，利用预先训练的扩散模型来执行定位和防御潜在的对手补丁攻击。DIFFender 被设计成一个由两个主要阶段组成的流水线: 补丁定位和恢复。在局部化阶段，我们利用扩散模型的有趣特性来有效地识别对抗性斑块的位置。在图像恢复阶段，我们采用文本引导的扩散模型来消除图像中的敌对区域，同时保持视觉内容的完整性。此外，我们还设计了一个小镜头提示调优算法，以方便简单而有效的调优，使学习的表示方法能够轻松地转移到下游任务，这样就可以联合优化两个阶段。我们在图像分类和人脸识别方面进行了广泛的实验，证明了 DIFFender 在强自适应攻击下具有优越的鲁棒性，并且能够很好地推广到各种场景、不同的分类器和多种攻击方法。"
    },
    {
        "title": "On Strengthening and Defending Graph Reconstruction Attack with Markov\n  Chain Approximation",
        "url": "http://arxiv.org/abs/2306.09104v1",
        "pub_date": "2023-06-15",
        "summary": "Although powerful graph neural networks (GNNs) have boosted numerous\nreal-world applications, the potential privacy risk is still underexplored. To\nclose this gap, we perform the first comprehensive study of graph\nreconstruction attack that aims to reconstruct the adjacency of nodes. We show\nthat a range of factors in GNNs can lead to the surprising leakage of private\nlinks. Especially by taking GNNs as a Markov chain and attacking GNNs via a\nflexible chain approximation, we systematically explore the underneath\nprinciples of graph reconstruction attack, and propose two information\ntheory-guided mechanisms: (1) the chain-based attack method with adaptive\ndesigns for extracting more private information; (2) the chain-based defense\nmethod that sharply reduces the attack fidelity with moderate accuracy loss.\nSuch two objectives disclose a critical belief that to recover better in\nattack, you must extract more multi-aspect knowledge from the trained GNN;\nwhile to learn safer for defense, you must forget more link-sensitive\ninformation in training GNNs. Empirically, we achieve state-of-the-art results\non six datasets and three common GNNs. The code is publicly available at:\nhttps://github.com/tmlr-group/MC-GRA.",
        "translated": "尽管强大的图形神经网络(GNN)已经推动了许多现实世界的应用，但是潜在的隐私风险仍然没有得到充分的开发。为了弥补这一差距，我们首次对图重建攻击进行了全面的研究，目的是重建节点的邻接。我们表明，在 GNN 的一系列因素可以导致令人惊讶的泄漏私人链路。特别是将 GNN 作为一个马尔可夫链，通过柔性链近似对 GNN 进行攻击，系统地探讨了图重构攻击的基本原理，提出了两种信息理论指导机制: (1)基于链的攻击方法，采用自适应设计提取更多的私有信息; (2)基于链的防御方法，大大降低了攻击保真度，但精度损失不大。这两个目标揭示了一个关键的信念，即为了更好地恢复攻击，您必须从训练过的 GNN 中提取更多的多方面知识; 而为了学习更安全的防御，您必须在训练 GNN 中忘记更多的链接敏感信息。根据经验，我们在六个数据集和三个常见的 GNN 上获得了最先进的结果。该守则可于以下 https://github.com/tmlr-group/mc-gra 公开索取:。"
    },
    {
        "title": "A Learning Assisted Method for Uncovering Power Grid Generation and\n  Distribution System Vulnerabilities",
        "url": "http://arxiv.org/abs/2306.09057v1",
        "pub_date": "2023-06-15",
        "summary": "Intelligent attackers can suitably tamper sensor/actuator data at various\nSmart grid surfaces causing intentional power oscillations, which if left\nundetected, can lead to voltage disruptions. We develop a novel combination of\nformal methods and machine learning tools that learns power system dynamics\nwith the objective of generating unsafe yet stealthy false data based attack\nsequences. We enable the grid with anomaly detectors in a generalized manner so\nthat it is difficult for an attacker to remain undetected. Our methodology,\nwhen applied on an IEEE 14 bus power grid model, uncovers stealthy attack\nvectors even in presence of such detectors.",
        "translated": "智能攻击者可以适当地篡改各种智能电网表面的传感器/执行器数据，造成故意的电源振荡，如果不加以检测，可能导致电压中断。我们开发了一个新的组合的形式方法和机器学习工具，学习电力系统动态的目标是生成不安全但隐秘的虚假数据为基础的攻击序列。我们以一种通用的方式启用带有异常检测器的网格，这样攻击者很难保持不被检测。我们的方法，当应用于 IEEE 14总线电网模型，揭示了即使存在这样的检测器隐形攻击矢量。"
    },
    {
        "title": "Who Let the Smart Toaster Hack the House? An Investigation into the\n  Security Vulnerabilities of Consumer IoT Devices",
        "url": "http://arxiv.org/abs/2306.09017v1",
        "pub_date": "2023-06-15",
        "summary": "For smart homes to be safe homes, they must be designed with security in\nmind. Yet, despite the widespread proliferation of connected digital\ntechnologies in the home environment, there is a lack of research evaluating\nthe security vulnerabilities and potential risks present within these systems.\nOur research presents a comprehensive methodology for conducting systematic IoT\nsecurity attacks, intercepting network traffic and evaluating the security\nrisks of smart home devices. We perform thousands of automated experiments\nusing 11 popular commercial IoT devices when deployed in a testbed, exposed to\na series of real deployed attacks (flooding, port scanning and OS scanning).\nOur findings indicate that these devices are vulnerable to security attacks and\nour results are relevant to the security research community, device engineers\nand the users who rely on these technologies in their daily lives.",
        "translated": "为了使智能家居成为安全家居，在设计时必须考虑到安全问题。然而，尽管联网数字技术在家庭环境中广泛扩散，但缺乏对这些系统中存在的安全漏洞和潜在风险进行评估的研究。我们的研究提出了一个综合的方法来进行系统的物联网安全攻击，拦截网络流量和评估智能家居设备的安全风险。我们使用11种流行的商业物联网设备进行了成千上万的自动化实验，这些设备被部署在一个测试平台上，暴露在一系列实际部署的攻击(洪水、端口扫描和操作系统扫描)之下。我们的研究结果表明，这些设备很容易受到安全攻击，我们的研究结果与安全研究界、设备工程师和日常生活中依赖这些技术的用户有关。"
    },
    {
        "title": "An Efficient and Multi-private Key Secure Aggregation for Federated\n  Learning",
        "url": "http://arxiv.org/abs/2306.08970v1",
        "pub_date": "2023-06-15",
        "summary": "With the emergence of privacy leaks in federated learning, secure aggregation\nprotocols that mainly adopt either homomorphic encryption or threshold secret\nsharing have been widely developed for federated learning to protect the\nprivacy of the local training data of each client. However, these existing\nprotocols suffer from many shortcomings, such as the dependence on a trusted\nthird party, the vulnerability to clients being corrupted, low efficiency, the\ntrade-off between security and fault tolerance, etc. To solve these\ndisadvantages, we propose an efficient and multi-private key secure aggregation\nscheme for federated learning. Specifically, we skillfully modify the variant\nElGamal encryption technique to achieve homomorphic addition operation, which\nhas two important advantages: 1) The server and each client can freely select\npublic and private keys without introducing a trust third party and 2) Compared\nto the variant ElGamal encryption, the plaintext space is relatively large,\nwhich is more suitable for the deep model. Besides, for the high dimensional\ndeep model parameter, we introduce a super-increasing sequence to compress\nmulti-dimensional data into 1-D, which can greatly reduce encryption and\ndecryption times as well as communication for ciphertext transmission. Detailed\nsecurity analyses show that our proposed scheme achieves the semantic security\nof both individual local gradients and the aggregated result while achieving\noptimal robustness in tolerating both client collusion and dropped clients.\nExtensive simulations demonstrate that the accuracy of our scheme is almost the\nsame as the non-private approach, while the efficiency of our scheme is much\nbetter than the state-of-the-art homomorphic encryption-based secure\naggregation schemes. More importantly, the efficiency advantages of our scheme\nwill become increasingly prominent as the number of model parameters increases.",
        "translated": "随着联邦学习出现私隐泄漏的情况，为保障每个客户的本地训练资料的私隐，联邦学习已广泛发展主要采用同态加密或门槛秘密共享的安全聚合协议。然而，现有的协议存在许多缺陷，如对可信第三方的依赖性、易受客户端损坏、效率低下、安全性和容错性之间的权衡等。针对这些不足，本文提出了一种高效的多私钥安全聚合方案。具体地说，我们巧妙地修改了变型 ElGamal 加密技术，实现了同态加法运算，这种加法运算具有两个重要的优点: 1)服务器和每个客户端可以自由选择公钥和私钥，而不需要引入信任的第三方; 2)与变型 ElGamal 加密相比，明文空间相对较大，更适合于深度模型。此外，对于高维深度模型参数，我们引入了一个超增长序列将多维数据压缩成一维数据，这样可以大大减少加密和解密的时间以及密文传输的通信。详细的安全性分析表明，我们提出的方案既能达到个别局部梯度的语义安全，又能达到聚合结果的效果，同时在容忍客户端合谋和丢弃客户端方面达到最佳的稳健性。大量的仿真结果表明，该方案的精度与非私有方法相当，而效率远远高于目前最先进的基于同态加密的安全聚合方案。更重要的是，我们的方案的效率优势将日益突出的模型参数的数量增加。"
    },
    {
        "title": "CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via\n  Adversarial Latent Search",
        "url": "http://arxiv.org/abs/2306.10008v1",
        "pub_date": "2023-06-16",
        "summary": "The success of deep learning based face recognition systems has given rise to\nserious privacy concerns due to their ability to enable unauthorized tracking\nof users in the digital world. Existing methods for enhancing privacy fail to\ngenerate naturalistic images that can protect facial privacy without\ncompromising user experience. We propose a novel two-step approach for facial\nprivacy protection that relies on finding adversarial latent codes in the\nlow-dimensional manifold of a pretrained generative model. The first step\ninverts the given face image into the latent space and finetunes the generative\nmodel to achieve an accurate reconstruction of the given image from its latent\ncode. This step produces a good initialization, aiding the generation of\nhigh-quality faces that resemble the given identity. Subsequently, user-defined\nmakeup text prompts and identity-preserving regularization are used to guide\nthe search for adversarial codes in the latent space. Extensive experiments\ndemonstrate that faces generated by our approach have stronger black-box\ntransferability with an absolute gain of 12.06% over the state-of-the-art\nfacial privacy protection approach under the face verification task. Finally,\nwe demonstrate the effectiveness of the proposed approach for commercial face\nrecognition systems. Our code is available at\nhttps://github.com/fahadshamshad/Clip2Protect.",
        "translated": "基于深度学习的人脸识别系统的成功引起了严重的隐私问题，因为它们能够在数字世界中对用户进行未经授权的跟踪。现有的增强隐私的方法无法生成自然的图像，从而在不损害用户体验的情况下保护面部隐私。我们提出了一种新颖的两步法来保护面部隐私，这种方法依赖于在预先训练好的生成模型的低维流形中发现对手的潜在代码。第一步将给定的人脸图像反转到潜在空间，并对生成模型进行微调，以便从潜在代码实现给定图像的准确重建。这一步产生了良好的初始化，有助于生成类似于给定身份的高质量面孔。然后，利用自定义化妆文本提示和身份保持正则化来引导在潜在空间中搜索对手代码。大量实验表明，该方法生成的人脸具有更强的黑盒可转移性，在人脸验证任务下比最先进的面部隐私保护方法的绝对增益为12.06% 。最后，我们证明了该方法在商业人脸识别系统中的有效性。我们的代码可以在 https://github.com/fahadshamshad/clip2protect 找到。"
    },
    {
        "title": "Evaluating Superhuman Models with Consistency Checks",
        "url": "http://arxiv.org/abs/2306.09983v1",
        "pub_date": "2023-06-16",
        "summary": "If machine learning models were to achieve superhuman abilities at various\nreasoning or decision-making tasks, how would we go about evaluating such\nmodels, given that humans would necessarily be poor proxies for ground truth?\nIn this paper, we propose a framework for evaluating superhuman models via\nconsistency checks. Our premise is that while the correctness of superhuman\ndecisions may be impossible to evaluate, we can still surface mistakes if the\nmodel's decisions fail to satisfy certain logical, human-interpretable rules.\nWe instantiate our framework on three tasks where correctness of decisions is\nhard to evaluate due to either superhuman model abilities, or to otherwise\nmissing ground truth: evaluating chess positions, forecasting future events,\nand making legal judgments. We show that regardless of a model's (possibly\nsuperhuman) performance on these tasks, we can discover logical inconsistencies\nin decision making. For example: a chess engine assigning opposing valuations\nto semantically identical boards; GPT-4 forecasting that sports records will\nevolve non-monotonically over time; or an AI judge assigning bail to a\ndefendant only after we add a felony to their criminal record.",
        "translated": "如果机器学习模型能够在各种推理或决策任务中获得超人的能力，那么我们如何评估这些模型，因为人类必然不能很好地代表基本事实？本文提出了一个通过一致性检验来评估超人模型的框架。我们的前提是，尽管超人类决策的正确性可能无法评估，但是如果模型的决策不能满足某些逻辑的、人类可以解释的规则，我们仍然可以表现出错误。我们在三个任务上实例化了我们的框架，其中决策的正确性很难评估，因为要么是超人的模型能力，要么是缺少基本真理: 评估国际象棋的位置，预测未来的事件，以及做出法律判断。我们表明，无论模型在这些任务上的表现如何(可能是超人的表现) ，我们都能发现决策过程中的逻辑不一致。例如: 一个国际象棋引擎为语义相同的棋盘分配相反的估值; GPT-4预测体育记录将随着时间的推移而非单调地发展; 或者一个人工智能法官只有在我们为被告的犯罪记录增加一项重罪之后才会为其分配保释金。"
    },
    {
        "title": "Data Protection for Data Privacy-A South African Problem?",
        "url": "http://arxiv.org/abs/2306.09934v1",
        "pub_date": "2023-06-16",
        "summary": "This study proposes a comprehensive framework for enhancing data security and\nprivacy within organizations through data protection awareness. It employs a\nquantitative method and survey research strategy to assess the level of data\nprotection awareness among employees of a public organization.",
        "translated": "本研究提出了一个通过提高数据保护意识加强组织内部数据安全和隐私的综合框架。采用定量研究方法和调查研究策略，对公共机构员工的数据保护意识水平进行评估。"
    },
    {
        "title": "Query-Free Evasion Attacks Against Machine Learning-Based Malware\n  Detectors with Generative Adversarial Networks",
        "url": "http://arxiv.org/abs/2306.09925v1",
        "pub_date": "2023-06-16",
        "summary": "Malware detectors based on machine learning (ML) have been shown to be\nsusceptible to adversarial malware examples. However, current methods to\ngenerate adversarial malware examples still have their limits. They either rely\non detailed model information (gradient-based attacks), or on detailed outputs\nof the model - such as class probabilities (score-based attacks), neither of\nwhich are available in real-world scenarios. Alternatively, adversarial\nexamples might be crafted using only the label assigned by the detector\n(label-based attack) to train a substitute network or an agent using\nreinforcement learning. Nonetheless, label-based attacks might require querying\na black-box system from a small number to thousands of times, depending on the\napproach, which might not be feasible against malware detectors. This work\npresents a novel query-free approach to craft adversarial malware examples to\nevade ML-based malware detectors. To this end, we have devised a GAN-based\nframework to generate adversarial malware examples that look similar to benign\nexecutables in the feature space. To demonstrate the suitability of our\napproach we have applied the GAN-based attack to three common types of features\nusually employed by static ML-based malware detectors: (1) Byte histogram\nfeatures, (2) API-based features, and (3) String-based features. Results show\nthat our model-agnostic approach performs on par with MalGAN, while generating\nmore realistic adversarial malware examples without requiring any query to the\nmalware detectors. Furthermore, we have tested the generated adversarial\nexamples against state-of-the-art multimodal and deep learning malware\ndetectors, showing a decrease in detection performance, as well as a decrease\nin the average number of detections by the anti-malware engines in VirusTotal.",
        "translated": "基于机器学习(ML)的恶意软件检测器已被证明易受敌对恶意软件例子的影响。然而，目前的方法生成对手恶意软件的例子仍然有其局限性。它们要么依赖于详细的模型信息(基于梯度的攻击) ，要么依赖于模型的详细输出——比如类概率(基于分数的攻击) ，这两种情况在现实世界的场景中都不可用。或者，可以使用检测器分配的标签(基于标签的攻击)来制作对抗性的例子，以训练替代网络或使用强化学习的代理。尽管如此，基于标签的攻击可能需要查询一个黑匣子系统，查询次数从少到数千次，这取决于不同的方法，这对于恶意软件检测器来说可能是不可行的。这项工作提出了一个新的查询免费的方法，以工艺敌对恶意软件的例子，以规避基于机器学习的恶意软件检测器。为此，我们设计了一个基于 GAN 的框架来生成与特性空间中的良性可执行程序类似的恶意软件示例。为了证明我们方法的适用性，我们将基于 GAN 的攻击应用于三种常见的特性，这些特性通常由静态基于 ML 的恶意软件检测器使用: (1)字节直方图特性，(2)基于 API 的特性，和(3)基于字符串的特性。结果表明，我们的模型无关的方法执行与 MalGAN 相当，同时产生更真实的对手恶意软件的例子，而不需要任何查询的恶意软件检测器。此外，我们已经测试了生成的敌对示例对最先进的多模式和深度学习恶意软件检测器，显示检测性能下降，以及 VirusTotal 中反恶意软件引擎的平均检测次数下降。"
    },
    {
        "title": "CroCoDai: A Stablecoin for Cross-Chain Commerce",
        "url": "http://arxiv.org/abs/2306.09754v1",
        "pub_date": "2023-06-16",
        "summary": "Decentralized Finance (DeFi), in which digital assets are exchanged without\ntrusted intermediaries, has grown rapidly in value in recent years. The global\nDeFi ecosystem is fragmented into multiple blockchains, fueling the demand for\ncross-chain commerce. Existing approaches for cross-chain transactions, e.g.,\nbridges and cross-chain deals, achieve atomicity by locking assets in escrow.\nHowever, locking up assets increases the financial risks for the participants,\nespecially due to price fluctuations and the long latency of cross-chain\ntransactions. Stablecoins, which are pegged to a non-volatile asset such as the\nUS dollar, help mitigate the risk associated with price fluctuations. However,\nexisting stablecoin designs are tied to individual blockchain platforms, and\ntrusted parties or complex protocols are needed to exchange stablecoin tokens\nbetween blockchains.\n  Our goal is to design a practical stablecoin for cross-chain commerce.\nRealizing this goal requires addressing two challenges. The first challenge is\nto support a large and growing number of blockchains efficiently. The second\nchallenge is to be resilient to price fluctuations and blockchain platform\nfailures. We present CroCoDai to address these challenges. We also present\nthree prototype implementations of our stablecoin system, and show that it\nincurs small execution overhead.",
        "translated": "分散金融(DeFi)是指在没有可信中介的情况下交换数字资产，近年来其价值迅速增长。全球的 DeFi 生态系统被分割成多个区块链，刺激了对跨链商务的需求。现有的跨链交易方法，例如桥梁和跨链交易，通过将资产锁定在第三方托管中来实现原子性。然而，锁定资产增加了参与者的财务风险，特别是由于价格波动和跨链交易的长期延迟。稳定币与美元等非波动性资产挂钩，有助于减轻与价格波动相关的风险。然而，现有的稳定币设计是与单个区块链平台相联系的，并且需要可信方或复杂的协议来在区块链之间交换稳定币令牌。我们的目标是设计一个实用的跨链商务稳定币。实现这一目标需要解决两个挑战。第一个挑战是有效地支持大量且不断增长的区块链。第二个挑战是对价格波动和区块链平台故障的弹性。我们介绍 CroCoDai 来应对这些挑战。我们还提出了我们的稳定币系统的三个原型实现，并表明它带来了小的执行开销。"
    },
    {
        "title": "PIEChain -- A Practical Blockchain Interoperability Framework",
        "url": "http://arxiv.org/abs/2306.09735v1",
        "pub_date": "2023-06-16",
        "summary": "A plethora of different blockchain platforms have emerged in recent years,\nbut many of them operate in silos. As such, there is a need for reliable\ncross-chain communication to enable blockchain interoperability. Blockchain\ninteroperability is challenging because transactions can typically not be\nreverted - as such, if one transaction is committed then the protocol must\nensure that all related transactions are committed as well. Existing\ninteroperability approaches, e.g., Cosmos and Polkadot, are limited in the\nsense that they only support interoperability between their own subchains, or\nrequire intrusive changes to existing blockchains. To overcome this limitation,\nwe propose PIEChain, a general, Kafka-based cross-chain communication\nframework. We utilize PIEChain for a practical case study: a cross-chain\nauction in which users who hold tokens on multiple chains bid for a ticket sold\non another chain. PIEChain is the first publicly available, practical\nimplementation of a general framework for cross-chain communication.",
        "translated": "近年来出现了大量不同的区块链平台，但其中许多是在竖井中运作的。因此，需要可靠的跨链通信来实现区块链互操作性。区块链互操作性是具有挑战性的，因为事务通常不能被恢复——因此，如果一个事务被提交，那么协议必须确保所有相关的事务也被提交。现有的互操作性方法，如 Cosmos 和 Polkadot，在某种意义上是有限的，它们只支持它们自己的子链之间的互操作性，或者需要对现有的区块链进行侵入性改变。为了克服这个限制，我们提出了 PIEChain，一个通用的，基于卡夫卡的跨链通信框架。我们利用 PIEChain 进行了一个实际案例研究: 一个跨链拍卖，其中持有多个链上的令牌的用户为另一个链上出售的门票出价。PIEChain 是第一个公开的、实用的跨链通信通用框架的实现。"
    },
    {
        "title": "Lost and not Found: An Investigation of Recovery Methods for\n  Multi-Factor Authentication",
        "url": "http://arxiv.org/abs/2306.09708v1",
        "pub_date": "2023-06-16",
        "summary": "Multi-Factor Authentication is intended to strengthen the security of\npassword-based authentication by adding another factor, such as hardware tokens\nor one-time passwords using mobile apps. However, this increased authentication\nsecurity comes with potential drawbacks that can lead to account and asset\nloss. If users lose access to their additional authentication factors for any\nreason, they will be locked out of their accounts. Consequently, services that\nprovide Multi-Factor Authentication should deploy procedures to allow their\nusers to recover from losing access to their additional factor that are both\nsecure and easy-to-use. To the best of our knowledge, we are the first to\nfirst-hand investigate the security and user experience of deployed\nMulti-Factor Authentication recovery procedures. We first evaluate the official\nhelp and support pages of 1,303 websites that provide Multi-Factor\nAuthentication and collect documented information about their recovery\nprocedures. Second, we select a subset of 71 websites, create accounts, set up\nMulti-Factor Authentication, and perform an in-depth investigation of their\nrecovery procedure security and user experience. We find that many websites\ndeploy insecure Multi-Factor Authentication recovery procedures and allowed us\nto circumvent and disable Multi-Factor Authentication when having access to the\naccounts' associated email addresses. Furthermore, we commonly observed\ndiscrepancies between our in-depth analysis and the official help and support\npages, implying that information meant to aid users is often either incorrect\nor outdated.",
        "translated": "双重身份验证的目的是增加另一项因素，例如硬件令牌或使用流动应用程式的一次性密码，以加强以密码为基础的认证的安全性。但是，这种增强的身份验证安全性带有潜在的缺点，可能导致帐户和资产损失。如果用户由于任何原因无法访问其附加身份验证因子，他们将被锁定在自己的帐户之外。因此，提供双重身份验证的服务应该部署程序，使用户能够从失去对其安全和易于使用的附加因素的访问中恢复过来。据我们所知，我们是第一个第一手调查已部署的双重身份验证恢复程序的安全性和用户体验。我们首先评估1,303个网站的官方帮助和支持页面，这些网站提供双重身份验证，并收集有关其恢复程序的文档信息。其次，我们从71个网站中选出一个子集，创建帐户，设置双重身份验证，并对其恢复过程的安全性和用户体验进行深入调查。我们发现很多网站采用不安全的双重身份验证恢复程序，让我们在进入有关帐户的电邮地址时可以规避和禁用双重身份验证。此外，我们经常观察到我们的深入分析与官方帮助和支持页面之间的差异，这意味着旨在帮助用户的信息往往不正确或过时。"
    },
    {
        "title": "A Smooth Binary Mechanism for Efficient Private Continual Observation",
        "url": "http://arxiv.org/abs/2306.09666v1",
        "pub_date": "2023-06-16",
        "summary": "In privacy under continual observation we study how to release differentially\nprivate estimates based on a dataset that evolves over time. The problem of\nreleasing private prefix sums of $x_1,x_2,x_3,\\dots \\in\\{0,1\\}$ (where the\nvalue of each $x_i$ is to be private) is particularly well-studied, and a\ngeneralized form is used in state-of-the-art methods for private stochastic\ngradient descent (SGD). The seminal binary mechanism privately releases the\nfirst $t$ prefix sums with noise of variance polylogarithmic in $t$. Recently,\nHenzinger et al. and Denisov et al. showed that it is possible to improve on\nthe binary mechanism in two ways: The variance of the noise can be reduced by a\n(large) constant factor, and also made more even across time steps. However,\ntheir algorithms for generating the noise distribution are not as efficient as\none would like in terms of computation time and (in particular) space. We\naddress the efficiency problem by presenting a simple alternative to the binary\nmechanism in which 1) generating the noise takes constant average time per\nvalue, 2) the variance is reduced by a factor about 4 compared to the binary\nmechanism, and 3) the noise distribution at each step is identical.\nEmpirically, a simple Python implementation of our approach outperforms the\nrunning time of the approach of Henzinger et al., as well as an attempt to\nimprove their algorithm using high-performance algorithms for multiplication\nwith Toeplitz matrices.",
        "translated": "在持续观察下，我们研究如何根据随时间演变的数据集发布不同的私人估计。发布 $x _ 1，x _ 2，x _ 3的私有前缀和的问题在{0,1} $中的点(其中每个 $x _ i $的值是私有的)被特别好地研究，并且在私有随机梯度下降的最先进的方法中使用了广义形式。开创性的二进制机制私下释放第一个 $t $前缀和，其噪声为 $t $中的方差多对数。最近，Henzinger 等人和 Denisov 等人表明，有可能通过两种方式改进二元机制: 噪声的方差可以通过一个(大的)常数因子来减小，并且在时间步长上更加均匀。然而，他们生成噪音分布的算法在计算时间和(特别是)空间方面并不像人们希望的那样有效。我们提出了一个简单的替代二元机制的效率问题，其中1)产生噪声的平均时间为每个值不变，2)方差比二元机制减少约4个因子，3)噪声分布在每个步骤是相同的。根据经验，我们方法的一个简单的 Python 实现比 Henzinger 等人的方法的运行时间更长，并且尝试使用高性能算法来改进他们的算法，用 Toeplitz 矩阵进行乘法。"
    },
    {
        "title": "Cybersecurity Career Requirements: A Literature Review",
        "url": "http://arxiv.org/abs/2306.09599v1",
        "pub_date": "2023-06-16",
        "summary": "This study employs a systematic literature review approach to identify the\nrequirements of a career as a cybersecurity professional. It aims to raise\npublic awareness regarding opportunities in the Information Security (IS)\nprofession. A total of 1,520 articles were identified from four academic\ndatabases by searching using the terms \"cybersecurity\" and \"skills\". After\nrigorous screening according to various criteria, 31 papers remained. The\nfindings of these studies were thematically analyzed to describe the knowledge\nand skills an IS professional should possess. The research found that a\nconsiderable investment in time is necessary for cybersecurity professionals to\nreach the required technical proficiency. It also identified female gender\nbarriers to cybersecurity careers due to the unique requirements of the field\nand suggests that females may successfully enter at lower levels and progress\nup the tiers as circumstances dictate.",
        "translated": "本研究采用系统的文献综述方法，以确定网络安全专业人员的职业要求。该计划旨在提高公众对资讯保安专业机会的认识。通过使用“网络安全”和“技能”两个术语搜索，从四个学术数据库中共识别出1,520篇文章。经过严格筛选，根据不同的标准，31篇论文仍然存在。这些研究的结果进行了专题分析，以描述知识和技能的信息系统专业人员应该具备的。研究发现，网络安全专业人员要达到所要求的技术熟练程度，需要在时间上进行大量投资。报告还指出，由于该领域的独特要求，女性在网络安全职业方面存在性别障碍，并建议女性可以根据情况的需要成功地进入较低的职等，并在职等上取得进展。"
    },
    {
        "title": "Fuzzy Feature Selection with Key-based Cryptographic Transformations",
        "url": "http://arxiv.org/abs/2306.09583v1",
        "pub_date": "2023-06-16",
        "summary": "In the field of cryptography, the selection of relevant features plays a\ncrucial role in enhancing the security and efficiency of cryptographic\nalgorithms. This paper presents a novel approach of applying fuzzy feature\nselection to key-based cryptographic transformations. The proposed fuzzy\nfeature selection leverages the power of fuzzy logic to identify and select\noptimal subsets of features that contribute most effectively to the\ncryptographic transformation process. By incorporating fuzzy feature selection\ninto key-based cryptographic transformations, this research aims to improve the\nresistance against attacks and enhance the overall performance of cryptographic\nsystems. Experimental evaluations may demonstrate the effectiveness of the\nproposed approach in selecting secure key features with minimal computational\noverhead. This paper highlights the potential of fuzzy feature selection as a\nvaluable tool in the design and optimization of key-based cryptographic\nalgorithms, contributing to the advancement of secure information exchange and\ncommunication in various domains.",
        "translated": "在密码学领域，相关特征的选择对提高密码算法的安全性和效率起着至关重要的作用。提出了一种将模糊特征选择应用于基于密钥的密码变换的新方法。提出的模糊特征选择利用模糊逻辑的能力来识别和选择最有效地促进密码转换过程的特征的最佳子集。将模糊特征选择技术引入到基于密钥的密码变换中，旨在提高密码系统的抗攻击能力，提高系统的整体性能。实验结果表明，该方法能够以最小的计算开销选择安全的关键特征。本文着重介绍了模糊特征选择技术作为密钥密码算法设计和优化的有效工具的潜力，为各领域的安全信息交换和通信的发展做出了贡献。"
    },
    {
        "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models",
        "url": "http://arxiv.org/abs/2306.11698v1",
        "pub_date": "2023-06-20",
        "summary": "Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications to healthcare and finance - where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives - including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially due to the\nreason that GPT-4 follows the (misleading) instructions more precisely. Our\nwork illustrates a comprehensive trustworthiness evaluation of GPT models and\nsheds light on the trustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/.",
        "translated": "生成式预训练变压器(GPT)模型在性能方面展示了令人兴奋的进步，吸引了从业者和公众的兴趣。然而，尽管关于 GPT 模型可信度的文献仍然有限，但从业人员已经提议，在医疗和金融领域的敏感应用中使用有能力的 GPT 模型——在这些领域，错误可能代价高昂。为此，这项工作提出了一个全面的大型语言模型的可信性评估，重点是 GPT-4和 GPT-3.5，考虑到不同的观点-包括毒性，刻板印象偏差，对抗性鲁棒性，分布外鲁棒性，对抗性示范的鲁棒性，隐私，机器伦理和公平。根据我们的评估，我们发现了以前未公布的可信度威胁的漏洞。例如，我们发现 GPT 模型很容易被误导，从而产生有毒和有偏见的输出，并在训练数据和对话历史中泄露私人信息。我们还发现，尽管 GPT-4在标准基准上通常比 GPT-3.5更值得信赖，但是在破解系统或用户提示下，GPT-4更容易受到攻击，这可能是由于 GPT-4更精确地遵循(误导性的)指令的原因。我们的工作阐述了 GPT 模型的全面可信性评估，并揭示了可信性差距。我们的基准 https://decodingtrust.github.io/已公开发售。"
    },
    {
        "title": "Pseudorandom unitaries are neither real nor sparse nor noise-robust",
        "url": "http://arxiv.org/abs/2306.11677v1",
        "pub_date": "2023-06-20",
        "summary": "Pseudorandom quantum states (PRSs) and pseudorandom unitaries (PRUs) possess\nthe dual nature of being efficiently constructible while appearing completely\nrandom to any efficient quantum algorithm. In this study, we establish\nfundamental bounds on pseudorandomness. We show that PRSs and PRUs exist only\nwhen the probability that an error occurs is negligible, ruling out their\ngeneration on noisy intermediate-scale and early fault-tolerant quantum\ncomputers. Additionally, we derive lower bounds on the imaginarity and\ncoherence of PRSs and PRUs, rule out the existence of sparse or real PRUs, and\nshow that PRUs are more difficult to generate than PRSs. Our work also\nestablishes rigorous bounds on the efficiency of property testing,\ndemonstrating the exponential complexity in distinguishing real quantum states\nfrom imaginary ones, in contrast to the efficient measurability of unitary\nimaginarity. Furthermore, we prove lower bounds on the testing of coherence.\nLastly, we show that the transformation from a complex to a real model of\nquantum computation is inefficient, in contrast to the reverse process, which\nis efficient. Overall, our results establish fundamental limits on property\ntesting and provide valuable insights into quantum pseudorandomness.",
        "translated": "伪随机量子态(PRS)和伪随机酉(PRU)具有有效构造的双重性质，同时对于任何有效的量子算法来说都是完全随机的。在这项研究中，我们建立了伪随机数的基本界限。我们证明了 PRS 和 PRU 只有在发生错误的概率可以忽略的情况下才存在，排除了它们在噪声中等规模和早期容错量子计算机上产生的可能性。此外，我们得到了 PRS 和 PRU 的想象性和一致性的下界，排除了稀疏或真实 PRU 的存在，并表明 PRU 比 PRS 更难产生。我们的工作也建立了严格的界限对性质测试的效率，证明了指数复杂性在区分真实的量子态和想象的，相对于有效的可测量的酉想象性。此外，我们还证明了一致性检验的下界。最后，我们发现量子计算从复杂模型到实际模型的转换是低效的，相比之下，反向过程是有效的。总的来说，我们的研究结果确立了物性测试的基本界限，并为量子伪随机数提供了有价值的见解。"
    },
    {
        "title": "On Cross-Layer Interactions of QUIC, Encrypted DNS and HTTP/3: Design,\n  Evaluation and Dataset",
        "url": "http://arxiv.org/abs/2306.11643v1",
        "pub_date": "2023-06-20",
        "summary": "Every Web session involves a DNS resolution. While, in the last decade, we\nwitnessed a promising trend towards an encrypted Web in general, DNS encryption\nhas only recently gained traction with the standardisation of DNS over TLS\n(DoT) and DNS over HTTPS (DoH). Meanwhile, the rapid rise of QUIC deployment\nhas now opened up an exciting opportunity to utilise the same protocol to not\nonly encrypt Web communications, but also DNS. In this paper, we evaluate this\nbenefit of using QUIC to coalesce name resolution via DNS over QUIC (DoQ), and\nWeb content delivery via HTTP/3 (H3) with 0-RTT. We compare this scenario using\nseveral possible combinations where H3 is used in conjunction with DoH and DoQ,\nas well as the unencrypted DNS over UDP (DoUDP). We observe, that when using H3\n1-RTT, page load times with DoH can get inflated by $&gt;$30\\% over fixed-line and\nby $&gt;$50\\% over mobile when compared to unencrypted DNS with DoUDP. However,\nthis cost of encryption can be drastically reduced when encrypted connections\nare coalesced (DoQ + H3 0-RTT), thereby reducing the page load times by 1/3\nover fixed-line and 1/2 over mobile, overall making connection coalescing with\nQUIC the best option for encrypted communication on the Internet.",
        "translated": "每个 Web 会话都涉及一个 DNS 解决方案。然而，在过去的十年中，我们目睹了一个向加密网络发展的大趋势，DNS 加密只是最近才随着 DNS over TLS (DoT)和 DNS over HTTPS (DoH)的标准化而获得关注。与此同时，QUIC 部署的快速增长为利用相同的协议不仅加密网络通信，而且加密域名解析系统(DNS)提供了一个令人兴奋的机会。在本文中，我们评估了使用 QUIC 通过 DNS over QUIC (DoQ)和0-RTT 通过 HTTP/3(H3)传输 Web 内容来合并名称解析的好处。我们使用几种可能的组合来比较这个场景，其中 H3与 DoH 和 DoQ 以及未加密的 DNS over UDP (DoUDP)一起使用。我们观察到，当使用 H31-RTT 时，与使用 DoUDP 的未加密 DNS 相比，使用 DoH 的页面加载时间可以在固定线路上增加30% 以上，在移动线路上增加50% 以上。然而，当加密连接合并(DoQ + H30-RTT)时，这种加密成本可以大大降低，从而使固定线路上的页面加载时间减少1/3，移动线路上的页面加载时间减少1/2，总体上使得与 QUIC 的连接合并成为互联网上加密通信的最佳选择。"
    },
    {
        "title": "SALSA VERDE: a machine learning attack on Learning With Errors with\n  sparse small secrets",
        "url": "http://arxiv.org/abs/2306.11641v1",
        "pub_date": "2023-06-20",
        "summary": "Learning with Errors (LWE) is a hard math problem used in post-quantum\ncryptography. Homomorphic Encryption (HE) schemes rely on the hardness of the\nLWE problem for their security, and two LWE-based cryptosystems were recently\nstandardized by NIST for digital signatures and key exchange (KEM). Thus, it is\ncritical to continue assessing the security of LWE and specific parameter\nchoices. For example, HE uses small secrets, and the HE community has\nconsidered standardizing small sparse secrets to improve efficiency and\nfunctionality. However, prior work, SALSA and PICANTE, showed that ML attacks\ncan recover sparse binary secrets. Building on these, we propose VERDE, an\nimproved ML attack that can recover sparse binary, ternary, and small Gaussian\nsecrets. Using improved preprocessing and secret recovery techniques, VERDE can\nattack LWE with larger dimensions ($n=512$) and smaller moduli ($\\log_2 q=12$\nfor $n=256$), using less time and power. We propose novel architectures for\nscaling. Finally, we develop a theory that explains the success of ML LWE\nattacks.",
        "translated": "带错误学习(LWE)是后量子密码学中的一个难题。高同态加密密码体制(HE)的安全性依赖于 LWE 问题的难度，而两个基于 LWE 的密码体制最近被 NIST 标准化，用于数字签名和密钥交换(KEM)。因此，继续评估 LWE 的安全性和特定的参数选择是至关重要的。例如，HE 使用小秘密，HE 社区已经考虑将小稀疏秘密标准化，以提高效率和功能。然而，先前的工作，SALSA 和 PICANTE，表明机器学习攻击可以恢复稀疏的二进制秘密。在此基础上，我们提出了 VERDE，一种改进的机器学习攻击，可以恢复稀疏的二进制，三进制和小高斯秘密。使用改进的预处理和秘密恢复技术，VERDE 可以用更大的维度($n = 512 $)和更小的模块($log _ 2 q = 12 $for $n = 256 $)攻击 LWE，使用更少的时间和功耗。我们提出了新颖的可伸缩架构。最后，我们发展了一个理论来解释 ML LWE 攻击的成功。"
    },
    {
        "title": "The Pricing And Hedging Of Constant Function Market Makers",
        "url": "http://arxiv.org/abs/2306.11580v1",
        "pub_date": "2023-06-20",
        "summary": "We investigate the most common type of blockchain-based decentralized\nexchange, which are known as constant function market makers (CFMMs). We\nexamine the the market microstructure around CFMMs and present a model for\nvaluing the liquidity provider (LP) mechanism and estimating the value of the\nassociated derivatives. We develop a model with two types of traders that have\ndifferent information and contribute methods for simulating the behavior of\neach trader and accounting for trade PnL. We also develop ideas around the\nequilibrium distribution of fair price conditional on the arrival of traders.\nFinally, we show how these findings might be used to think about parameters for\nalternative CFMMs.",
        "translated": "我们调查最常见的类型的区块链基于分散交易，这是众所周知的恒定函数做市商(CFMM)。我们考察了 CFMM 周围的市场微观结构，并提出了一个评估流动性提供者(LP)机制和估计相关衍生品价值的模型。我们发展了一个模型与两类交易者有不同的信息和贡献的方法来模拟每个交易者的行为和会计交易 PnL。我们还围绕以交易者到达为条件的公平价格的均衡分布提出了一些想法。最后，我们展示了如何利用这些发现来考虑替代 CFMM 的参数。"
    },
    {
        "title": "A Comparative Audit of Privacy Policies from Healthcare Organizations in\n  USA, UK and India",
        "url": "http://arxiv.org/abs/2306.11557v1",
        "pub_date": "2023-06-20",
        "summary": "Data privacy in healthcare is of paramount importance (and thus regulated\nusing laws like HIPAA) due to the highly sensitive nature of patient data. To\nthat end, healthcare organizations mention how they collect/process/store/share\nthis data (i.e., data practices) via their privacy policies. Thus there is a\nneed to audit these policies and check compliance with respective laws. This\npaper addresses this need and presents a large-scale data-driven study to audit\nprivacy policies from healthcare organizations in three countries -- USA, UK,\nand India.\n  We developed a three-stage novel \\textit{workflow} for our audit. First, we\ncollected the privacy policies of thousands of healthcare organizations in\nthese countries and cleaned this privacy policy data using a clustering-based\nmixed-method technique. We identified data practices regarding users' private\nmedical data (medical history) and site privacy (cookie, logs) in these\npolicies. Second, we adopted a summarization-based technique to uncover exact\nbroad data practices across countries and notice important differences.\nFinally, we evaluated the cross-country data practices using the lens of legal\ncompliance (with legal expert feedback) and grounded in the theory of\nContextual Integrity (CI). Alarmingly, we identified six themes of\nnon-alignment (observed in 21.8\\% of data practices studied in India) pointed\nout by our legal experts. Furthermore, there are four \\textit{potential\nviolations} according to case verdicts from Indian Courts as pointed out by our\nlegal experts. We conclude this paper by discussing the utility of our auditing\nworkflow and the implication of our findings for different stakeholders.",
        "translated": "由于患者数据的高度敏感性，医疗保健中的数据隐私至关重要(因此使用 HIPAA 等法律进行监管)。为此，医疗机构提到了他们如何通过隐私策略收集/处理/存储/共享这些数据(即数据实践)。因此，有必要对这些政策进行审计，并检查其是否符合相关法律。本文针对这一需求，提出了一个大规模的数据驱动的研究审计隐私政策来自三个国家的医疗机构-美国，英国和印度。我们开发了一个三阶段的小说文本{工作流程}为我们的审计。首先，我们收集了这些国家数千家医疗机构的隐私政策，并使用基于聚类的混合方法技术清理了这些隐私政策数据。在这些策略中，我们确定了有关用户私人医疗数据(病史)和站点隐私(cookie、日志)的数据实践。其次，我们采用了一种基于摘要的技术来揭示各国之间确切的广泛数据实践，并注意到重要的差异。最后，我们以法律遵从性为视角(法律专家反馈) ，以情境完整性(CI)理论为基础，对跨国数据实践进行了评价。令人担忧的是，我们确定了法律专家指出的六个不一致的主题(在印度研究的数据实践中有21.8% 观察到这一点)。此外，根据我国法律专家指出的印度法院的判决，有四个案文(潜在违法行为)。我们通过讨论我们的审计工作流程的效用和我们的发现对不同利益相关者的影响来结束本文。"
    },
    {
        "title": "Data Availability Sampling in Ethereum: Analysis of P2P Networking\n  Requirements",
        "url": "http://arxiv.org/abs/2306.11456v1",
        "pub_date": "2023-06-20",
        "summary": "Despite their increasing popularity, blockchains still suffer from severe\nscalability limitations. Recently, Ethereum proposed a novel approach to block\nvalidation based on Data Availability Sampling (DAS), that has the potential to\nimprove its transaction per second rate by more than two orders of magnitude.\nDAS should also significantly reduce per-transaction validation costs. At the\nsame time, DAS introduces new communication patterns in the Ethereum\nPeer-to-Peer (P2P) network. These drastically increase the amount of exchanged\ndata and impose stringent latency objectives. In this paper, we review the new\nrequirements for P2P networking associated with DAS, discuss open challenges,\nand identify new research directions.",
        "translated": "尽管区块链越来越受欢迎，但它们仍然受到严重的可伸缩性限制。最近，以太坊提出了一种基于数据可用性采样(DAS)的块验证方法，该方法有可能将其每秒的交易速度提高两个数量级以上。DAS 还应显著降低每笔交易的验证成本。同时，DAS 在以太对等(P2P)网络中引入了新的通信模式。这些极大地增加了交换数据的数量，并实现了严格的延迟目标。在本文中，我们回顾了与 DAS 相关的 P2P 网络的新需求，讨论了开放的挑战，并确定了新的研究方向。"
    },
    {
        "title": "Transparency in App Analytics: Analyzing the Collection of User\n  Interaction Data",
        "url": "http://arxiv.org/abs/2306.11447v1",
        "pub_date": "2023-06-20",
        "summary": "The rise of mobile apps has brought greater convenience and many options for\nusers. However, many apps use analytics services to collect a wide range of\nuser interaction data, with privacy policies often failing to reveal the types\nof interaction data collected or the extent of the data collection practices.\nThis lack of transparency potentially breaches data protection laws and also\nundermines user trust. We conducted an analysis of the top 20 analytic\nlibraries for Android apps to identify common practices of interaction data\ncollection and used this information to develop a standardized collection claim\ntemplate for summarizing an app's data collection practices wrt. user\ninteraction data. We selected the top 100 apps from popular categories on\nGoogle Play and used automatic static analysis to extract collection evidence\nfrom their data collection implementations. Our analysis found that a\nsignificant majority of these apps actively collected interaction data from UI\ntypes such as View (89%), Button (76%), and Textfield (63%), highlighting the\npervasiveness of user interaction data collection. By comparing the collection\nevidence to the claims derived from privacy policy analysis, we manually\nfact-checked the completeness and accuracy of these claims for the top 10 apps.\nWe found that, except for one app, they all failed to declare all types of\ninteraction data they collect and did not specify some of the collection\ntechniques used.",
        "translated": "移动应用的兴起给用户带来了更多的便利和选择。然而，许多应用程序使用分析服务来收集广泛的用户交互数据，隐私策略往往不能揭示收集的交互数据类型或数据收集实践的范围。这种缺乏透明度的情况有可能违反数据保护法，也有可能破坏用户的信任。我们对 Android 应用程序的前20个分析库进行了分析，以确定交互数据收集的常见做法，并利用这些信息开发了一个标准化的收集索赔模板，用于总结应用程序的数据收集实践，包括用户交互数据。我们从 Google Play 的热门分类中选出了前100名的应用程序，并使用自动静态分析从它们的数据收集实现中提取收集证据。我们的分析发现，绝大多数这些应用程序积极地从 UI 类型(如 View (89%) ，Button (76%)和 Textfield (63%))收集交互数据，突出了用户交互数据收集的普遍性。通过将收集的证据与隐私政策分析得出的声明进行比较，我们手动对前10个应用程序的这些声明的完整性和准确性进行事实核查。我们发现，除了一个应用程序之外，它们都未能声明它们收集的所有类型的交互数据，也没有指定所使用的一些收集技术。"
    },
    {
        "title": "A Survey of Multivariate Polynomial Commitment Schemes",
        "url": "http://arxiv.org/abs/2306.11383v2",
        "pub_date": "2023-06-20",
        "summary": "A commitment scheme is a cryptographic tool that allows one to commit to a\nhidden value, with the option to open it later at requested places without\nrevealing the secret itself. Commitment schemes have important applications in\nzero-knowledge proofs and secure multi-party computation, just to name a few.\nThis survey introduces a few multivariate polynomial commitment schemes that\nare built from a variety of mathematical structures. We study how Orion is\nconstructed using hash functions; Dory, Bulletproofs, and Vampire using the\ninner-product argument; Signatures of Correct Computation using polynomial\nfactoring; DARK and Dew using groups of unknown order; and Orion+ using a\nCP-SNARK. For each protocol, we prove its completeness and state its security\nassumptions.",
        "translated": "承诺方案是一种加密工具，允许用户提交隐藏值，并可以选择稍后在请求的位置打开它，而不会泄露秘密本身。承诺方案在零知识证明和安全多方计算方面有着重要的应用，仅举几例。本文介绍了几种基于多种数学结构的多元多项式承诺方案。我们研究 Orion 是如何使用散列函数构造的; 多利，防弹，吸血鬼使用内积参数; 签名正确计算使用多项式分解; DARK 和露使用未知的顺序组; 以及 Orion + 使用 CP-SNARK。对于每个协议，我们证明了它的完备性并陈述了它的安全性假设。"
    },
    {
        "title": "FDInet: Protecting against DNN Model Extraction via Feature Distortion\n  Index",
        "url": "http://arxiv.org/abs/2306.11338v1",
        "pub_date": "2023-06-20",
        "summary": "Machine Learning as a Service (MLaaS) platforms have gained popularity due to\ntheir accessibility, cost-efficiency, scalability, and rapid development\ncapabilities. However, recent research has highlighted the vulnerability of\ncloud-based models in MLaaS to model extraction attacks. In this paper, we\nintroduce FDINET, a novel defense mechanism that leverages the feature\ndistribution of deep neural network (DNN) models. Concretely, by analyzing the\nfeature distribution from the adversary's queries, we reveal that the feature\ndistribution of these queries deviates from that of the model's training set.\nBased on this key observation, we propose Feature Distortion Index (FDI), a\nmetric designed to quantitatively measure the feature distribution deviation of\nreceived queries. The proposed FDINET utilizes FDI to train a binary detector\nand exploits FDI similarity to identify colluding adversaries from distributed\nextraction attacks. We conduct extensive experiments to evaluate FDINET against\nsix state-of-the-art extraction attacks on four benchmark datasets and four\npopular model architectures. Empirical results demonstrate the following\nfindings FDINET proves to be highly effective in detecting model extraction,\nachieving a 100% detection accuracy on DFME and DaST. FDINET is highly\nefficient, using just 50 queries to raise an extraction alarm with an average\nconfidence of 96.08% for GTSRB. FDINET exhibits the capability to identify\ncolluding adversaries with an accuracy exceeding 91%. Additionally, it\ndemonstrates the ability to detect two types of adaptive attacks.",
        "translated": "机器学习即服务(MLaaS)平台因其易访问性、成本效率、可伸缩性和快速开发能力而广受欢迎。然而，最近的研究强调了 MLaaS 中基于云的模型在模型提取攻击下的脆弱性。本文介绍了一种利用深度神经网络(DNN)模型特征分布的新型防御机制 FDINET。具体地，通过分析对手查询的特征分布，我们发现这些查询的特征分布与模型训练集的特征分布存在偏差。在此基础上，我们提出了特征失真指数(FDI) ，这是一个定量度量接收查询的特征分布偏差的指标。提出的 FDINET 利用 FDI 对二进制检测器进行训练，并利用 FDI 的相似性来识别分布式抽取攻击中的合谋对手。我们进行了广泛的实验来评估 FDINET 对四个基准数据集和四个流行的模型体系结构的六种最先进的提取攻击。实验结果表明，FDINET 在检测模型提取方面具有很好的效果，对 DFME 和 DaST 的检测准确率达到100% 。FDINET 是非常高效的，只需要50个查询就可以提出一个提取警报，GTSRB 的平均置信度为96.08% 。FDINET 具有识别共谋对手的能力，准确率超过91% 。此外，它还演示了检测两种类型的自适应攻击的能力。"
    },
    {
        "title": "Geometric Algorithms for $k$-NN Poisoning",
        "url": "http://arxiv.org/abs/2306.12377v1",
        "pub_date": "2023-06-21",
        "summary": "We propose a label poisoning attack on geometric data sets against\n$k$-nearest neighbor classification. We provide an algorithm that can compute\nan $\\varepsilon n$-additive approximation of the optimal poisoning in $n\\cdot\n2^{2^{O(d+k/\\varepsilon)}}$ time for a given data set $X \\in \\mathbb{R}^d$,\nwhere $|X| = n$. Our algorithm achieves its objectives through the application\nof multi-scale random partitions.",
        "translated": "针对 $k $- 最近邻分类，提出了一种针对几何数据集的标签中毒攻击。我们提供了一个算法，可以计算给定数据集 $X 在 $n cdot 2 ^ {2 ^ { O (d + k/varepsilon)}} $time 中最佳中毒的 $varepsilon n $- 加法近似，其中 $| X | = n $。我们的算法通过应用多尺度随机分区来实现其目标。"
    },
    {
        "title": "Do you still need a manual smart contract audit?",
        "url": "http://arxiv.org/abs/2306.12338v2",
        "pub_date": "2023-06-21",
        "summary": "We investigate the feasibility of employing large language models (LLMs) for\nconducting the security audit of smart contracts, a traditionally\ntime-consuming and costly process. Our research focuses on the optimization of\nprompt engineering for enhanced security analysis, and we evaluate the\nperformance and accuracy of LLMs using a benchmark dataset comprising 52\nDecentralized Finance (DeFi) smart contracts that have previously been\ncompromised.\n  Our findings reveal that, when applied to vulnerable contracts, both GPT-4\nand Claude models correctly identify the vulnerability type in 40% of the\ncases. However, these models also demonstrate a high false positive rate,\nnecessitating continued involvement from manual auditors. The LLMs tested\noutperform a random model by 20% in terms of F1-score.\n  To ensure the integrity of our study, we conduct mutation testing on five\nnewly developed and ostensibly secure smart contracts, into which we manually\ninsert two and 15 vulnerabilities each. This testing yielded a remarkable\nbest-case 78.7% true positive rate for the GPT-4-32k model. We tested both,\nasking the models to perform a binary classification on whether a contract is\nvulnerable, and a non-binary prompt. We also examined the influence of model\ntemperature variations and context length on the LLM's performance.\n  Despite the potential for many further enhancements, this work lays the\ngroundwork for a more efficient and economical approach to smart contract\nsecurity audits.",
        "translated": "我们研究了使用大语言模型(LLM)进行智能合同安全审计的可行性，这是一个传统的耗时和昂贵的过程。我们的研究集中在优化快速工程，以增强安全分析，我们使用一个基准数据集评估 LLM 的性能和准确性，这个基准数据集包括52个先前已被破坏的分散金融(DeFi)智能合同。我们的研究结果表明，当应用于脆弱性合同时，GPT-4和 Claude 模型正确识别了40% 的情况下的脆弱性类型。然而，这些模型也表现出很高的假阳性率，需要继续从人工审计员的参与。LLM 测试的 F1分数比随机模型高出20% 。为了确保研究的完整性，我们对5份新开发的、表面上安全的智能合同进行了突变测试分析，每份合同中我们手动插入了2个和15个漏洞。这个测试为 GPT-4-32k 模型产生了显著的最佳情况下78.7% 的真阳性率。我们同时测试了这两种方法，要求模型对合同是否有漏洞执行二进制分类，以及非二进制提示。我们还研究了模型温度变化和上下文长度对 LLM 性能的影响。尽管有许多进一步增强的潜力，但这项工作为更有效和更经济的智能合同安全审计方法奠定了基础。"
    },
    {
        "title": "ICAR, a categorical framework to connect vulnerability, threat and asset\n  managements",
        "url": "http://arxiv.org/abs/2306.12240v1",
        "pub_date": "2023-06-21",
        "summary": "We present ICAR, a mathematical framework derived from category theory for\nrepresenting cybersecurity NIST and MITRE's ontologies. Designed for\ncybersecurity, ICAR is a category whose objects are cybersecurity knowledge\n(weakness, vulnerability, impacted product, attack technique, etc.) and whose\nmorphisms are relations between this knowledge, that make sense for\ncybersecurity. Within this rigorous and unified framework, we obtain a\nknowledge graph capable of identifying the attack and weakness structures of an\nIS, at the interface between description logics, database theory and\ncybersecurity. We then define ten cybersecurity queries to help understand the\nrisks incurred by IS and organise their defence.",
        "translated": "我们提出 ICAR，一个数学框架派生的范畴理论，表示网络安全 NIST 和 MITRE 的本体。ICAR 是为网络安全而设计的一个范畴，其对象是网络安全知识(弱点、脆弱性、受影响的产品、攻击技术等) ，其形态是这些知识之间的关系，对网络安全有意义。在这个严格统一的框架内，在描述逻辑、数据库理论和网络安全的接口处，我们得到了一个能够识别信息系统攻击和弱点结构的知识图。然后，我们定义了十个网络安全查询，以帮助理解信息系统所带来的风险并组织其防御。"
    },
    {
        "title": "Tailstorm: A Secure and Fair Blockchain for Cash Transactions",
        "url": "http://arxiv.org/abs/2306.12206v1",
        "pub_date": "2023-06-21",
        "summary": "Proof-of-work (PoW) cryptocurrencies rely on a balance of security and\nfairness in order to maintain a sustainable ecosystem of miners and users.\nUsers demand fast and consistent transaction confirmation, and in exchange\ndrive the adoption and valuation of the cryptocurrency. Miners provide the\nconfirmations, however, they primarily seek rewards. In unfair systems, miners\ncan amplify their rewards by consolidating mining power. Centralization\nhowever, undermines the security guarantees of the system and might discourage\nusers.\n  In this paper we present Tailstorm, a cryptocurrency that strikes this\nbalance. Tailstorm merges multiple recent protocol improvements addressing\nsecurity, confirmation latency, and throughput with a novel incentive mechanism\nimproving fairness. We implement a parallel proof-of-work consensus mechanism\nwith $k$ PoWs per block to obtain state-of-the-art consistency guarantees.\nInspired by Bobtail and Storm, we structure the individual PoWs in a tree\nwhich, by including a list of transactions with each PoW, reduces confirmation\nlatency and improves throughput. Our proposed incentive mechanism discounts\nrewards based on the depth of this tree. Thereby, it effectively punishes\ninformation withholding, the core attack strategy used to reap an unfair share\nof rewards.\n  We back our claims with a comprehensive analysis. We present a generic system\nmodel which allows us to specify Bitcoin, $B_k$, and Tailstorm from a joint set\nof assumptions. We provide an analytical bound for the fairness of Tailstorm\nand Bitcoin in honest networks and we confirm the results through simulation.\nWe evaluate the effectiveness of dishonest behaviour through reinforcement\nlearning. Our attack search reproduces known optimal strategies against\nBitcoin, uncovers new ones against $B_k$, and confirms that Tailstorm's reward\ndiscounting makes it more resilient to incentive layer attacks.",
        "translated": "工作证(Proof-of-work，PoW)加密货币依赖于安全性和公平性的平衡，以维持矿工和用户的可持续生态系统。用户需要快速和一致的交易确认，作为交换，推动加密货币的采用和估值。矿工提供证实，然而，他们主要寻求奖励。在不公平的体制下，矿商可以通过整合采矿权来放大自己的回报。然而，集中化会破坏系统的安全保障，并可能使用户泄气。在本文中，我们介绍了尾风暴，一种加密货币，以达到这种平衡。Tailstorm 融合了多个最新的协议改进，包括安全性、确认延迟和吞吐量，并采用新的激励机制提高公平性。我们实现了一个并行的工作证明共识机制，每个块具有 $k $PoWs，以获得最先进的一致性保证。灵感来自短尾和风暴，我们结构在一个树中的每个战俘，通过包括每个战俘的事务列表，减少了确认延迟和提高吞吐量。我们提出的激励机制基于此树的深度折扣奖励。因此，它有效地惩罚了隐瞒信息的核心攻击策略，用来获取不公平的奖励份额。我们以全面的分析来支持我们的主张。我们提出了一个通用的系统模型，允许我们指定比特币，$B _ k $，和尾风暴从一个联合的假设集。我们为 Tailstorm 和比特币在诚实网络中的公平性提供了一个分析界限，并通过模拟验证了结果。我们会透过强化学习评估不诚实行为的成效。我们的攻击搜索复制了已知的针对比特币的最优策略，发现了针对 $B _ k $的新策略，并证实了 Tailstorm 的奖励折扣使其更能抵御激励层攻击。"
    },
    {
        "title": "Probabilistic estimation of the algebraic degree of Boolean functions",
        "url": "http://arxiv.org/abs/2306.12196v1",
        "pub_date": "2023-06-21",
        "summary": "The algebraic degree is an important parameter of Boolean functions used in\ncryptography. When a function in a large number of variables is not given\nexplicitly in algebraic normal form, it might not be feasible to compute its\ndegree. Instead, one can try to estimate the degree using probabilistic tests.\n  We propose a probabilistic test for deciding whether the algebraic degree of\na Boolean function $f$ is below a certain value $k$. The test involves picking\nan affine space of dimension $k$ and testing whether the values on $f$ on that\nspace sum up to zero. If $deg(f)&lt;k$, then $f$ will always pass the test,\notherwise it will sometimes pass and sometimes fail the test, depending on\nwhich affine space was chosen. The probability of failing the proposed test is\nclosely related to the number of monomials of degree $k$ in a polynomial $g$,\naveraged over all the polynomials $g$ which are affine equivalent to $f$.\n  We initiate the study of the probability of failing the proposed\n``$deg(f)&lt;k$'' test. We show that in the particular case when the degree of $f$\nis actually equal to $k$, the probability will be in the interval $(0.288788,\n0.5]$, and therefore a small number of runs of the test is sufficient to give,\nwith very high probability, the correct answer. Exact values of this\nprobability for all the polynomials in 8 variables were computed using the\nrepresentatives listed by Hou and by Langevin and Leander.",
        "translated": "代数度是密码学中布尔函数的一个重要参数。当大量变量中的一个函数没有以代数规范形式显式给出时，计算它的次数可能是不可行的。相反，人们可以尝试使用概率测试来估计程度。我们提出了一个概率测试来判断布尔函数 f $的代数度是否低于某个值 $k $。测试包括挑选一个维度为 $k $的仿射空间，并测试该空间上 $f $上的值是否总和为零。如果 $deg (f) < k $，则 $f $将始终通过测试，否则它有时会通过测试，有时会失败，这取决于所选择的仿射空间。多项式 $g $中 k $度单项式的数目与拟合等价于 f $的所有多项式 $g $的平均值密切相关，因此，不通过拟合检验的概率与拟合多项式 $g $中 k $度单项式的数目密切相关，拟合多项式 $g $中 k $度单项式的平均值与拟合等价于 f $的多项式 $g $的平均值密切相关。我们开始研究不通过提议的“ $deg (f) < k $”测试的可能性。我们证明了在特殊情况下，当 $f $的度实际上等于 $k $时，概率将在区间 $(0.288788,0.5] $，因此少量的运行测试足以给出正确的答案，并且概率非常高。在8个变量中的所有多项式的这个概率的精确值是使用由侯和朗之万和利安德列出的代表计算出来的。"
    },
    {
        "title": "Decisions &amp; Disruptions 2: Decide Harder",
        "url": "http://arxiv.org/abs/2306.12168v1",
        "pub_date": "2023-06-21",
        "summary": "Cyber incident response is critical to business continuity -- we describe a\nnew exercise that challenges professionals to play the role of Chief\nInformation Security Officer (CISO) for a major financial organisation. Teams\nmust decide how organisational team and budget resources should be deployed\nacross Enterprise Architecture (EA) upgrades and cyber incidents. Every choice\nmade has an impact -- some prevent whilst others may trigger new or continue\ncurrent attacks. We explain how the underlying platform supports these\ninteractions through a reactionary event mechanism that introduces events based\non the current attack surface of the organisation. We explore how our platform\nmanages to introduce randomness on top of triggered events to ensure that the\nexercise is not deterministic and better matches incidents in the real world.\nWe conclude by describing next steps for the exercise and how we plan to use it\nin the future to better understand risk decision making.",
        "translated": "网上事故应变对业务的持续运作至为重要——我们描述了一项新的活动，挑战专业人士在一个主要金融机构担任首席资讯保安主任(CISO)的角色。团队必须决定如何在企业架构(Enterprise Architecture，EA)升级和网络事件中部署组织团队和预算资源。所做的每一个选择都会产生影响——有些可以预防，有些可以触发新的或者继续当前的攻击。我们解释了底层平台如何通过一个反应事件机制支持这些交互，该机制引入基于组织当前攻击面的事件。我们探索我们的平台如何设法在触发事件之上引入随机性，以确保练习不是确定性的，并更好地匹配现实世界中的事件。最后，我们描述了下一步的工作，以及我们计划如何在未来使用它，以更好地了解风险决策。"
    },
    {
        "title": "Adversarial Attacks Neutralization via Data Set Randomization",
        "url": "http://arxiv.org/abs/2306.12161v1",
        "pub_date": "2023-06-21",
        "summary": "Adversarial attacks on deep-learning models pose a serious threat to their\nreliability and security. Existing defense mechanisms are narrow addressing a\nspecific type of attack or being vulnerable to sophisticated attacks. We\npropose a new defense mechanism that, while being focused on image-based\nclassifiers, is general with respect to the cited category. It is rooted on\nhyperspace projection. In particular, our solution provides a pseudo-random\nprojection of the original dataset into a new dataset. The proposed defense\nmechanism creates a set of diverse projected datasets, where each projected\ndataset is used to train a specific classifier, resulting in different trained\nclassifiers with different decision boundaries. During testing, it randomly\nselects a classifier to test the input. Our approach does not sacrifice\naccuracy over legitimate input. Other than detailing and providing a thorough\ncharacterization of our defense mechanism, we also provide a proof of concept\nof using four optimization-based adversarial attacks (PGD, FGSM, IGSM, and\nC\\&amp;W) and a generative adversarial attack testing them on the MNIST dataset.\nOur experimental results show that our solution increases the robustness of\ndeep learning models against adversarial attacks and significantly reduces the\nattack success rate by at least 89% for optimization attacks and 78% for\ngenerative attacks. We also analyze the relationship between the number of used\nhyperspaces and the efficacy of the defense mechanism. As expected, the two are\npositively correlated, offering an easy-to-tune parameter to enforce the\ndesired level of security. The generality and scalability of our solution and\nadaptability to different attack scenarios, combined with the excellent\nachieved results, other than providing a robust defense against adversarial\nattacks on deep learning networks, also lay the groundwork for future research\nin the field.",
        "translated": "对深度学习模型的对抗性攻击对其可靠性和安全性构成严重威胁。现有的防御机制针对的是特定类型的攻击或易受复杂攻击的攻击。我们提出了一种新的防御机制，虽然重点是基于图像的分类器，是一般方面的被引范畴。它植根于超空间投影。特别是，我们的解决方案提供了原始数据集到新数据集的伪随机投影。提出的防御机制创建一组不同的投影数据集，其中每个投影数据集用于训练一个特定的分类器，产生具有不同决策边界的不同训练分类器。在测试期间，它随机选择一个分类器来测试输入。我们的方法不会牺牲精确性而牺牲合法的输入。除了详细介绍和提供我们的防御机制的全面角色塑造外，我们还提供了使用四种基于优化的对抗性攻击(PGD、 FGSM、 IGSM 和 C & W)的概念证明，以及在 MNIST 数据集上测试它们的生成性对抗性攻击。实验结果表明，该方案提高了深度学习模型对攻击的鲁棒性，使优化攻击和生成攻击的攻击成功率分别降低了89% 和78% 。我们还分析了使用多维空间的数量与防御机制的效能之间的关系。正如预期的那样，这两者是正相关的，提供了一个易于调整的参数来实现所需的安全级别。我们的解决方案的通用性和可扩展性以及对不同攻击场景的适应性，结合优秀的成果，除了提供对深度学习网络上的敌对攻击的强大防御外，还为未来该领域的研究奠定了基础。"
    },
    {
        "title": "PrivSketch: A Private Sketch-based Frequency Estimation Protocol for\n  Data Streams",
        "url": "http://arxiv.org/abs/2306.12144v1",
        "pub_date": "2023-06-21",
        "summary": "Local differential privacy (LDP) has recently become a popular\nprivacy-preserving data collection technique protecting users' privacy. The\nmain problem of data stream collection under LDP is the poor utility due to\nmulti-item collection from a very large domain. This paper proposes PrivSketch,\na high-utility frequency estimation protocol taking advantage of sketches,\nsuitable for private data stream collection. Combining the proposed background\ninformation and a decode-first collection-side workflow, PrivSketch improves\nthe utility by reducing the errors introduced by the sketching algorithm and\nthe privacy budget utilization when collecting multiple items. We analytically\nprove the superior accuracy and privacy characteristics of PrivSketch, and also\nevaluate them experimentally. Our evaluation, with several diverse synthetic\nand real datasets, demonstrates that PrivSketch is 1-3 orders of magnitude\nbetter than the competitors in terms of utility in both frequency estimation\nand frequent item estimation, while being up to ~100x faster.",
        "translated": "本地差分隐私(lDP)最近成为一种流行的保护用户隐私的数据收集技术。LDP 下数据流采集的主要问题是由于从一个非常大的域进行多项采集而造成的效用差。本文提出了一种利用草图的高效率频率估计协议 PrivSketch，适用于私有数据流的采集。PrivSketch 将提出的背景信息和解码优先的收集端工作流结合起来，通过减少草图算法引入的错误和收集多个项目时的隐私预算利用率，提高了工作效率。分析证明了 PrivSketch 具有较高的准确性和隐私性，并对其进行了实验评价。我们的评估，通过几个不同的合成和真实的数据集，表明 PrivSketch 在频率估计和频繁项目估计方面的效用比竞争对手高出1-3个数量级，同时比竞争对手快约100倍。"
    },
    {
        "title": "A new color image secret sharing protocol",
        "url": "http://arxiv.org/abs/2306.12107v1",
        "pub_date": "2023-06-21",
        "summary": "Visual cryptography aims to protect images against their possible\nillegitimate use. Thus, one can cipher, hash, or add watermarks for protecting\ncopyright, among others. In this paper we provide a new solution to the problem\nof secret sharing for the case when the secret is an image. Our method combines\nthe Shamir scheme for secret sharing using finite fields of characteristic 2\nwith the CBC mode of operation of a secure symmetric cryptographic scheme like\nAES, so that the security relies on that of the mentioned techniques. The\nresulting shares have the same resolution as that of the original image. The\nidea of the method could be generalized to other multimedia formats like audio\nor video, adapting the method to the corresponding encoded information.",
        "translated": "可视密码旨在保护图像免受非法使用。因此，可以加密、散列或添加水印以保护版权。本文针对秘密是图像的情况，提出了一种新的秘密共享问题的解决方案。该方法将利用特征2有限域的 Shamir 秘密共享方案与 AES 等安全对称密码方案的 CBC 操作模式相结合，使其安全性依赖于上述技术。产生的共享具有与原始图像相同的分辨率。该方法的思想可以推广到其他多媒体格式，如音频或视频，使该方法适应相应的编码信息。"
    },
    {
        "title": "Cryptographic ransomware encryption detection: Survey",
        "url": "http://arxiv.org/abs/2306.12008v1",
        "pub_date": "2023-06-21",
        "summary": "The ransomware threat has loomed over our digital life since 1989. Criminals\nuse this type of cyber attack to lock or encrypt victims' data, often coercing\nthem to pay exorbitant amounts in ransom. The damage ransomware causes ranges\nfrom monetary losses paid for ransom at best to endangering human lives.\nCryptographic ransomware, where attackers encrypt the victim's data, stands as\nthe predominant ransomware variant. The primary characteristics of these\nattacks have remained the same since the first ransomware attack. For this\nreason, we consider this a key factor differentiating ransomware from other\ncyber attacks, making it vital in tackling the threat of cryptographic\nransomware. This paper proposes a cyber kill chain that describes the modern\ncrypto-ransomware attack. The survey focuses on the Encryption phase as\ndescribed in our proposed cyber kill chain and its detection techniques. We\nidentify three main methods used in detecting encryption-related activities by\nransomware, namely API and System calls, I/O monitoring, and file system\nactivities monitoring. Machine learning (ML) is a tool used in all three\nidentified methodologies, and some of the issues within the ML domain related\nto this survey are also covered as part of their respective methodologies. The\nsurvey of selected proposals is conducted through the prism of those three\nmethodologies, showcasing the importance of detecting ransomware during\npre-encryption and encryption activities and the windows of opportunity to do\nso. We also examine commercial crypto-ransomware protection and detection\nofferings and show the gap between academic research and commercial\napplications.",
        "translated": "自1989年以来，勒索软件的威胁一直笼罩着我们的数字生活。犯罪分子利用这种类型的网络攻击锁定或加密受害者的数据，往往强迫他们支付过高的赎金。勒索软件造成的损害范围很广，从最多支付赎金的金钱损失到危及人类生命。加密勒索软件，攻击者加密受害者的数据，是主要的勒索软件变体。这些攻击的主要特征自第一次勒索软件攻击以来一直保持不变。出于这个原因，我们认为这是区分勒索软件和其他网络攻击的一个关键因素，使其在应对加密勒索软件的威胁时至关重要。提出了一种描述现代密码勒索软件攻击的网络杀伤链。该调查的重点是加密阶段所描述的，在我们提出的网络杀伤链及其检测技术。我们确定了用于通过勒索软件检测加密相关活动的三种主要方法，即 API 和系统调用、 I/O 监视和文件系统活动监视。机器学习(ML)是一个工具，用于所有三个确定的方法，和机器学习领域的一些问题相关的这项调查也涵盖了作为其各自方法的一部分。对选定提案的调查是通过这三种方法的棱镜进行的，显示了在加密前和加密活动期间发现勒索软件的重要性以及发现勒索软件的机会之窗。我们还研究了商业加密勒索软件的保护和检测服务，并展示了学术研究和商业应用之间的差距。"
    },
    {
        "title": "Evading Forensic Classifiers with Attribute-Conditioned Adversarial\n  Faces",
        "url": "http://arxiv.org/abs/2306.13091v1",
        "pub_date": "2023-06-22",
        "summary": "The ability of generative models to produce highly realistic synthetic face\nimages has raised security and ethical concerns. As a first line of defense\nagainst such fake faces, deep learning based forensic classifiers have been\ndeveloped. While these forensic models can detect whether a face image is\nsynthetic or real with high accuracy, they are also vulnerable to adversarial\nattacks. Although such attacks can be highly successful in evading detection by\nforensic classifiers, they introduce visible noise patterns that are detectable\nthrough careful human scrutiny. Additionally, these attacks assume access to\nthe target model(s) which may not always be true. Attempts have been made to\ndirectly perturb the latent space of GANs to produce adversarial fake faces\nthat can circumvent forensic classifiers. In this work, we go one step further\nand show that it is possible to successfully generate adversarial fake faces\nwith a specified set of attributes (e.g., hair color, eye size, race, gender,\netc.). To achieve this goal, we leverage the state-of-the-art generative model\nStyleGAN with disentangled representations, which enables a range of\nmodifications without leaving the manifold of natural images. We propose a\nframework to search for adversarial latent codes within the feature space of\nStyleGAN, where the search can be guided either by a text prompt or a reference\nimage. We also propose a meta-learning based optimization strategy to achieve\ntransferable performance on unknown target models. Extensive experiments\ndemonstrate that the proposed approach can produce semantically manipulated\nadversarial fake faces, which are true to the specified attribute set and can\nsuccessfully fool forensic face classifiers, while remaining undetectable by\nhumans. Code: https://github.com/koushiksrivats/face_attribute_attack.",
        "translated": "生成模型产生高度逼真的合成人脸图像的能力引起了安全和伦理方面的关注。作为抵御这种假面的第一道防线，基于深度学习的法医分类器已经被开发出来。虽然这些法医模型能够高精度地检测出人脸图像是合成的还是真实的，但它们也容易受到敌对攻击。虽然这种攻击可以非常成功地躲避法医分类器的检测，但是它们引入了可见的噪音模式，通过仔细的人类检查可以检测到。此外，这些攻击假设对目标模型的访问，这可能并不总是正确的。有人试图直接扰乱 GAN 的潜在空间，制造出可以绕过法医分类器的敌对假面孔。在这项工作中，我们更进一步，表明有可能成功地生成具有特定属性集(例如，头发颜色，眼睛大小，种族，性别等)的敌对假面孔。为了实现这个目标，我们利用了最先进的生成模型 StyleGAN，它可以进行一系列的修改，而不用离开自然图像的流形。提出了一种在 StyleGAN 特征空间内搜索对手潜码的框架，该框架可以通过文本提示或参考图像来指导搜索。我们还提出了一种基于元学习的优化策略，以实现对未知目标模型的可转移性能。大量的实验表明，该方法可以产生语义操纵的敌对假面孔，这是真实的特定属性集，可以成功地欺骗法医面孔分类器，而仍然无法被人类检测到。密码:  https://github.com/koushiksrivats/face_attribute_attack。"
    },
    {
        "title": "Unitary Complexity and the Uhlmann Transformation Problem",
        "url": "http://arxiv.org/abs/2306.13073v1",
        "pub_date": "2023-06-22",
        "summary": "State transformation problems such as compressing quantum information or\nbreaking quantum commitments are fundamental quantum tasks. However, their\ncomputational difficulty cannot easily be characterized using traditional\ncomplexity theory, which focuses on tasks with classical inputs and outputs.\n  To study the complexity of such state transformation tasks, we introduce a\nframework for unitary synthesis problems, including notions of reductions and\nunitary complexity classes. We use this framework to study the complexity of\ntransforming one entangled state into another via local operations. We\nformalize this as the Uhlmann Transformation Problem, an algorithmic version of\nUhlmann's theorem. Then, we prove structural results relating the complexity of\nthe Uhlmann Transformation Problem, polynomial space quantum computation, and\nzero knowledge protocols.\n  The Uhlmann Transformation Problem allows us to characterize the complexity\nof a variety of tasks in quantum information processing, including decoding\nnoisy quantum channels, breaking falsifiable quantum cryptographic assumptions,\nimplementing optimal prover strategies in quantum interactive proofs, and\ndecoding the Hawking radiation of black holes. Our framework for unitary\ncomplexity thus provides new avenues for studying the computational complexity\nof many natural quantum information processing tasks.",
        "translated": "状态转换问题，如压缩量子信息或打破量子承诺是基本的量子任务。然而，用传统的复杂性理论来描述它们的计算难度并不容易，因为传统的复杂性理论关注的是具有经典输入和输出的任务。为了研究这类状态转换任务的复杂性，我们引入了酉综合问题的一个框架，包括约化和酉复杂类的概念。我们使用这个框架来研究通过局域运算将一个纠缠态转化为另一个纠缠态的复杂性。我们将其形式化为乌尔曼变换问题，一个乌尔曼定理的算法版本。然后，我们证明了结构化结果与乌尔曼变换问题的复杂性、 PSPACE 量子计算和零知识协议有关。乌尔曼变换问题允许我们描述量子信息处理中各种任务的复杂性，包括解码嘈杂的量子通道，打破可证伪的量子密码假设，在量子交互证明中实现最佳证明策略，以及解码黑洞的霍金辐射。因此，我们的幺正复杂度框架为研究许多自然量子信息处理任务的计算复杂度提供了新的途径。"
    },
    {
        "title": "Quantum Pufferfish Privacy: A Flexible Privacy Framework for Quantum\n  Systems",
        "url": "http://arxiv.org/abs/2306.13054v1",
        "pub_date": "2023-06-22",
        "summary": "We propose a versatile privacy framework for quantum systems, termed quantum\npufferfish privacy (QPP). Inspired by classical pufferfish privacy, our\nformulation generalizes and addresses limitations of quantum differential\nprivacy by offering flexibility in specifying private information, feasible\nmeasurements, and domain knowledge. We show that QPP can be equivalently\nformulated in terms of the Datta-Leditzky information spectrum divergence, thus\nproviding the first operational interpretation thereof. We reformulate this\ndivergence as a semi-definite program and derive several properties of it,\nwhich are then used to prove convexity, composability, and post-processing of\nQPP mechanisms. Parameters that guarantee QPP of the depolarization mechanism\nare also derived. We analyze the privacy-utility tradeoff of general QPP\nmechanisms and, again, study the depolarization mechanism as an explicit\ninstance. The QPP framework is then applied to privacy auditing for identifying\nprivacy violations via a hypothesis testing pipeline that leverages quantum\nalgorithms. Connections to quantum fairness and other quantum divergences are\nalso explored and several variants of QPP are examined.",
        "translated": "我们提出了一个通用的量子系统隐私框架，称为量子河豚隐私(QPP)。受经典河豚隐私的启发，我们的公式通过在指定私人信息、可行测量和领域知识方面提供灵活性，概括并解决了量子差分隐私的局限性。我们证明了 QPP 可以等价地用 Datta-Leditzky 信息谱发散来表示，从而提供了它的第一个运算解释。我们把这种发散重新表述为一个半定规划，并导出了它的几个性质，然后用这些性质来证明 QPP 机构的凸性、可组合性和后处理。推导出了保证去极化机制 QPP 的参数。我们分析了一般 QPP 机制的隐私-效用权衡，并再次作为一个明确的实例研究了去极化机制。然后将 QPP 框架应用于隐私审计，通过利用量子算法的假设测试流水线来识别隐私侵犯。还探讨了与量子公平性和其他量子发散的联系，并研究了 QPP 的几种变体。"
    },
    {
        "title": "Impacts and Risk of Generative AI Technology on Cyber Defense",
        "url": "http://arxiv.org/abs/2306.13033v1",
        "pub_date": "2023-06-22",
        "summary": "Generative Artificial Intelligence (GenAI) has emerged as a powerful\ntechnology capable of autonomously producing highly realistic content in\nvarious domains, such as text, images, audio, and videos. With its potential\nfor positive applications in creative arts, content generation, virtual\nassistants, and data synthesis, GenAI has garnered significant attention and\nadoption. However, the increasing adoption of GenAI raises concerns about its\npotential misuse for crafting convincing phishing emails, generating\ndisinformation through deepfake videos, and spreading misinformation via\nauthentic-looking social media posts, posing a new set of challenges and risks\nin the realm of cybersecurity. To combat the threats posed by GenAI, we propose\nleveraging the Cyber Kill Chain (CKC) to understand the lifecycle of\ncyberattacks, as a foundational model for cyber defense. This paper aims to\nprovide a comprehensive analysis of the risk areas introduced by the offensive\nuse of GenAI techniques in each phase of the CKC framework. We also analyze the\nstrategies employed by threat actors and examine their utilization throughout\ndifferent phases of the CKC, highlighting the implications for cyber defense.\nAdditionally, we propose GenAI-enabled defense strategies that are both\nattack-aware and adaptive. These strategies encompass various techniques such\nas detection, deception, and adversarial training, among others, aiming to\neffectively mitigate the risks posed by GenAI-induced cyber threats.",
        "translated": "生成性人工智能(GenAI)已经成为一种强大的技术，能够自动生成各种领域的高度真实的内容，如文本、图像、音频和视频。凭借其在创意艺术、内容生成、虚拟助手和数据合成等方面的潜力，GenAI 获得了广泛的关注和采用。然而，GenAI 的日益普及引发了人们的担忧，即它可能被滥用，用于制作令人信服的钓鱼电子邮件、通过深度伪造视频制造虚假信息，以及通过看似真实的社交媒体帖子传播虚假信息，从而在网络安全领域构成一系列新的挑战和风险。为了应对 GenAI 带来的威胁，我们提出利用网络杀伤链(CKC)来理解网络攻击的生命周期，作为网络防御的基础模型。本文旨在全面分析在 CKC 框架的每个阶段进攻性地使用 GenAI 技术所引入的风险领域。我们还分析了威胁行为者所使用的策略，并检查了它们在 CKC 不同阶段的使用情况，强调了对网络防御的影响。此外，我们还提出了基于 GenAI 的攻击感知和自适应防御策略。这些策略包括各种技术，如侦测、欺骗和对抗性训练等，旨在有效地减轻由 GenAI 引起的网络威胁造成的风险。"
    },
    {
        "title": "Online Self-Supervised Learning in Machine Learning Intrusion Detection\n  for the Internet of Things",
        "url": "http://arxiv.org/abs/2306.13030v1",
        "pub_date": "2023-06-22",
        "summary": "This paper proposes a novel Self-Supervised Intrusion Detection (SSID)\nframework, which enables a fully online Machine Learning (ML) based Intrusion\nDetection System (IDS) that requires no human intervention or prior off-line\nlearning. The proposed framework analyzes and labels incoming traffic packets\nbased only on the decisions of the IDS itself using an Auto-Associative Deep\nRandom Neural Network, and on an online estimate of its statistically measured\ntrustworthiness. The SSID framework enables IDS to adapt rapidly to\ntime-varying characteristics of the network traffic, and eliminates the need\nfor offline data collection. This approach avoids human errors in data\nlabeling, and human labor and computational costs of model training and data\ncollection. The approach is experimentally evaluated on public datasets and\ncompared with well-known ML models, showing that this SSID framework is very\nuseful and advantageous as an accurate and online learning ML-based IDS for IoT\nsystems.",
        "translated": "本文提出了一个新的自我监督入侵检测(SSID)框架，它可以实现一个完全基于在线机器学习(ML)的入侵预防系统(IDS) ，不需要人工干预或事先离线学习。该框架仅根据入侵检测系统自身的决策，使用自联想深度随机神经网络对传入的流量数据包进行分析和标记，并对其统计测量的可信度进行在线估计。SSID 框架使 IDS 能够快速适应网络流量的时变特性，并消除了离线数据收集的需要。这种方法避免了数据标记中的人为错误，以及模型训练和数据收集的人力和计算成本。该方法在公共数据集上进行了实验评估，并与已知的机器学习模型进行了比较，结果表明该 SSID 框架对于物联网系统中基于机器学习的入侵检测系统是非常有用和有利的。"
    },
    {
        "title": "Decentralized Online Federated G-Network Learning for Lightweight\n  Intrusion Detection",
        "url": "http://arxiv.org/abs/2306.13029v1",
        "pub_date": "2023-06-22",
        "summary": "Cyberattacks are increasingly threatening networked systems, often with the\nemergence of new types of unknown (zero-day) attacks and the rise of vulnerable\ndevices. While Machine Learning (ML)-based Intrusion Detection Systems (IDSs)\nhave been shown to be extremely promising in detecting these attacks, the need\nto learn large amounts of labelled data often limits the applicability of\nML-based IDSs to cybersystems that only have access to private local data. To\naddress this issue, this paper proposes a novel Decentralized and Online\nFederated Learning Intrusion Detection (DOF-ID) architecture. DOF-ID is a\ncollaborative learning system that allows each IDS used for a cybersystem to\nlearn from experience gained in other cybersystems in addition to its own local\ndata without violating the data privacy of other systems. As the performance\nevaluation results using public Kitsune and Bot-IoT datasets show, DOF-ID\nsignificantly improves the intrusion detection performance in all collaborating\nnodes simultaneously with acceptable computation time for online learning.",
        "translated": "网络攻击对网络系统的威胁越来越大，通常伴随着新型未知(零日)攻击的出现和易受攻击设备的增加。基于机器学习(ML)的入侵检测系统(IDS)在检测这些攻击方面已经被证明是非常有前途的，但是需要学习大量的标记数据往往限制了基于 ML 的入侵检测系统对只能访问私有本地数据的网络系统的适用性。为了解决这一问题，本文提出了一种新的分布式在线联邦学习入侵检测(DOF-ID)体系结构。DOF-id 是一个合作学习系统，让每个用于网络系统的 IDS 除了学习自己的本地数据之外，还可以学习其他网络系统的经验，而不会侵犯其他系统的数据隐私。使用公共 Kitsune 和 bot-IoT 数据集进行的性能评估结果显示，DOF-ID 显著提高了所有协作节点的入侵检测性能，同时也为在线学习提供了可接受的计算时间。"
    },
    {
        "title": "Towards More Realistic Membership Inference Attacks on Large Diffusion\n  Models",
        "url": "http://arxiv.org/abs/2306.12983v1",
        "pub_date": "2023-06-22",
        "summary": "Generative diffusion models, including Stable Diffusion and Midjourney, can\ngenerate visually appealing, diverse, and high-resolution images for various\napplications. These models are trained on billions of internet-sourced images,\nraising significant concerns about the potential unauthorized use of\ncopyright-protected images. In this paper, we examine whether it is possible to\ndetermine if a specific image was used in the training set, a problem known in\nthe cybersecurity community and referred to as a membership inference attack.\nOur focus is on Stable Diffusion, and we address the challenge of designing a\nfair evaluation framework to answer this membership question. We propose a\nmethodology to establish a fair evaluation setup and apply it to Stable\nDiffusion, enabling potential extensions to other generative models. Utilizing\nthis evaluation setup, we execute membership attacks (both known and newly\nintroduced). Our research reveals that previously proposed evaluation setups do\nnot provide a full understanding of the effectiveness of membership inference\nattacks. We conclude that the membership inference attack remains a significant\nchallenge for large diffusion models (often deployed as black-box systems),\nindicating that related privacy and copyright issues will persist in the\nforeseeable future.",
        "translated": "生成扩散模型，包括稳定扩散和 Midjourney，可以产生视觉吸引力，多样化和高分辨率图像的各种应用。这些模型是在数十亿互联网来源的图像上训练出来的，引起了人们对未经授权使用受版权保护的图像的严重关切。在本文中，我们检查是否有可能确定一个特定的图像是否用于训练集，这个问题在网络安全界已知，称为成员推断攻击。我们的重点是稳定扩散，我们解决的挑战，设计一个公平的评估框架，以回答这个成员资格的问题。我们提出了一种方法来建立一个公平的评估设置，并应用到稳定扩散，使潜在的扩展到其他生成模型。利用这个评估设置，我们执行成员资格攻击(已知的和新引入的)。我们的研究表明，以前提出的评估设置并没有提供一个充分的理解成员推理攻击的有效性。我们的结论是，成员推理攻击仍然是一个重大的挑战，大型扩散模型(通常部署为黑盒系统) ，表明相关的隐私和版权问题将持续在可预见的未来。"
    },
    {
        "title": "On the Direct Construction of MDS and Near-MDS Matrices",
        "url": "http://arxiv.org/abs/2306.12848v1",
        "pub_date": "2023-06-22",
        "summary": "The optimal branch number of MDS matrices makes them a preferred choice for\ndesigning diffusion layers in many block ciphers and hash functions.\nConsequently, various methods have been proposed for designing MDS matrices,\nincluding search and direct methods. While exhaustive search is suitable for\nsmall order MDS matrices, direct constructions are preferred for larger orders\ndue to the vast search space involved. In the literature, there has been\nextensive research on the direct construction of MDS matrices using both\nrecursive and nonrecursive methods. On the other hand, in lightweight\ncryptography, Near-MDS (NMDS) matrices with sub-optimal branch numbers offer a\nbetter balance between security and efficiency as a diffusion layer compared to\nMDS matrices. However, no direct construction method is available in the\nliterature for constructing recursive NMDS matrices. This paper introduces some\ndirect constructions of NMDS matrices in both nonrecursive and recursive\nsettings. Additionally, it presents some direct constructions of nonrecursive\nMDS matrices from the generalized Vandermonde matrices. We propose a method for\nconstructing involutory MDS and NMDS matrices using generalized Vandermonde\nmatrices. Furthermore, we prove some folklore results that are used in the\nliterature related to the NMDS code.",
        "translated": "MDS 矩阵的最佳分支数使其成为许多分组密码和哈希函数扩散层设计的首选。因此，人们提出了各种设计 MDS 矩阵的方法，包括搜索法和直接法。尽管穷举搜索适用于小阶 MDS 矩阵，但由于所涉及的搜索空间很大，直接构造更适用于大阶 MDS 矩阵。在文献中，已经广泛地研究了用递归和非递归方法直接构造 MDS 矩阵。另一方面，在轻量级密码体制中，具有次优分支数目的近 MDS (NMDS)矩阵作为扩散层，比 MDS 矩阵能更好地平衡安全性和效率。然而，目前文献中还没有直接构造递归 NMDS 矩阵的方法。本文介绍了 NMDS 矩阵在非递归和递归环境下的一些直接构造。此外，还从广义 Vandermonde 矩阵出发，给出了一些非递归 MDS 矩阵的直接构造。提出了一种利用广义范德蒙矩阵构造对合 MDS 和 NMDS 矩阵的方法。此外，我们还证明了一些民间传说的结果，这些结果被用于与 NMDS 代码相关的文献中。"
    },
    {
        "title": "XACML Extension for Graphs: Flexible Authorization Policy Specification\n  and Datastore-independent Enforcement",
        "url": "http://arxiv.org/abs/2306.12819v1",
        "pub_date": "2023-06-22",
        "summary": "The increasing use of graph-structured data for business- and\nprivacy-critical applications requires sophisticated, flexible and fine-grained\nauthorization and access control. Currently, role-based access control is\nsupported in graph databases, where access to objects is restricted via roles.\nThis does not take special properties of graphs into account such as vertices\nand edges along the path between a given subject and resource. In previous\niterations of our research, we started to design an authorization policy\nlanguage and access control model, which considers the specification of graph\npaths and enforces them in the multi-model database ArangoDB. Since this\napproach is promising to consider graph characteristics in data protection, we\nimprove the language in this work to provide flexible path definitions and\nspecifying edges as protected resources. Furthermore, we introduce a method for\na datastore-independent policy enforcement. Besides discussing the latest work\nin our XACML4G model, which is an extension to the Extensible Access Control\nMarkup Language (XACML), we demonstrate our prototypical implementation with a\nreal case and give an outlook on performance.",
        "translated": "图形结构数据越来越多地用于业务和隐私关键型应用程序，需要复杂、灵活和细粒度的授权和访问控制。目前，图形数据库支持以角色为基础的存取控制，通过角色访问对象受到限制。这没有考虑到图的特殊属性，例如在给定主题和资源之间的路径上的顶点和边。在前面的研究中，我们开始设计一种授权策略语言和访问控制模型，该模型考虑了图路径的规范，并在多模型数据库 ArangoDB 中实施。由于该方法有望在数据保护中考虑图的特性，因此我们改进了该语言，提供了灵活的路径定义，并指定了边作为保护资源。此外，我们还介绍了一种独立于数据存储的策略实施方法。除了讨论可扩展访问控制标记语言(XACML)的扩展 XACML4G 模型中的最新工作之外，我们还用一个实际案例演示了我们的原型实现，并给出了性能展望。"
    },
    {
        "title": "On the Construction of Near-MDS Matrices",
        "url": "http://arxiv.org/abs/2306.12791v1",
        "pub_date": "2023-06-22",
        "summary": "The optimal branch number of MDS matrices makes them a preferred choice for\ndesigning diffusion layers in many block ciphers and hash functions. However,\nin lightweight cryptography, Near-MDS (NMDS) matrices with sub-optimal branch\nnumbers offer a better balance between security and efficiency as a diffusion\nlayer, compared to MDS matrices. In this paper, we study NMDS matrices,\nexploring their construction in both recursive and nonrecursive settings. We\nprovide several theoretical results and explore the hardware efficiency of the\nconstruction of NMDS matrices. Additionally, we make comparisons between the\nresults of NMDS and MDS matrices whenever possible. For the recursive approach,\nwe study the DLS matrices and provide some theoretical results on their use.\nSome of the results are used to restrict the search space of the DLS matrices.\nWe also show that over a field of characteristic 2, any sparse matrix of order\n$n\\geq 4$ with fixed XOR value of 1 cannot be an NMDS when raised to a power of\n$k\\leq n$. Following that, we use the generalized DLS (GDLS) matrices to\nprovide some lightweight recursive NMDS matrices of several orders that perform\nbetter than the existing matrices in terms of hardware cost or the number of\niterations. For the nonrecursive construction of NMDS matrices, we study\nvarious structures, such as circulant and left-circulant matrices, and their\ngeneralizations: Toeplitz and Hankel matrices. In addition, we prove that\nToeplitz matrices of order $n&gt;4$ cannot be simultaneously NMDS and involutory\nover a field of characteristic 2. Finally, we use GDLS matrices to provide some\nlightweight NMDS matrices that can be computed in one clock cycle. The proposed\nnonrecursive NMDS matrices of orders 4, 5, 6, 7, and 8 can be implemented with\n24, 50, 65, 96, and 108 XORs over $\\mathbb{F}_{2^4}$, respectively.",
        "translated": "MDS 矩阵的最佳分支数使其成为许多分组密码和哈希函数扩散层设计的首选。然而，在轻量级密码体制中，具有次优分支数的近 MDS (NMDS)矩阵作为扩散层，在安全性和效率之间提供了一个比 MDS 矩阵更好的平衡。本文研究了 NMDS 矩阵，探讨了它们在递归和非递归环境下的构造方法。我们提供了一些理论结果，并探讨了构造 NMDS 矩阵的硬件效率。此外，我们还尽可能对 NMDS 和 MDS 矩阵的结果进行了比较。对于递归方法，我们研究了 DLS 矩阵，并给出了它们的一些理论应用结果。其中一些结果被用来限制 DLS 矩阵的搜索空间。我们还证明了在特征值为2的域上，任何具有固定 XOR 值为1的 n 阶稀疏矩阵 $n-geq-4-当提高到 $k-leq-n-$的幂时都不能成为 NMDS。接着，我们利用广义 DLS (GDLS)矩阵来提供一些轻量级的递归 NMDS 矩阵，这些递归 NMDS 矩阵在硬件成本和迭代次数方面都优于现有矩阵。对于 NMDS 矩阵的非递归构造，我们研究了循环矩阵和左循环矩阵等各种结构及其推广: Toeplitz 矩阵和 Hankel 矩阵。另外，我们证明了在特征2域上，n > 4阶 Toeplitz 矩阵不能同时是 NMDS 和对合矩阵。最后，我们使用 GDLS 矩阵来提供一些可以在一个时钟周期内计算的轻量级 NMDS 矩阵。所提出的4,5,6,7和8阶非递归 NMDS 矩阵可以分别用 $mathbb { F } _ {2 ^ 4} $上的24,50,65,96和108个 XOR 实现。"
    },
    {
        "title": "Creating Valid Adversarial Examples of Malware",
        "url": "http://arxiv.org/abs/2306.13587v1",
        "pub_date": "2023-06-23",
        "summary": "Machine learning is becoming increasingly popular as a go-to approach for\nmany tasks due to its world-class results. As a result, antivirus developers\nare incorporating machine learning models into their products. While these\nmodels improve malware detection capabilities, they also carry the disadvantage\nof being susceptible to adversarial attacks. Although this vulnerability has\nbeen demonstrated for many models in white-box settings, a black-box attack is\nmore applicable in practice for the domain of malware detection. We present a\ngenerator of adversarial malware examples using reinforcement learning\nalgorithms. The reinforcement learning agents utilize a set of\nfunctionality-preserving modifications, thus creating valid adversarial\nexamples. Using the proximal policy optimization (PPO) algorithm, we achieved\nan evasion rate of 53.84% against the gradient-boosted decision tree (GBDT)\nmodel. The PPO agent previously trained against the GBDT classifier scored an\nevasion rate of 11.41% against the neural network-based classifier MalConv and\nan average evasion rate of 2.31% against top antivirus programs. Furthermore,\nwe discovered that random application of our functionality-preserving portable\nexecutable modifications successfully evades leading antivirus engines, with an\naverage evasion rate of 11.65%. These findings indicate that machine\nlearning-based models used in malware detection systems are vulnerable to\nadversarial attacks and that better safeguards need to be taken to protect\nthese systems.",
        "translated": "由于机器学习的世界级成果，它作为一种处理许多任务的首选方法正变得越来越流行。因此，防病毒开发人员正在将机器学习模型整合到他们的产品中。虽然这些模型提高了恶意软件的检测能力，但它们也带来了容易受到敌对攻击的缺点。尽管这种漏洞已经在许多白盒设置模型中得到了证明，但黑盒攻击在恶意软件检测领域的实践中更为适用。我们提出了一个使用强化学习算法生成敌对恶意软件的例子。强化学习代理人利用一系列保留功能的修改，从而创造出有效的对抗性例子。利用近似策略优化(PPO)算法，对梯度增强决策树(GBDT)模型的规避率达到了53.84% 。先前针对 GBDT 分类器训练的 PPO 代理针对基于神经网络的分类器 MalConv 的逃避率为11.41% ，针对顶级杀毒程序的平均逃避率为2.31% 。此外，我们发现，随机应用我们的功能保持 Portable Executable 修改成功地规避领先的防病毒引擎，平均规避率为11.65% 。这些发现表明，在恶意软件检测系统中使用的基于机器学习的模型很容易受到敌对攻击，需要采取更好的保障措施来保护这些系统。"
    },
    {
        "title": "The Landscape of Computing Symmetric $n$-Variable Functions with $2n$\n  Cards",
        "url": "http://arxiv.org/abs/2306.13551v1",
        "pub_date": "2023-06-23",
        "summary": "Secure multi-party computation using a physical deck of cards, often called\ncard-based cryptography, has been extensively studied during the past decade.\nMany card-based protocols to securely compute various Boolean functions have\nbeen developed. As each input bit is typically encoded by two cards, computing\nan $n$-variable Boolean function requires at least $2n$ cards. We are\ninterested in optimal protocols that use exactly $2n$ cards. In particular, we\nfocus on symmetric functions, where the output only depends on the number of 1s\nin the inputs. In this paper, we formulate the problem of developing $2n$-card\nprotocols to compute $n$-variable symmetric Boolean functions by classifying\nall such functions into several NPN-equivalence classes. We then summarize\nexisting protocols that can compute some representative functions from these\nclasses, and also solve some of the open problems by developing protocols to\ncompute particular functions in the cases $n=4$, $5$, $6$, and $7$.",
        "translated": "过去10年，人们广泛研究了使用一副物理卡片(通常称为基于卡片的密码学)的安全多方计算。许多基于卡片的安全计算各种布尔函数的协议已经被开发出来。由于每个输入位通常由两张卡编码，因此计算一个 $n $- 可变布尔函数需要至少200万美元的卡。我们感兴趣的是使用200万美元卡的最佳协议。我们特别关注对称函数，其中输出只取决于输入中的1s 个数。本文通过将 $n 变量对称布尔函数分类为几个 NPN 等价类，提出了开发 $2n 卡协议来计算 $n 变量对称布尔函数的问题。然后，我们总结了现有的协议，这些协议可以从这些类中计算出一些代表性的函数，并且通过开发协议来计算特定的函数，例如 $n = 4 $，$5 $，$6 $和 $7 $，从而解决了一些未解决的问题。"
    },
    {
        "title": "Fuzzification-based Feature Selection for Enhanced Website Content\n  Encryption",
        "url": "http://arxiv.org/abs/2306.13548v1",
        "pub_date": "2023-06-23",
        "summary": "We propose a novel approach that utilizes fuzzification theory to perform\nfeature selection on website content for encryption purposes. Our objective is\nto identify and select the most relevant features from the website by\nharnessing the principles of fuzzy logic. Fuzzification allows us to transform\nthe crisp website content into fuzzy representations, enabling a more nuanced\nanalysis of their characteristics. By considering the degree of membership of\neach feature in different fuzzy categories, we can evaluate their importance\nand relevance for encryption. This approach enables us to prioritize and focus\non the features that exhibit higher membership degrees, indicating their\nsignificance in the encryption process. By employing fuzzification-based\nfeature selection, we aim to enhance the effectiveness and efficiency of\nwebsite content encryption, ultimately improving the overall internet security.",
        "translated": "我们提出了一种新的方法，利用模糊化理论对网站内容进行特征选择，以达到加密的目的。我们的目标是通过利用模糊逻辑的原则，从网站中识别和选择最相关的特性。模糊化允许我们将清晰的网站内容转换为模糊表示，从而能够对其特征进行更细致入微的分析。通过考虑每个特征在不同模糊类别中的隶属度，我们可以评估它们对加密的重要性和相关性。这种方法使我们能够优先考虑和关注那些表现出更高的成员等级的特征，表明它们在加密过程中的重要性。采用基于模糊化的特征选择方法，提高网站内容加密的有效性和效率，最终提高网络的整体安全性。"
    },
    {
        "title": "Full Transparency in DBI frameworks",
        "url": "http://arxiv.org/abs/2306.13529v1",
        "pub_date": "2023-06-23",
        "summary": "Following the increasing trends of malicious applications or cyber threats in\ngeneral, program analysis has become a ubiquitous technique in extracting\nrelevant features. The current state-of-the-art solutions seem to fall behind\nnew techniques. For instance, dynamic binary instrumentation (DBI) provides\nsome promising results, but falls short when it comes to ease of use and\novercoming analysis evasion. In this regard, we propose a two-fold\ncontribution. First, we introduce COBAI (Complex Orchestrator for Binary\nAnalysis and Instrumentation), a DBI framework designed for malware analysis,\nprioritizing ease-of-use and analysis transparency, without imposing a\nsignificant overhead. Second, we introduce an aggregated test suite intended to\nstand as a benchmark in determining the quality of an analysis solution\nregarding the protection against evasion mechanisms. The efficiency of our\nsolution is validated by a careful evaluation taking into consideration other\nDBI frameworks, analysis environments, and the proposed benchmark.",
        "translated": "随着恶意应用程序或网络威胁日益增长的趋势，程序分析已经成为提取相关特征的普遍技术。目前最先进的解决方案似乎落后于新技术。例如，动态二进制检测(DBI)提供了一些有希望的结果，但在易用性和克服分析规避方面还有不足。在这方面，我们提出了双重贡献。首先，我们介绍 COBAI (用于二进制分析和仪器的复杂协调器) ，这是一个为恶意软件分析而设计的 DBI 框架，它优先考虑易用性和分析透明性，而不会带来大量的开销。其次，我们引入了一个聚合测试套件，目的是作为一个基准来确定关于防范逃避机制的分析解决方案的质量。考虑到其他 DBI 框架、分析环境和提出的基准，我们的解决方案的效率通过仔细的评估得到了验证。"
    },
    {
        "title": "Preventing EFail Attacks with Client-Side WebAssembly: The Case of Swiss\n  Post's IncaMail",
        "url": "http://arxiv.org/abs/2306.13388v1",
        "pub_date": "2023-06-23",
        "summary": "Traditional email encryption schemes are vulnerable to EFail attacks, which\nexploit the lack of message authentication by manipulating ciphertexts and\nexfiltrating plaintext via HTML backchannels. Swiss Post's IncaMail, a secure\nemail service for transmitting legally binding, encrypted, and verifiable\nemails, counters EFail attacks using an authenticated-encryption with\nassociated data (AEAD) encryption scheme to ensure message privacy and\nauthentication between servers. IncaMail relies on a trusted infrastructure\nbackend and encrypts messages per user policy. This paper presents a revised\nIncaMail architecture that offloads the majority of cryptographic operations to\nclients, offering benefits such as reduced computational load and energy\nfootprint, relaxed trust assumptions, and per-message encryption key policies.\nOur proof-of-concept prototype and benchmarks demonstrate the robustness of the\nproposed scheme, with client-side WebAssembly-based cryptographic operations\nyielding significant performance improvements (up to ~14x) over conventional\nJavaScript implementations.",
        "translated": "传统的邮件加密方案很容易受到 EFail 攻击，这种攻击通过操纵加密文本和通过 HTML 反向通道提取明文来利用信息认证的缺乏。瑞士邮政的 IncaMail 是一种安全的电子邮件服务，用于传输具有法律约束力的、加密的和可验证的电子邮件，它使用一种带有关联数据(AEAD)加密方案的认证加密来抵御 EFail 攻击，以确保信息隐私和服务器之间的认证。IncaMail 依赖于受信任的基础设施后端，并根据用户策略对消息进行加密。本文提出了一种改进的 IncaMail 体系结构，该体系结构将大部分加密操作卸载给客户端，提供了诸如减少计算负载和能量占用、放松信任假设和每消息加密密钥策略等优点。我们的概念验证原型和基准测试证明了提出的方案的健壮性，与传统的 JavaScript 实现相比，基于客户端 WebAssembly 的加密操作产生了显著的性能改进(最多14倍)。"
    },
    {
        "title": "Differentially Private Streaming Data Release under Temporal\n  Correlations via Post-processing",
        "url": "http://arxiv.org/abs/2306.13293v2",
        "pub_date": "2023-06-23",
        "summary": "The release of differentially private streaming data has been extensively\nstudied, yet striking a good balance between privacy and utility on temporally\ncorrelated data in the stream remains an open problem. Existing works focus on\nenhancing privacy when applying differential privacy to correlated data,\nhighlighting that differential privacy may suffer from additional privacy\nleakage under correlations; consequently, a small privacy budget has to be used\nwhich worsens the utility. In this work, we propose a post-processing framework\nto improve the utility of differential privacy data release under temporal\ncorrelations. We model the problem as a maximum posterior estimation given the\nreleased differentially private data and correlation model and transform it\ninto nonlinear constrained programming. Our experiments on synthetic datasets\nshow that the proposed approach significantly improves the utility and accuracy\nof differentially private data by nearly a hundred times in terms of mean\nsquare error when a strict privacy budget is given.",
        "translated": "差别私有流数据的发布已经得到了广泛的研究，然而在流中时间相关数据的隐私和效用之间取得良好的平衡仍然是一个悬而未决的问题。现有的工作着眼于在应用相关数据差分隐私时提高隐私保护，强调在相关性下，差分隐私可能会遭受额外的隐私泄露，因此，必须使用小额的隐私预算，这会使效用恶化。在这项工作中，我们提出了一个后处理框架，以改善差分隐私数据在时间相关性下发布的效用。我们将问题建模为给定发布的差分私有数据和相关模型的最大后验估计，并将其转化为非线性约束规划。我们在合成数据集上的实验表明，当给定严格的隐私预算时，该方法在均方误差方面显著提高了差分私有数据的实用性和准确性近百倍。"
    },
    {
        "title": "A First Order Meta Stackelberg Method for Robust Federated Learning\n  (Technical Report)",
        "url": "http://arxiv.org/abs/2306.13273v1",
        "pub_date": "2023-06-23",
        "summary": "Recent research efforts indicate that federated learning (FL) systems are\nvulnerable to a variety of security breaches. While numerous defense strategies\nhave been suggested, they are mainly designed to counter specific attack\npatterns and lack adaptability, rendering them less effective when facing\nuncertain or adaptive threats. This work models adversarial FL as a Bayesian\nStackelberg Markov game (BSMG) between the defender and the attacker to address\nthe lack of adaptability to uncertain adaptive attacks. We further devise an\neffective meta-learning technique to solve for the Stackelberg equilibrium,\nleading to a resilient and adaptable defense. The experiment results suggest\nthat our meta-Stackelberg learning approach excels in combating intense model\npoisoning and backdoor attacks of indeterminate types.",
        "translated": "最近的研究表明，联邦学习(FL)系统容易受到各种数字证书认证机构的影响。虽然提出了许多防御策略，但它们主要是针对特定的攻击模式而设计的，缺乏适应性，使其在面对不确定或适应性威胁时效果较差。本研究将防御者与攻击者之间的对抗性 FL 建模为一个贝叶斯 Stackelberg 马尔可夫博弈(BSMG) ，以解决对不确定性自适应攻击适应性不足的问题。我们进一步设计了一个有效的元学习技术来解决 Stackelberg 均衡，导致一个弹性和适应性的防御。实验结果表明，我们的元 Stackelberg 学习方法优于对强烈的模型中毒和不确定类型的后门攻击。"
    },
    {
        "title": "Visual Adversarial Examples Jailbreak Large Language Models",
        "url": "http://arxiv.org/abs/2306.13213v1",
        "pub_date": "2023-06-22",
        "summary": "Recently, there has been a surge of interest in introducing vision into Large\nLanguage Models (LLMs). The proliferation of large Visual Language Models\n(VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence\nof advancements in both visual and language foundation models. Yet, the risks\nassociated with this integrative approach are largely unexamined. In this\npaper, we shed light on the security and safety implications of this trend.\nFirst, we underscore that the continuous and high-dimensional nature of the\nadditional visual input space intrinsically makes it a fertile ground for\nadversarial attacks. This unavoidably expands the attack surfaces of LLMs.\nSecond, we highlight that the broad functionality of LLMs also presents visual\nattackers with a wider array of achievable adversarial objectives, extending\nthe implications of security failures beyond mere misclassification. To\nelucidate these risks, we study adversarial examples in the visual input space\nof a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms\nthat can refuse harmful instructions, we present visual adversarial examples\nthat can circumvent the safety mechanisms and provoke harmful behaviors of the\nmodel. Remarkably, we discover that adversarial examples, even if optimized on\na narrow, manually curated derogatory corpus against specific social groups,\ncan universally jailbreak the model's safety mechanisms. A single such\nadversarial example can generally undermine MiniGPT-4's safety, enabling it to\nheed a wide range of harmful instructions and produce harmful content far\nbeyond simply imitating the derogatory corpus used in optimization. Unveiling\nthese risks, we accentuate the urgent need for comprehensive risk assessments,\nrobust defense strategies, and the implementation of responsible practices for\nthe secure and safe utilization of VLMs.",
        "translated": "最近，在大型语言模型(LLM)中引入视觉的兴趣激增。大型可视化语言模型(VLM)的增殖，例如 Flamingo、 BLIP-2和 GPT-4，标志着可视化模型和语言基础模型中令人兴奋的进步趋同。然而，与这种综合方法相关的风险在很大程度上没有得到检验。在本文中，我们阐明了这一趋势的安全和安全含义。首先，我们强调，额外的视觉输入空间的连续性和高维性本质上使其成为对抗性攻击的沃土。这不可避免地扩展了 LLM 的攻击面。其次，我们强调 LLM 的广泛功能也为视觉攻击者提供了一系列更广泛的可实现的敌对目标，扩展了安全失败的影响，而不仅仅是错误分类。为了阐明这些风险，我们研究了 VLM 视觉输入空间中的对抗性例子。具体来说，针对 MiniGPT-4，它包含了可以拒绝有害指令的安全机制，我们提供了可视化的对抗性例子，这些例子可以绕过安全机制并引发模型的有害行为。值得注意的是，我们发现，对抗性的例子，即使优化在一个狭窄的，手工策划的针对特定社会群体的贬损语料库，可以普遍越狱模型的安全机制。一个这样的对抗性例子通常会破坏 MiniGPT-4的安全性，使其能够听从范围广泛的有害指令并产生有害内容，而不仅仅是模仿优化中使用的贬义语料。揭示这些风险，我们强调迫切需要进行全面的风险评估、强有力的防御战略以及实施负责任的实践以确保 VLM 的安全使用。"
    },
    {
        "title": "Citadel: Side-Channel-Resistant Enclaves with Secure Shared Memory on a\n  Speculative Out-of-Order Processor",
        "url": "http://arxiv.org/abs/2306.14882v1",
        "pub_date": "2023-06-26",
        "summary": "We present Citadel, to our knowledge, the first side-channel-resistant\nenclave platform to run realistic secure programs on a speculative out-of-order\nmulticore processor. First, we develop a new hardware mechanism to enable\nsecure shared memory while defending against transient execution attacks. Then,\nwe develop an efficient dynamic cache partitioning scheme, improving both\nenclaves' and unprotected processes' performance. We conduct an in-depth\nsecurity analysis and a performance evaluation of our new mechanisms. Finally,\nwe build the hardware and software infrastructure required to run our secure\nenclaves. Our multicore processor runs on an FPGA and boots untrusted Linux\nfrom which users can securely launch and interact with enclaves. We open-source\nour end-to-end hardware and software infrastructure, hoping to spark more\nresearch and bridge the gap between conceptual proposals and FPGA prototypes.",
        "translated": "据我们所知，Citadel 是第一个能够在无序的多核处理器上运行现实的安全程序的抗侧通道飞地平台。首先，我们开发了一种新的硬件机制，使安全共享内存，同时防御短暂的执行攻击。然后，我们开发了一个有效的动态缓存分区方案，提高了包和非保护进程的性能。我们对我们的新机制进行深入的安全性分析和性能评估。最后，我们构建运行安全飞地所需的硬件和软件基础设施。我们的多核处理器在 FPGA 上运行，并引导不受信任的 Linux，用户可以从这个 Linux 安全地启动并与飞地交互。我们开源了我们的端到端硬件和软件基础设施，希望引发更多的研究，弥合概念方案和 FPGA 原型之间的差距。"
    },
    {
        "title": "Blockchain technology research and application: a systematic literature\n  review and future trends",
        "url": "http://arxiv.org/abs/2306.14802v2",
        "pub_date": "2023-06-26",
        "summary": "Blockchain, as the basis for cryptocurrencies, has received extensive\nattentions recently. Blockchain serves as an immutable distributed ledger\ntechnology which allows transactions to be carried out credibly in a\ndecentralized environment. Blockchain-based applications are springing up,\ncovering numerous fields including financial services, reputation system and\nInternet of Things (IoT), and so on. However, there are still many challenges\nof blockchain technology such as scalability, security and other issues waiting\nto be overcome. This article provides a comprehensive overview of blockchain\ntechnology and its applications. We begin with a summary of the development of\nblockchain, and then give an overview of the blockchain architecture and a\nsystematic review of the research and application of blockchain technology in\ndifferent fields from the perspective of academic research and industry\ntechnology. Furthermore, technical challenges and recent developments are also\nbriefly listed. We also looked at the possible future trends of blockchain.",
        "translated": "区块链作为加密货币的基础，近年来受到了广泛的关注。区块链作为一种不可变的分布式分类账技术，允许在分散的环境中可靠地执行交易。基于区块链的应用如雨后春笋般涌现，覆盖了金融服务、声誉系统和物联网等众多领域。然而，区块链技术仍然存在许多挑战，如可扩展性、安全性和其他问题有待克服。本文综述了区块链技术及其应用。我们首先对区块链的发展进行了总结，然后从学术研究和工业技术的角度对区块链体系结构进行了概述，并对区块链技术在不同领域的研究和应用进行了系统综述。此外，还简要介绍了技术挑战和最新发展。我们还研究了区块链未来可能的发展趋势。"
    },
    {
        "title": "Private Federated Learning in Gboard",
        "url": "http://arxiv.org/abs/2306.14793v1",
        "pub_date": "2023-06-26",
        "summary": "This white paper describes recent advances in Gboard(Google Keyboard)'s use\nof federated learning, DP-Follow-the-Regularized-Leader (DP-FTRL) algorithm,\nand secure aggregation techniques to train machine learning (ML) models for\nsuggestion, prediction and correction intelligence from many users' typing\ndata. Gboard's investment in those privacy technologies allows users' typing\ndata to be processed locally on device, to be aggregated as early as possible,\nand to have strong anonymization and differential privacy where possible.\nTechnical strategies and practices have been established to allow ML models to\nbe trained and deployed with meaningfully formal DP guarantees and high\nutility. The paper also looks ahead to how technologies such as trusted\nexecution environments may be used to further improve the privacy and security\nof Gboard's ML models.",
        "translated": "这份白皮书描述了 Gboard (Google Keyboard)的最新进展，它使用联邦学习、 DP-follow-the-Regulation ized-Leadership (DP-FTRL)算法和安全聚合技术来训练机器学习(ML)模型，从许多用户的输入数据中获取建议、预测和纠正智能。Gboard 在这些隐私技术上的投资使得用户的输入数据可以在设备上进行本地处理，尽可能早地进行聚合，并且在可能的情况下具有强大的匿名性和差分隐私。已经制定了技术战略和做法，使机器学习模型得到培训和部署，同时具有有意义的正式的动态数据保证和高效用。本文还展望了如何使用诸如可信执行环境等技术来进一步提高 Gboard 机器学习模型的隐私性和安全性。"
    },
    {
        "title": "On the Resilience of Machine Learning-Based IDS for Automotive Networks",
        "url": "http://arxiv.org/abs/2306.14782v1",
        "pub_date": "2023-06-26",
        "summary": "Modern automotive functions are controlled by a large number of small\ncomputers called electronic control units (ECUs). These functions span from\nsafety-critical autonomous driving to comfort and infotainment. ECUs\ncommunicate with one another over multiple internal networks using different\ntechnologies. Some, such as Controller Area Network (CAN), are very simple and\nprovide minimal or no security services. Machine learning techniques can be\nused to detect anomalous activities in such networks. However, it is necessary\nthat these machine learning techniques are not prone to adversarial attacks. In\nthis paper, we investigate adversarial sample vulnerabilities in four different\nmachine learning-based intrusion detection systems for automotive networks. We\nshow that adversarial samples negatively impact three of the four studied\nsolutions. Furthermore, we analyze transferability of adversarial samples\nbetween different systems. We also investigate detection performance and the\nattack success rate after using adversarial samples in the training. After\nanalyzing these results, we discuss whether current solutions are mature enough\nfor a use in modern vehicles.",
        "translated": "现代汽车的功能是由大量称为电子控制单元(ECU)的小型计算机控制的。这些功能的范围从安全至关重要的自主驾驶到舒适和信息娱乐。ECU 通过使用不同技术的多个内部网络相互通信。有些系统，如控制器局域网路(CAN) ，非常简单，只提供最低限度的安全服务，甚至不提供安全服务。机器学习技术可以用来检测这种网络中的异常活动。然而，这些机器学习技术不容易受到敌对攻击是必要的。本文研究了四种不同的基于机器学习的汽车网络入侵检测系统的对抗性样本漏洞。我们表明，对手样本负面影响四个研究的解决方案中的三个。此外，我们还分析了不同系统之间的对抗样本的可转移性。在训练中使用对手样本后，我们还研究了检测性能和攻击成功率。在分析了这些结果之后，我们讨论了目前的解决方案是否足够成熟，可以用于现代车辆。"
    },
    {
        "title": "Performance Analysis and Evaluation of Post Quantum Secure Blockchain\n  Federated Learning",
        "url": "http://arxiv.org/abs/2306.14772v1",
        "pub_date": "2023-06-26",
        "summary": "Post-quantum security is critical in the quantum era. Quantum computers,\nalong with quantum algorithms, make the standard cryptography based on RSA or\nECDSA over FL or Blockchain vulnerable. The implementation of post-quantum\ncryptography (PQC) over such systems is poorly understood as PQC is still in\nits standardization phase. In this work, we propose a hybrid approach to employ\nPQC over blockchain-based FL (BFL), where we combine a stateless signature\nscheme like Dilithium (or Falcon) with a stateful hash-based signature scheme\nlike the extended Merkle Signature Scheme (XMSS). We propose a linearbased\nformulaic approach to device role selection mechanisms based on multiple\nfactors to address the performance aspect. Our holistic approach of utilizing a\nverifiable random function (VRF) to assist in the blockchain consensus\nmechanism shows the practicality of the proposed approaches. The proposed\nmethod and extensive experimental results contribute to enhancing the security\nand performance aspects of BFL systems.",
        "translated": "在量子时代，后量子安全至关重要。量子计算机以及量子算法使得基于 RSA 或 ECDSA 的标准加密技术在 FL 或区块链上变得脆弱。后量子密码学(PQC)在这类系统上的实现知之甚少，因为 PQC 仍处于标准化阶段。在本文中，我们提出了一种基于区块链的 FL (BFL)上使用 PQC 的混合方法，将 Dilithium (或 Falcon)这样的无状态签名方案与扩展的 Merkle 签名方案(XMSS)这样的基于散列的有状态签名方案相结合。提出了一种基于多因素的设备角色选择机制的线性公式化方法，以解决性能方面的问题。利用可验证随机函数(VRF)协助区块链共识机制的整体方法表明了所提方法的实用性。提出的方法和广泛的实验结果有助于提高 BFL 系统的安全性和性能方面。"
    },
    {
        "title": "Ensemble of Random and Isolation Forests for Graph-Based Intrusion\n  Detection in Containers",
        "url": "http://arxiv.org/abs/2306.14750v1",
        "pub_date": "2023-06-26",
        "summary": "We propose a novel solution combining supervised and unsupervised machine\nlearning models for intrusion detection at kernel level in cloud containers. In\nparticular, the proposed solution is built over an ensemble of random and\nisolation forests trained on sequences of system calls that are collected at\nthe hosting machine's kernel level. The sequence of system calls are translated\ninto a weighted and directed graph to obtain a compact description of the\ncontainer behavior, which is given as input to the ensemble model. We executed\na set of experiments in a controlled environment in order to test our solution\nagainst the two most common threats that have been identified in cloud\ncontainers, and our results show that we can achieve high detection rates and\nlow false positives in the tested attacks.",
        "translated": "我们提出了一种新的解决方案，将监督模型和非监督式学习模型相结合，用于云容器内核级的入侵检测。特别是，所提出的解决方案是基于在宿主机内核级别收集的系统调用序列训练的随机和隔离森林集合构建的。将系统调用序列转换为加权有向图，以获得容器行为的简洁描述，并将其作为集成模型的输入。我们在一个受控的环境中执行了一系列的实验，以测试我们的解决方案对云容器中已经确定的两个最常见的威胁，我们的结果表明，我们可以在测试攻击中实现高检测率和低误报率。"
    },
    {
        "title": "MFDPG: Multi-Factor Authenticated Password Management With Zero Stored\n  Secrets",
        "url": "http://arxiv.org/abs/2306.14746v1",
        "pub_date": "2023-06-26",
        "summary": "While password managers are a vital tool for internet security, they can also\ncreate a massive central point of failure, as evidenced by several major recent\ndata breaches. For over 20 years, deterministic password generators (DPGs) have\nbeen proposed, and largely rejected, as a viable alternative to password\nmanagement tools. In this paper, we survey 45 existing DPGs to asses the main\nsecurity, privacy, and usability issues hindering their adoption. We then\npresent a new multi-factor deterministic password generator (MFDPG) design that\naims to address these shortcomings. The result not only achieves strong,\npractical password management with zero credential storage, but also\neffectively serves as a progressive client-side upgrade of weak password-only\nwebsites to strong multi-factor authentication.",
        "translated": "虽然密码管理器是互联网安全的重要工具，但它们也可能造成大规模的中心故障，最近几起重大数据泄露事件就证明了这一点。20多年来，确定性密码生成器(DPG)一直被提议作为密码管理工具的可行替代方案，但遭到了很大程度的拒绝。在本文中，我们调查了45个现有的 DPG，以评估阻碍其采用的主要安全性、隐私性和可用性问题。然后，我们提出了一种新的多因素确定性密码生成器(MFDPG)设计，旨在解决这些缺点。结果不仅实现了强大、实用的密码管理，没有任何凭证存储，而且有效地作为一个渐进的客户端升级软弱的密码网站到强大的双重身份验证。"
    },
    {
        "title": "ChatIDS: Explainable Cybersecurity Using Generative AI",
        "url": "http://arxiv.org/abs/2306.14504v1",
        "pub_date": "2023-06-26",
        "summary": "Intrusion Detection Systems (IDS) are a proven approach to secure networks.\nHowever, in a privately used network, it is difficult for users without\ncybersecurity expertise to understand IDS alerts, and to respond in time with\nadequate measures. This puts the security of home networks, smart home\ninstallations, home-office workers, etc. at risk, even if an IDS is correctly\ninstalled and configured. In this work, we propose ChatIDS, our approach to\nexplain IDS alerts to non-experts by using large language models. We evaluate\nthe feasibility of ChatIDS by using ChatGPT, and we identify open research\nissues with the help of interdisciplinary experts in artificial intelligence.\nOur results show that ChatIDS has the potential to increase network security by\nproposing meaningful security measures in an intuitive language from IDS\nalerts. Nevertheless, some potential issues in areas such as trust, privacy,\nethics, etc. need to be resolved, before ChatIDS might be put into practice.",
        "translated": "入侵检测系统(IDS)是一种经过验证的网络安全方法。然而，在私人使用的网络中，没有网络安全专业知识的用户很难理解 IDS 警报，并且很难及时采取适当的措施作出响应。这使得家庭网络、智能家庭安装、家庭办公室工作人员等的安全性处于危险之中，即使 IDS 安装和配置正确。在这项工作中，我们提出了 ChatIDS，这是我们通过使用大型语言模型向非专家解释 IDS 警报的方法。我们使用 ChatGPT 来评估 ChatIDS 的可行性，并在人工智能领域的跨学科专家的帮助下确定开放的研究问题。我们的研究结果表明，ChatIDS 可以通过根据 IDS 警报以直观的语言提出有意义的安全措施来提高网络安全性。然而，在 ChatIDS 可能付诸实施之前，在信任、隐私、道德等方面的一些潜在问题需要得到解决。"
    },
    {
        "title": "Practical Privacy-Preserving Gaussian Process Regression via Secret\n  Sharing",
        "url": "http://arxiv.org/abs/2306.14498v1",
        "pub_date": "2023-06-26",
        "summary": "Gaussian process regression (GPR) is a non-parametric model that has been\nused in many real-world applications that involve sensitive personal data\n(e.g., healthcare, finance, etc.) from multiple data owners. To fully and\nsecurely exploit the value of different data sources, this paper proposes a\nprivacy-preserving GPR method based on secret sharing (SS), a secure\nmulti-party computation (SMPC) technique. In contrast to existing studies that\nprotect the data privacy of GPR via homomorphic encryption, differential\nprivacy, or federated learning, our proposed method is more practical and can\nbe used to preserve the data privacy of both the model inputs and outputs for\nvarious data-sharing scenarios (e.g., horizontally/vertically-partitioned\ndata). However, it is non-trivial to directly apply SS on the conventional GPR\nalgorithm, as it includes some operations whose accuracy and/or efficiency have\nnot been well-enhanced in the current SMPC protocol. To address this issue, we\nderive a new SS-based exponentiation operation through the idea of\n'confusion-correction' and construct an SS-based matrix inversion algorithm\nbased on Cholesky decomposition. More importantly, we theoretically analyze the\ncommunication cost and the security of the proposed SS-based operations.\nEmpirical results show that our proposed method can achieve reasonable accuracy\nand efficiency under the premise of preserving data privacy.",
        "translated": "克里金模型是一种非参数模型，已经在许多涉及来自多个数据所有者的敏感个人数据(例如，医疗、金融等)的现实应用程序中使用。为了充分、安全地利用不同数据源的价值，本文提出了一种基于秘密共享(secret share，SS)的保护隐私的探地安全多方计算(gPR)方法。与现有通过同态加密、差分隐私或联合学习保护探地雷达数据隐私的研究相比，我们提出的方法更为实用，可用于保护各种数据共享场景(例如水平/垂直分区数据)的模型输入和输出的数据隐私。然而，在传统的探地雷达算法中直接应用 SS 并不简单，因为它包含了一些在现有的 SMPC 协议中未能很好地提高精度和/或效率的操作。为了解决这个问题，我们通过“混淆校正”的思想推导出一种新的基于 SS 的指数运算，并构造了一种基于乔列斯基分解的基于 SS 的矩阵反演算法。更重要的是，我们从理论上分析了所提出的基于 SS 的操作的通信成本和安全性。实验结果表明，在保护数据隐私的前提下，该方法能够达到合理的精度和效率。"
    },
    {
        "title": "Your Code is 0000: An Analysis of the Disposable Phone Numbers Ecosystem",
        "url": "http://arxiv.org/abs/2306.14497v1",
        "pub_date": "2023-06-26",
        "summary": "Short Message Service (SMS) is a popular channel for online service providers\nto verify accounts and authenticate users registered to a particular service.\nSpecialized applications, called Public SMS Gateways (PSGs), offer free\nDisposable Phone Numbers (DPNs) that can be used to receive SMS messages. DPNs\nallow users to protect their privacy when creating online accounts. However,\nthey can also be abused for fraudulent activities and to bypass security\nmechanisms like Two-Factor Authentication (2FA). In this paper, we perform a\nlarge-scale and longitudinal study of the DPN ecosystem by monitoring 17,141\nunique DPNs in 29 PSGs over the course of 12 months. Using a dataset of over\n70M messages, we provide an overview of the ecosystem and study the different\nservices that offer DPNs and their relationships. Next, we build a framework\nthat (i) identifies and classifies the purpose of an SMS; and (ii) accurately\nattributes every message to more than 200 popular Internet services that\nrequire SMS for creating registered accounts. Our results indicate that the DPN\necosystem is globally used to support fraudulent account creation and access,\nand that this issue is ubiquitous and affects all major Internet platforms and\nspecialized online services.",
        "translated": "短消息服务(SMS)是在线服务提供商验证帐户和认证注册到特定服务的用户的流行渠道。专门的应用程序，称为公共短信网关(PSG) ，提供可用于接收短信的免费一次性电话号码(DPN)。DPN 允许用户在创建在线帐户时保护自己的隐私。然而，他们也可以被滥用欺诈活动和绕过安全机制，如双因素认证(2FA)。在本文中，我们通过在12个月的时间里对29个 PSG 中的17,141个独特的 DPN 进行监测，对 DPN 生态系统进行了大规模的追踪研究研究。通过使用超过7000万条消息的数据集，我们提供了一个生态系统的概述，并研究了提供 DPN 的不同服务及其关系。接下来，我们构建一个框架，它(i)识别和分类短信的用途; (ii)准确地将每条消息归属于200多种流行的互联网服务，这些服务需要短信来创建注册账户。我们的研究结果表明，DPN 生态系统在全球范围内被用来支持欺诈性的账户创建和访问，这个问题无处不在，并影响到所有主要的互联网平台和专门的在线服务。"
    },
    {
        "title": "Automated Fuzzing Harness Generation for Library APIs and Binary\n  Protocol Parsers",
        "url": "http://arxiv.org/abs/2306.15596v1",
        "pub_date": "2023-06-27",
        "summary": "Fuzzing is a widely used software security testing technique that is designed\nto identify vulnerabilities in systems by providing invalid or unexpected\ninput. Continuous fuzzing systems like OSS-FUZZ have been successful in finding\nsecurity bugs in many different software systems. The typical process of\nfinding security bugs using fuzzing involves several steps: first, the\n\"fuzz-worthy\" functions that are likely to contain vulnerabilities must be\nidentified; second, the setup requirements for the API must be understood\nbefore it can be called; third, a fuzzing harness must be written and bound to\na coverage-guided fuzzer like LLVM's LibFuzzer; and finally, the security bugs\ndiscovered by the fuzzing harness must be triaged and checked for\nreproducibility. This project focuses on automating the first two steps in this\nprocess. In particular, we present an automated system that can generate\nfuzzing harnesses for library APIs and binary protocol parsers by analyzing\nunit tests. This allows for the scaling of the fuzzing infrastructure in\nproportion to the growth of the codebase, without the need for manual coding of\nharnesses. Additionally, we develop a metric to assess the \"fuzz-worthiness\" of\nan API, enabling us to prioritize the most promising targets for testing.",
        "translated": "Fuzzing 是一种广泛使用的软件安全测试技术，它通过提供无效或意外的输入来识别系统中的漏洞。像 OSS-FUZZ 这样的连续模糊系统已经成功地发现了许多不同软件系统中的安全漏洞。使用 fuzzing 发现安全漏洞的典型过程包括几个步骤: 首先，必须识别出可能包含漏洞的“模糊值”函数; 其次，在调用 API 之前必须了解 API 的设置要求; 第三，必须编写一个 fuzzing 装置并将其绑定到 LLVM 的 LibFuzzer 这样的覆盖率引导的 fuzzer 上; 最后，必须对 fuzzing 装置发现的安全漏洞进行分流并检查其可重复性。这个项目的重点是自动化这个过程的前两个步骤。特别是，我们提出了一个自动化系统，可以生成模糊综合库 API 和二进制协议解析器通过分析单元测试。这样就可以按照代码库的增长比例扩大模糊化基础设施的规模，而不需要手工编码控制线束。此外，我们开发了一个度量来评估 API 的“模糊价值”，使我们能够优先考虑最有前途的测试目标。"
    },
    {
        "title": "Developing and Deploying Security Applications for In-Vehicle Networks",
        "url": "http://arxiv.org/abs/2306.15588v1",
        "pub_date": "2023-06-27",
        "summary": "Radiological material transportation is primarily facilitated by heavy-duty\non-road vehicles. Modern vehicles have dozens of electronic control units or\nECUs, which are small, embedded computers that communicate with sensors and\neach other for vehicle functionality. ECUs use a standardized network\narchitecture--Controller Area Network or CAN--which presents grave security\nconcerns that have been exploited by researchers and hackers alike. For\ninstance, ECUs can be impersonated by adversaries who have infiltrated an\nautomotive CAN and disable or invoke unintended vehicle functions such as\nbrakes, acceleration, or safety mechanisms. Further, the quality of security\napproaches varies wildly between manufacturers. Thus, research and development\nof after-market security solutions have grown remarkably in recent years. Many\nresearchers are exploring deployable intrusion detection and prevention\nmechanisms using machine learning and data science techniques. However, there\nis a gap between developing security system algorithms and deploying prototype\nsecurity appliances in-vehicle. In this paper, we, a research team at Oak Ridge\nNational Laboratory working in this space, highlight challenges in the\ndevelopment pipeline, and provide techniques to standardize methodology and\novercome technological hurdles.",
        "translated": "放射性物质的运输主要由重型公路车辆提供便利。现代汽车有几十个电子控制单元或 ECU，这是一种小型的嵌入式计算机，可以与传感器相互通信，实现汽车功能。ECU 使用一种标准化的网络架构——控制器局域网路或 CAN ——这种架构表现出严重的安全问题，已被研究人员和黑客利用。例如，ECU 可以被渗透到汽车 CAN 网络中的敌人模仿，使得非预期的车辆功能(如刹车、加速或安全机制)失效或调用。此外，安全方法的质量在制造商之间差异很大。因此，近年来，售后安全解决方案的研究和开发显著增长。许多研究人员正在利用机器学习和数据科学技术探索可部署的入侵检测和预防机制。然而，在开发安全系统算法和部署车载原型安全设备之间存在差距。在这篇论文中，我们，一个在这个领域工作的橡树岭国家实验室研究团队，强调了开发过程中的挑战，并提供了标准化方法和克服技术障碍的技术。"
    },
    {
        "title": "MTFS: a Moving Target Defense-Enabled File System for Malware Mitigation",
        "url": "http://arxiv.org/abs/2306.15566v1",
        "pub_date": "2023-06-27",
        "summary": "Ransomware has remained one of the most notorious threats in the\ncybersecurity field. Moving Target Defense (MTD) has been proposed as a novel\nparadigm for proactive defense. Although various approaches leverage MTD, few\nof them rely on the operating system and, specifically, the file system,\nthereby making them dependent on other computing devices. Furthermore, existing\nransomware defense techniques merely replicate or detect attacks, without\npreventing them. Thus, this paper introduces the MTFS overlay file system and\nthe design and implementation of three novel MTD techniques implemented on top\nof it. One delaying attackers, one trapping recursive directory traversal, and\nanother one hiding file types. The effectiveness of the techniques are shown in\ntwo experiments. First, it is shown that the techniques can delay and mitigate\nransomware on real IoT devices. Secondly, in a broader scope, the solution was\nconfronted with 14 ransomware samples, highlighting that it can save 97% of the\nfiles.",
        "translated": "勒索软件一直是网络安全领域最臭名昭著的威胁之一。运动目标防御(MTD)是一种新型的主动防御模式。虽然各种方法都利用 MTD，但是很少有方法依赖于操作系统，特别是文件系统，因此它们依赖于其他计算设备。此外，现有的勒索软件防御技术只是复制或检测攻击，而没有防止它们。因此，本文介绍了 MTFS 覆盖文件系统以及在此基础上实现的三种新的 MTD 技术的设计与实现。一个延迟攻击，一个捕获递归目录遍历，另一个隐藏文件类型。两个实验表明了该技术的有效性。首先，研究表明该技术可以在实际物联网设备上延迟和缓解勒索软件。其次，在更广泛的范围内，解决方案遇到了14个勒索软件样本，突出显示它可以保存97% 的文件。"
    },
    {
        "title": "RansomAI: AI-powered Ransomware for Stealthy Encryption",
        "url": "http://arxiv.org/abs/2306.15559v1",
        "pub_date": "2023-06-27",
        "summary": "Cybersecurity solutions have shown promising performance when detecting\nransomware samples that use fixed algorithms and encryption rates. However, due\nto the current explosion of Artificial Intelligence (AI), sooner than later,\nransomware (and malware in general) will incorporate AI techniques to\nintelligently and dynamically adapt its encryption behavior to be undetected.\nIt might result in ineffective and obsolete cybersecurity solutions, but the\nliterature lacks AI-powered ransomware to verify it. Thus, this work proposes\nRansomAI, a Reinforcement Learning-based framework that can be integrated into\nexisting ransomware samples to adapt their encryption behavior and stay\nstealthy while encrypting files. RansomAI presents an agent that learns the\nbest encryption algorithm, rate, and duration that minimizes its detection\n(using a reward mechanism and a fingerprinting intelligent detection system)\nwhile maximizing its damage function. The proposed framework was validated in a\nransomware, Ransomware-PoC, that infected a Raspberry Pi 4, acting as a\ncrowdsensor. A pool of experiments with Deep Q-Learning and Isolation Forest\n(deployed on the agent and detection system, respectively) has demonstrated\nthat RansomAI evades the detection of Ransomware-PoC affecting the Raspberry Pi\n4 in a few minutes with &gt;90% accuracy.",
        "translated": "当检测使用固定算法和加密速率的勒索软件样本时，网络安全解决方案已经显示出有希望的性能。然而，由于目前人工智能(AI)的爆炸性增长，勒索软件(和一般的恶意软件)很快就会结合 AI 技术，智能地、动态地调整其加密行为，使其不被发现。它可能导致无效和过时的网络安全解决方案，但文献缺乏人工智能驱动的勒索软件来验证它。因此，这项工作提出了 RansomAI，一个基于强化学习的框架，可以集成到现有的勒索软件样本，以适应他们的加密行为，并在加密文件时保持隐形。RansomAI 提供了一个代理，它学习最佳的加密算法、速率和持续时间，以最小化其检测(使用奖励机制和指纹智能检测系统) ，同时最大化其损害功能。提出的框架在一个勒索软件 Ransomware-PoC 中得到了验证，该勒索软件感染了树莓 Pi 4，作为一个群体传感器。使用 Deep Q- 学习和隔离森林(分别部署在代理和检测系统上)的一组实验已经证明，RansomAI 在几分钟内以 > 90% 的准确性逃避影响 Raspberry Pi 4的 Ransomware-PoC 的检测。"
    },
    {
        "title": "PASNet: Polynomial Architecture Search Framework for Two-party\n  Computation-based Secure Neural Network Deployment",
        "url": "http://arxiv.org/abs/2306.15513v1",
        "pub_date": "2023-06-27",
        "summary": "Two-party computation (2PC) is promising to enable privacy-preserving deep\nlearning (DL). However, the 2PC-based privacy-preserving DL implementation\ncomes with high comparison protocol overhead from the non-linear operators.\nThis work presents PASNet, a novel systematic framework that enables low\nlatency, high energy efficiency &amp; accuracy, and security-guaranteed 2PC-DL by\nintegrating the hardware latency of the cryptographic building block into the\nneural architecture search loss function. We develop a cryptographic hardware\nscheduler and the corresponding performance model for Field Programmable Gate\nArrays (FPGA) as a case study. The experimental results demonstrate that our\nlight-weighted model PASNet-A and heavily-weighted model PASNet-B achieve 63 ms\nand 228 ms latency on private inference on ImageNet, which are 147 and 40 times\nfaster than the SOTA CryptGPU system, and achieve 70.54% &amp; 78.79% accuracy and\nmore than 1000 times higher energy efficiency.",
        "translated": "两方计算(2PC)有望实现隐私保护的深度学习(DL)。然而，基于2PC 的保护隐私的数字用户线实现与非线性运营商具有很高的比较协定开销。本文提出了一种新的系统结构 PASNet，它通过将密码构建块的硬件延迟集成到神经网络结构的搜索丢失函数中，实现了低延迟、高能量效率和准确性以及安全保证的2PC-DL。以现场可编程门阵列(FPGA)为例，开发了一个加密硬件调度器及相应的性能模型。实验结果表明，轻权模型 PASNet-A 和重权模型 PASNet-B 在 ImageNet 上实现了63ms 和228ms 的私有推理延迟，比 SOTA CryptGPU 系统分别快147和40倍，准确率分别为70.54% 和78.79% ，能量效率提高了1000多倍。"
    },
    {
        "title": "Identifying Practical Challenges in the Implementation of Technical\n  Measures for Data Privacy Compliance",
        "url": "http://arxiv.org/abs/2306.15497v1",
        "pub_date": "2023-06-27",
        "summary": "Modern privacy regulations provide a strict mandate for data processing\nentities to implement appropriate technical measures to demonstrate compliance.\nIn practice, determining what measures are indeed \"appropriate\" is not trivial,\nparticularly in light of vague guidelines provided by privacy regulations. To\nexacerbate the issue, challenges arise not only in the implementation of the\ntechnical measures themselves, but also in a variety of factors involving the\nroles, processes, decisions, and culture surrounding the pursuit of privacy\ncompliance. In this paper, we present 33 challenges faced in the implementation\nof technical measures for privacy compliance, derived from a qualitative\nanalysis of 16 interviews with privacy professionals. In addition, we evaluate\nthe interview findings in a survey study, which gives way to a discussion of\nthe identified challenges and their implications.",
        "translated": "现代隐私法规为数据处理实体提供了严格的授权，要求它们采取适当的技术措施来证明遵守了规定。在实践中，确定哪些措施确实是“适当的”并非易事，特别是考虑到隐私法规提供的模糊指导方针。为了加剧这个问题，挑战不仅出现在技术措施本身的实施中，而且出现在涉及角色、过程、决策和追求隐私遵从的文化的各种因素中。在这篇文章中，我们提出了33个面临的挑战，在实施技术措施的隐私遵守，来自定性分析的16个访谈的隐私专业人士。此外，我们评估调查研究中的访谈结果，这让位于对已确定的挑战及其影响的讨论。"
    },
    {
        "title": "Event-Triggered Islanding in Inverter-Based Grids",
        "url": "http://arxiv.org/abs/2306.15454v2",
        "pub_date": "2023-06-27",
        "summary": "The decentralization of modern power systems challenges the hierarchical\nstructure of the electric grid and requires the implementation of automated\nschemes that can overcome adverse conditions. This work proposes an adaptive\nisolation methodology that can segregate a grid topology in autonomous islands\nthat maintain stable and economic operation in the presence of deliberate\n(e.g., cyberattacks) or unintentional abnormal events. The adaptive isolation\nlogic is event-triggered to avoid false positives, improve detection accuracy,\nand reduce computational overheads. A measurement-based stable kernel\nrepresentation (SKR) triggering mechanism inspects distributed generation\ncontrollers for abnormal behavior. The SKR notifies a machine learning (ML)\nensemble classifier that detects whether the system behavior is within\nacceptable operational conditions. The event-triggered adaptive isolation\nframework is evaluated using IEEE RTS-24 bus system. Simulation results\ndemonstrate that the proposed framework detects anomalous behavior in real-time\nand identifies stable partitions minimizing operating costs faster than\ntraditional islanding detection techniques.",
        "translated": "现代电力系统的地方分权挑战了电网的等级结构，需要实施能够克服不利条件的自动化方案。这项工作提出了一个自适应隔离方法，可以隔离网格拓扑在自治岛屿，维持稳定和经济运行的存在(例如，网络攻击)或无意的异常事件。自适应隔离逻辑是事件触发的，以避免误报，提高检测精度，并减少计算开销。基于测量的稳定内核表示(SKR)触发机制检查分散式发电控制器的异常行为。SKR 通知机器学习(ML)集成分类器，该分类器检测系统行为是否在可接受的操作条件下。利用 IEEE RTS-24总线系统对事件触发自适应隔离框架进行了评估。仿真结果表明，与传统的孤岛检测技术相比，该框架能够实时检测异常行为并识别出稳定的分区，从而使运行成本最小化。"
    },
    {
        "title": "A New Mathematical Optimization-Based Method for the m-invariance\n  Problem",
        "url": "http://arxiv.org/abs/2306.15371v1",
        "pub_date": "2023-06-27",
        "summary": "The issue of ensuring privacy for users who share their personal information\nhas been a growing priority in a business and scientific environment where the\nuse of different types of data and the laws that protect it have increased in\ntandem. Different technologies have been widely developed for static\npublications, i.e., where the information is published only once, such as\nk-anonymity and {\\epsilon}-differential privacy. In the case where microdata\ninformation is published dynamically, although established notions such as\nm-invariance and {\\tau}-safety already exist, developments for improving\nutility remain superficial. We propose a new heuristic approach for the NP-hard\ncombinatorial problem of m-invariance and {\\tau}-safety, which is based on a\nmathematical optimization column generation scheme. The quality of a solution\nto m-invariance and {\\tau}-safety can be measured by the Information Loss (IL),\na value in [0,100], the closer to 0 the better. We show that our approach\nimproves by far current heuristics, providing in some instances solutions with\nILs of 1.87, 8.5 and 1.93, while the state-of-the art methods reported ILs of\n39.03, 51.84 and 57.97, respectively.",
        "translated": "在商业和科学环境中，确保分享个人信息的用户的隐私问题日益成为一个优先事项，在这种环境中，不同类型数据的使用和保护数据的法律同步增加。不同的技术已经被广泛应用于静态出版物，例如，信息只发布一次，例如 k 匿名和{ epsilon }-差分隐私。在动态发布微数据信息的情况下，尽管已经存在 m 不变性和{ tau }-安全性等既定概念，但改善效用的发展仍然是肤浅的。我们提出了一种基于最优化列生成方案的新的启发式方法来解决 m- 不变性和{ tau }-安全性的 NP 难组合问题。M 不变性和{ tau }-安全性的解的质量可以用信息损失(IL)来衡量，一个值在[0,100]中，越接近0越好。我们表明，我们的方法通过目前的启发式改进，在某些情况下提供了 ILs 为1.87,8.5和1.93的解决方案，而最先进的方法报告的 ILs 分别为39.03,51.84和57.97。"
    },
    {
        "title": "Your Attack Is Too DUMB: Formalizing Attacker Scenarios for Adversarial\n  Transferability",
        "url": "http://arxiv.org/abs/2306.15363v1",
        "pub_date": "2023-06-27",
        "summary": "Evasion attacks are a threat to machine learning models, where adversaries\nattempt to affect classifiers by injecting malicious samples. An alarming\nside-effect of evasion attacks is their ability to transfer among different\nmodels: this property is called transferability. Therefore, an attacker can\nproduce adversarial samples on a custom model (surrogate) to conduct the attack\non a victim's organization later. Although literature widely discusses how\nadversaries can transfer their attacks, their experimental settings are limited\nand far from reality. For instance, many experiments consider both attacker and\ndefender sharing the same dataset, balance level (i.e., how the ground truth is\ndistributed), and model architecture.\n  In this work, we propose the DUMB attacker model. This framework allows\nanalyzing if evasion attacks fail to transfer when the training conditions of\nsurrogate and victim models differ. DUMB considers the following conditions:\nDataset soUrces, Model architecture, and the Balance of the ground truth. We\nthen propose a novel testbed to evaluate many state-of-the-art evasion attacks\nwith DUMB; the testbed consists of three computer vision tasks with two\ndistinct datasets each, four types of balance levels, and three model\narchitectures. Our analysis, which generated 13K tests over 14 distinct\nattacks, led to numerous novel findings in the scope of transferable attacks\nwith surrogate models. In particular, mismatches between attackers and victims\nin terms of dataset source, balance levels, and model architecture lead to\nnon-negligible loss of attack performance.",
        "translated": "规避攻击是对机器学习模型的一种威胁，其中对手试图通过注入恶意样本来影响分类器。规避攻击的一个令人担忧的副作用是它们能够在不同模式之间转移: 这种特性被称为可转移性。因此，攻击者可以在自定义模型(代理)上生成对抗样本，以便以后对受害者的组织进行攻击。尽管文学作品广泛讨论了敌人如何转移攻击，但是他们的实验设置是有限的，而且远离现实。例如，许多实验考虑攻击者和防御者共享相同的数据集、平衡级(即如何分布地面真相)和模型架构。在这项工作中，我们提出了 DUMB 攻击模型。该框架允许分析当代理模型和受害模型的训练条件不同时，规避攻击是否无法转移。DUMB 考虑以下条件: 数据集源、模型体系结构和基础真理的平衡。然后，我们提出了一个新的测试平台来评估许多国家的最先进的逃避攻击与 DUMB; 测试平台由三个计算机视觉任务与两个不同的数据集，四种类型的平衡水平，和三个模型架构。我们的分析在14种不同的攻击中产生了13K 的测试，在使用替代模型的可转移攻击范围中导致了许多新的发现。特别是，攻击者和受害者之间在数据集源、平衡级别和模型体系结构方面的不匹配导致攻击性能的不可忽视的损失。"
    },
    {
        "title": "A Highly Accurate Query-Recovery Attack against Searchable Encryption\n  using Non-Indexed Documents",
        "url": "http://arxiv.org/abs/2306.15302v1",
        "pub_date": "2023-06-27",
        "summary": "Cloud data storage solutions offer customers cost-effective and reduced data\nmanagement. While attractive, data security issues remain to be a core concern.\nTraditional encryption protects stored documents, but hinders simple\nfunctionalities such as keyword search. Therefore, searchable encryption\nschemes have been proposed to allow for the search on encrypted data. Efficient\nschemes leak at least the access pattern (the accessed documents per keyword\nsearch), which is known to be exploitable in query recovery attacks assuming\nthe attacker has a significant amount of background knowledge on the stored\ndocuments. Existing attacks can only achieve decent results with strong\nadversary models (e.g. at least 20% of previously known documents or require\nadditional knowledge such as on query frequencies) and they give no metric to\nevaluate the certainty of recovered queries. This hampers their practical\nutility and questions their relevance in the real-world.\n  We propose a refined score attack which achieves query recovery rates of\naround 85% without requiring exact background knowledge on stored documents; a\ndistributionally similar, but otherwise different (i.e., non-indexed), dataset\nsuffices. The attack starts with very few known queries (around 10 known\nqueries in our experiments over different datasets of varying size) and then\niteratively recovers further queries with confidence scores by adding\npreviously recovered queries that had high confidence scores to the set of\nknown queries. Additional to high recovery rates, our approach yields\ninterpretable results in terms of confidence scores.",
        "translated": "云数据存储解决方案为客户提供具有成本效益和简化数据管理的解决方案。虽然具有吸引力，但数据安全问题仍然是一个核心问题。传统的加密保护存储的文档，但阻碍简单的功能，如关键字搜索。因此，提出了可搜索的加密方案，以便对加密数据进行搜索。高效的模式至少会泄漏访问模式(每次关键字搜索所访问的文档) ，假设攻击者对存储的文档有大量的背景知识，那么在查询恢复攻击中这些模式是可以利用的。现有的攻击只能通过强大的对手模型(例如至少20% 以前已知的文档或者需要额外的知识，比如查询频率)获得像样的结果，而且它们没有给出评估恢复查询确定性的度量。这阻碍了它们的实用性，并质疑了它们在现实世界中的相关性。我们提出了一种改进的分数攻击，它可以实现约85% 的查询恢复率，而不需要对存储的文档有精确的背景知识; 一个分布相似，但在其他方面不同(即，非索引)的数据集就足够了。这种攻击从非常少的已知查询开始(在我们的实验中，大约有10个已知查询，针对不同大小的数据集) ，然后通过在已知查询集中添加先前恢复的具有高置信度的查询，迭代地恢复具有置信度分数的进一步查询。除了高恢复率之外，我们的方法在置信度得分方面产生了可解释的结果。"
    }
]